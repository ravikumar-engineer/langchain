{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e47164b",
   "metadata": {},
   "source": [
    "## **DATA INGESTION**\n",
    "Data ingestion is the process of collecting and loading data from different sources into a system so that an AI/LLM can understand and use it.\n",
    "\n",
    "**Why Data Ingestion is Necessary?**\n",
    "- LLMs do NOT know your data\n",
    "- LLMs are trained on public + generic data\n",
    "\n",
    "They cannot access your private data and automatically load into AI system\n",
    "\n",
    "---\n",
    "**Document Loaders: https://docs.langchain.com/oss/python/integrations/document_loaders**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d423b1e",
   "metadata": {},
   "source": [
    "#### **Text Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05290635",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/myenv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'cosmics.txt'}, page_content='Cosmics: Their Presence in the Galaxy and Their Relation with the Sound “Om”\\n\\nThe universe is vast, mysterious, and filled with forces that go far beyond what human senses can directly perceive. From ancient civilizations to modern astrophysics, humans have tried to understand the nature of the cosmos and its underlying energy. The term cosmics broadly refers to cosmic entities, energies, radiations, and phenomena that exist throughout the galaxy. These cosmics play a crucial role in shaping stars, planets, life, and even human consciousness. Interestingly, ancient spiritual traditions, especially from India, describe the universe as originating from a primordial sound known as Om. This essay explores the presence of cosmics in the galaxy and their deep symbolic and scientific connection with the sound Om.\\n\\nUnderstanding Cosmics and Cosmic Presence\\n\\nCosmics can be understood as universal forces and energies present throughout space. In scientific terms, this includes cosmic radiation, electromagnetic waves, dark matter, dark energy, gravitational fields, and subatomic particles traveling across the universe. Cosmic rays, for example, are high-energy particles that originate from supernova explosions, black holes, and distant galaxies. These particles constantly interact with Earth and all living beings, even though we are not consciously aware of them.\\n\\nThe galaxy is not empty space; it is a dynamic system filled with motion, vibration, and energy. Stars are born from clouds of cosmic dust, galaxies collide and merge, and black holes bend space and time. All these processes show that the cosmos is alive with activity. Cosmics act as the invisible framework that maintains balance and order in the universe. Without these forces, galaxies would not form, stars would not shine, and life would not exist.\\n\\nThe Universe as Vibration and Energy\\n\\nModern physics tells us that everything in the universe is made of energy. According to quantum mechanics, even solid matter is composed of vibrating particles. At the most fundamental level, reality behaves like waves rather than fixed objects. This idea strongly aligns with ancient philosophies that described the universe as sound or vibration.\\n\\nAstrophysical observations show that space itself vibrates. Planets produce electromagnetic frequencies, stars emit harmonic oscillations, and even black holes generate gravitational waves. These vibrations form a cosmic symphony, where each celestial object contributes its own frequency. Cosmics, therefore, are not just particles or forces; they are expressions of universal vibration.\\n\\nThe Concept of Om in Ancient Wisdom\\n\\nIn ancient Indian philosophy, Om (also written as AUM) is considered the primordial sound of the universe. It is believed to be the first vibration from which all creation emerged. The Mandukya Upanishad describes Om as the essence of past, present, and future, and as the sound that connects the physical, mental, and cosmic realms.\\n\\nOm is not just a spoken syllable; it is a vibrational frequency. Chanting Om produces a resonance that affects the body, mind, and environment. The sound begins deep in the abdomen, moves through the chest, and fades at the head, symbolizing the journey from material existence to higher consciousness. This flow mirrors the expansion of the universe from a single point to infinite space.\\n\\nScientific Parallels to the Sound Om\\n\\nWhile Om originates from spiritual traditions, its concept has surprising parallels in modern science. The Big Bang theory suggests that the universe began from a singular event, releasing immense energy and creating space, time, and matter. This event can be metaphorically compared to a cosmic sound or vibration, similar to Om.\\n\\nNASA has recorded sounds from space by converting electromagnetic waves into audible frequencies. These recordings reveal deep, humming, rhythmic sounds produced by planets, stars, and interstellar plasma. For example, the low-frequency vibrations emitted by the sun and the resonant waves of Saturn resemble continuous cosmic hums. Many researchers describe the universe as having a background “cosmic noise,” which can be symbolically related to the eternal sound Om.\\n\\nCosmics and Consciousness\\n\\nAnother fascinating connection between cosmics and Om lies in consciousness. Human brains operate through electrical signals and frequencies. Studies show that meditation and Om chanting can synchronize brain waves, especially alpha and theta waves, which are associated with calmness, focus, and creativity. This suggests that human consciousness may resonate with universal cosmic frequencies.\\n\\nSome scientists and philosophers believe that consciousness itself may be a fundamental property of the universe, influenced by cosmic energy. If cosmics permeate all space and matter, then human awareness may be indirectly shaped by these universal forces. Om, in this context, becomes a bridge between individual consciousness and cosmic consciousness.\\n\\nSymbolic Unity of Science and Spirituality\\n\\nThe relationship between cosmics and Om highlights a deeper unity between science and spirituality. Science explains how the universe functions through equations and observations, while spirituality explores why it exists and how humans connect to it. Both perspectives point toward a universe that is interconnected, dynamic, and vibrational in nature.\\n\\nCosmics represent the external expression of universal energy, while Om represents its internal, experiential form. One is observed through telescopes and detectors; the other is felt through meditation and awareness. Together, they suggest that the galaxy is not just a physical space but a living system of energy and meaning.\\n\\nConclusion\\n\\nThe presence of cosmics throughout the galaxy reveals that the universe is filled with powerful energies and constant motion. From cosmic rays to gravitational waves, these forces shape the structure of galaxies and influence life itself. Ancient wisdom, through the concept of Om, described this same universe as a manifestation of primordial vibration. Though expressed differently, both science and spirituality point toward the same truth: the cosmos is fundamentally vibrational.\\n\\nOm symbolizes the eternal sound of existence, while cosmics represent its measurable form in space. Understanding their relationship helps bridge the gap between modern astrophysics and ancient philosophy. In this unity, humanity finds not only knowledge of the galaxy but also a deeper connection to the universe and to itself.')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import TextLoader to load data from a .txt file\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Create a TextLoader object and pass the text file path\n",
    "loader = TextLoader(\"cosmics.txt\")\n",
    "\n",
    "# Load the text file content into LangChain Document\n",
    "documents = loader.load()\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9f073",
   "metadata": {},
   "source": [
    "#### **PDF Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3cbc335",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File path Deep Learning with Python - François Chollet - Manning (2018).pdf is not a valid file or url",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_community\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_loaders\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PyPDFLoader\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Create a PDF loader object by providing the PDF file path\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m loader = \u001b[43mPyPDFLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDeep Learning with Python - François Chollet - Manning (2018).pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Load the PDF content\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Each page of the PDF is loaded as a separate document\u001b[39;00m\n\u001b[32m      9\u001b[39m pages = loader.load()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/myenv/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:281\u001b[39m, in \u001b[36mPyPDFLoader.__init__\u001b[39m\u001b[34m(self, file_path, password, headers, extract_images, mode, images_parser, images_inner_format, pages_delimiter, extraction_mode, extraction_kwargs)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\n\u001b[32m    239\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    240\u001b[39m     file_path: Union[\u001b[38;5;28mstr\u001b[39m, PurePath],\n\u001b[32m   (...)\u001b[39m\u001b[32m    250\u001b[39m     extraction_kwargs: Optional[\u001b[38;5;28mdict\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    251\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    252\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Initialize with a file path.\u001b[39;00m\n\u001b[32m    253\u001b[39m \n\u001b[32m    254\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    279\u001b[39m \u001b[33;03m        `aload` methods to retrieve parsed documents with content and metadata.\u001b[39;00m\n\u001b[32m    280\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m     \u001b[38;5;28mself\u001b[39m.parser = PyPDFParser(\n\u001b[32m    283\u001b[39m         password=password,\n\u001b[32m    284\u001b[39m         mode=mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    290\u001b[39m         extraction_kwargs=extraction_kwargs,\n\u001b[32m    291\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/myenv/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:140\u001b[39m, in \u001b[36mBasePDFLoader.__init__\u001b[39m\u001b[34m(self, file_path, headers)\u001b[39m\n\u001b[32m    138\u001b[39m         \u001b[38;5;28mself\u001b[39m.file_path = \u001b[38;5;28mstr\u001b[39m(temp_pdf)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.isfile(\u001b[38;5;28mself\u001b[39m.file_path):\n\u001b[32m--> \u001b[39m\u001b[32m140\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile path \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m is not a valid file or url\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m.file_path)\n",
      "\u001b[31mValueError\u001b[39m: File path Deep Learning with Python - François Chollet - Manning (2018).pdf is not a valid file or url"
     ]
    }
   ],
   "source": [
    "# Import PyPDFLoader to read PDF files\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# Create a PDF loader object by providing the PDF file path\n",
    "loader = PyPDFLoader(\"Deep Learning with Python - François Chollet - Manning (2018).pdf\")\n",
    "\n",
    "# Load the PDF content\n",
    "# Each page of the PDF is loaded as a separate document\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e038ed",
   "metadata": {},
   "source": [
    "### **Web Based Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a347233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Artificial_intelligence', 'title': 'Artificial intelligence - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nArtificial intelligence - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nGoals\\n\\n\\n\\n\\nToggle Goals subsection\\n\\n\\n\\n\\n\\n1.1\\nReasoning and problem-solving\\n\\n\\n\\n\\n\\n\\n\\n\\n1.2\\nKnowledge representation\\n\\n\\n\\n\\n\\n\\n\\n\\n1.3\\nPlanning and decision-making\\n\\n\\n\\n\\n\\n\\n\\n\\n1.4\\nLearning\\n\\n\\n\\n\\n\\n\\n\\n\\n1.5\\nNatural language processing\\n\\n\\n\\n\\n\\n\\n\\n\\n1.6\\nPerception\\n\\n\\n\\n\\n\\n\\n\\n\\n1.7\\nSocial intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n1.8\\nGeneral intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nTechniques\\n\\n\\n\\n\\nToggle Techniques subsection\\n\\n\\n\\n\\n\\n2.1\\nSearch and optimization\\n\\n\\n\\n\\n\\n\\n2.1.1\\nState space search\\n\\n\\n\\n\\n\\n\\n\\n\\n2.1.2\\nLocal search\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nLogic\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nProbabilistic methods for uncertain reasoning\\n\\n\\n\\n\\n\\n\\n\\n\\n2.4\\nClassifiers and statistical learning methods\\n\\n\\n\\n\\n\\n\\n\\n\\n2.5\\nArtificial neural networks\\n\\n\\n\\n\\n\\n\\n\\n\\n2.6\\nDeep learning\\n\\n\\n\\n\\n\\n\\n\\n\\n2.7\\nGPT\\n\\n\\n\\n\\n\\n\\n\\n\\n2.8\\nHardware and software\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nApplications\\n\\n\\n\\n\\nToggle Applications subsection\\n\\n\\n\\n\\n\\n3.1\\nHealth and medicine\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\nGames\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\nMathematics\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\nFinance\\n\\n\\n\\n\\n\\n\\n\\n\\n3.5\\nMilitary\\n\\n\\n\\n\\n\\n\\n\\n\\n3.6\\nGenerative AI\\n\\n\\n\\n\\n\\n\\n\\n\\n3.7\\nAgents\\n\\n\\n\\n\\n\\n\\n\\n\\n3.8\\nWeb search\\n\\n\\n\\n\\n\\n\\n\\n\\n3.9\\nSexuality\\n\\n\\n\\n\\n\\n\\n\\n\\n3.10\\nOther industry-specific tasks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nEthics\\n\\n\\n\\n\\nToggle Ethics subsection\\n\\n\\n\\n\\n\\n4.1\\nRisks and harm\\n\\n\\n\\n\\n\\n\\n4.1.1\\nPrivacy and copyright\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.2\\nDominance by tech giants\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.3\\nPower needs and environmental impacts\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.4\\nMisinformation\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.5\\nAlgorithmic bias and fairness\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.6\\nLack of transparency\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.7\\nBad actors and weaponized AI\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.8\\nTechnological unemployment\\n\\n\\n\\n\\n\\n\\n\\n\\n4.1.9\\nExistential risk\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4.2\\nEthical machines and alignment\\n\\n\\n\\n\\n\\n\\n\\n\\n4.3\\nOpen source\\n\\n\\n\\n\\n\\n\\n\\n\\n4.4\\nFrameworks\\n\\n\\n\\n\\n\\n\\n\\n\\n4.5\\nRegulation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nPhilosophy\\n\\n\\n\\n\\nToggle Philosophy subsection\\n\\n\\n\\n\\n\\n6.1\\nDefining artificial intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n6.2\\nEvaluating approaches to AI\\n\\n\\n\\n\\n\\n\\n6.2.1\\nSymbolic AI and its limits\\n\\n\\n\\n\\n\\n\\n\\n\\n6.2.2\\nNeat vs. scruffy\\n\\n\\n\\n\\n\\n\\n\\n\\n6.2.3\\nSoft vs. hard computing\\n\\n\\n\\n\\n\\n\\n\\n\\n6.2.4\\nNarrow vs. general AI\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n6.3\\nMachine consciousness, sentience, and mind\\n\\n\\n\\n\\n\\n\\n6.3.1\\nConsciousness\\n\\n\\n\\n\\n\\n\\n\\n\\n6.3.2\\nComputationalism and functionalism\\n\\n\\n\\n\\n\\n\\n\\n\\n6.3.3\\nAI welfare and rights\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nFuture\\n\\n\\n\\n\\nToggle Future subsection\\n\\n\\n\\n\\n\\n7.1\\nSuperintelligence and the singularity\\n\\n\\n\\n\\n\\n\\n\\n\\n7.2\\nTranshumanism\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\nIn fiction\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n10\\nExplanatory notes\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\nReferences\\n\\n\\n\\n\\nToggle References subsection\\n\\n\\n\\n\\n\\n11.1\\nTextbooks\\n\\n\\n\\n\\n\\n\\n\\n\\n11.2\\nHistory of AI\\n\\n\\n\\n\\n\\n\\n\\n\\n11.3\\nOther sources\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12\\nExternal links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nArtificial intelligence\\n\\n\\n\\n173 languages\\n\\n\\n\\n\\nAfrikaansAlemannischአማርኛअंगिकाالعربيةAragonésԱրեւմտահայերէնঅসমীয়াAsturianuAvañe\\'ẽAzərbaycancaتۆرکجهবাংলা閩南語 / Bân-lâm-gíБашҡортсаБеларускаяБеларуская (тарашкевіца)भोजपुरीBikol CentralБългарскиBoarischབོད་ཡིགBosanskiBrezhonegБуряадCatalàЧӑвашлаCebuanoČeštinaCymraegDanskالدارجةDeutschEestiΕλληνικάEspañolEsperantoEstremeñuEuskaraفارسیFiji HindiFrançaisFurlanGaeilgeGaelgGàidhligGalego贛語Gĩkũyũगोंयची कोंकणी / Gõychi Konknni한국어HausaՀայերենहिन्दीHrvatskiIdoIgboIlokanoBahasa IndonesiaInterlinguaInterlingueIsiZuluÍslenskaItalianoעבריתJawaಕನ್ನಡქართულიکٲشُرҚазақшаKiswahiliKreyòl ayisyenKriyòl gwiyannenKurdîКыргызчаລາວLatinaLatviešuLëtzebuergeschLietuviųLigureLimburgsLa .lojban.LombardMagyarMadhurâМакедонскиMalagasyമലയാളംMaltiमराठीმარგალურიمصرىBahasa MelayuMinangkabauМонголမြန်မာဘာသာNederlandsNedersaksiesनेपालीनेपाल भाषा日本語NordfriiskNorsk bokmålNorsk nynorskOccitanଓଡ଼ିଆOʻzbekcha / ўзбекчаਪੰਜਾਬੀپنجابیပအိုဝ်ႏဘာႏသာႏپښتوPatoisភាសាខ្មែរPicardPiemontèisPlattdüütschPolskiPortuguêsQaraqalpaqshaQırımtatarcaReo tahitiRipoarischRomânăRuna SimiРусиньскыйРусскийСаха тылаसंस्कृतम्SängöScotsSesotho sa LeboaShqipSicilianuසිංහලSimple EnglishسنڌيSlovenčinaSlovenščinaکوردیСрпски / srpskiSrpskohrvatski / српскохрватскиSuomiSvenskaTagalogதமிழ்Татарча / tatarçaతెలుగుไทยТоҷикӣTürkçeTürkmençeУкраїнськаاردوئۇيغۇرچە / UyghurcheVènetoTiếng ViệtVõroWalon文言Winaray吴语ייִדיש粵語ZazakiŽemaitėška中文BetawiKadazandusunFɔ̀ngbèJaku Ibanꠍꠤꠟꠐꠤⵜⴰⵎⴰⵣⵉⵖⵜ ⵜⴰⵏⴰⵡⴰⵢⵜ\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadView sourceView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadView sourceView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikibooksWikiquoteWikiversityWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\n\\nIntelligence of machines\\n\"AI\" redirects here. For other uses, see AI (disambiguation) and Artificial intelligence (disambiguation).\\n\\n\\nPart of a series onArtificial intelligence (AI)\\nMajor goals\\nArtificial general intelligence\\nIntelligent agent\\nRecursive self-improvement\\nPlanning\\nComputer vision\\nGeneral game playing\\nKnowledge representation\\nNatural language processing\\nRobotics\\nAI safety\\n\\nApproaches\\nMachine learning\\nSymbolic\\nDeep learning\\nBayesian networks\\nEvolutionary algorithms\\nHybrid intelligent systems\\nSystems integration\\nOpen-source\\nAI data centers\\n\\nApplications\\nBioinformatics\\nDeepfake\\nEarth sciences\\n Finance \\nGenerative AI\\nArt\\nAudio\\nMusic\\nGovernment\\nHealthcare\\nMental health\\nIndustry\\nSoftware development\\nTranslation\\n Military \\nPhysics\\nProjects\\n\\nPhilosophy\\nAI alignment\\nArtificial consciousness\\nThe bitter lesson\\nChinese room\\nFriendly AI\\nEthics\\nExistential risk\\nTuring test\\nUncanny valley\\nHuman–AI interaction\\n\\nHistory\\nTimeline\\nProgress\\nAI winter\\nAI boom\\nAI bubble\\n\\nControversies\\nDeepfake pornography\\nTaylor Swift deepfake pornography controversy\\nGrok deepfake pornography controversy\\nGoogle Gemini image generation controversy\\nPause Giant AI Experiments\\nRemoval of Sam Altman from OpenAI\\nStatement on AI Risk\\nTay (chatbot)\\nThéâtre D\\'opéra Spatial\\nVoiceverse NFT plagiarism scandal\\n\\nGlossary\\nGlossary\\nvte\\nArtificial intelligence (AI) is the capability of computational systems to perform tasks typically associated with human intelligence, such as learning, reasoning, problem-solving, perception, and decision-making. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1]\\nHigh-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); virtual assistants (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., language models and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it\\'s not labeled AI anymore.\"[2][3]\\nVarious subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include learning, reasoning, knowledge representation, planning, natural language processing, perception, and support for robotics.[a] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[4] Some companies, such as OpenAI, Google DeepMind and Meta,[5] aim to create artificial general intelligence (AGI) – AI that can complete virtually any cognitive task at least as well as a human.\\nArtificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism throughout its history,[7][8] followed by periods of disappointment and loss of funding, known as AI winters.[9][10] Funding and interest vastly increased after 2012 when graphics processing units started being used to accelerate neural networks, and deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture.[12] In the 2020s, an ongoing period of rapid progress in advanced generative AI became known as the AI boom. Generative AI\\'s ability to create and modify content has led to several unintended consequences and harms. Ethical concerns have been raised about AI\\'s long-term effects and potential existential risks, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\\n\\n\\nGoals\\nThe general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\\n\\nReasoning and problem-solving\\nEarly researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[13] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[14]\\nMany of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem.\\n\\nKnowledge representation\\nAn ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.\\nKnowledge representation and knowledge engineering[17] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[18] scene interpretation,[19] clinical decision support,[20] knowledge discovery (mining \"interesting\" and actionable inferences from large databases),[21] and other areas.[22]\\nA knowledge base is a body of knowledge represented in a form that can be used by a program. An ontology is the set of objects, relations, concepts, and properties used by a particular domain of knowledge.[23] Knowledge bases need to represent things such as objects, properties, categories, and relations between objects;[24] situations, events, states, and time;[25] causes and effects;[26] knowledge about knowledge (what we know about what other people know);[27] default reasoning (things that humans assume are true until they are told differently and will remain true even when other facts are changing);[28] and many other aspects and domains of knowledge.\\nAmong the most difficult problems in knowledge representation are the breadth of commonsense knowledge (the set of atomic facts that the average person knows is enormous);[29] and the sub-symbolic form of most commonsense knowledge (much of what people know is not represented as \"facts\" or \"statements\" that they could express verbally).[16] There is also the difficulty of knowledge acquisition, the problem of obtaining knowledge for AI applications.[c]\\n\\nPlanning and decision-making\\nAn \"agent\" is anything that perceives and takes actions in the world. A rational agent has goals or preferences and takes actions to make them happen.[d][32] In automated planning, the agent has a specific goal.[33] In automated decision-making, the agent has preferences—there are some situations it would prefer to be in, and some situations it is trying to avoid. The decision-making agent assigns a number to each situation (called the \"utility\") that measures how much the agent prefers it. For each possible action, it can calculate the \"expected utility\": the utility of all possible outcomes of the action, weighted by the probability that the outcome will occur. It can then choose the action with the maximum expected utility.[34]\\nIn classical planning, the agent knows exactly what the effect of any action will be.[35] In most real-world problems, however, the agent may not be certain about the situation they are in (it is \"unknown\" or \"unobservable\") and it may not know for certain what will happen after each possible action (it is not \"deterministic\"). It must choose an action by making a probabilistic guess and then reassess the situation to see if the action worked.[36]\\nIn some problems, the agent\\'s preferences may be uncertain, especially if there are other agents or humans involved. These can be learned (e.g., with inverse reinforcement learning), or the agent can seek information to improve its preferences.[37] Information value theory can be used to weigh the value of exploratory or experimental actions.[38] The space of possible future actions and situations is typically intractably large, so the agents must take actions and evaluate situations while being uncertain of what the outcome will be.\\nA Markov decision process has a transition model that describes the probability that a particular action will change the state in a particular way and a reward function that supplies the utility of each state and the cost of each action. A policy associates a decision with each possible state. The policy could be calculated (e.g., by iteration), be heuristic, or it can be learned.[39]\\nGame theory describes the rational behavior of multiple interacting agents and is used in AI programs that make decisions that involve other agents.[40]\\n\\nLearning\\nMachine learning is the study of programs that can improve their performance on a given task automatically.[41] It has been a part of AI from the beginning.[e]\\n\\nIn supervised learning, the training data is labelled with the expected answers, while in unsupervised learning, the model identifies patterns or structures in unlabelled data.\\nThere are several kinds of machine learning. Unsupervised learning analyzes a stream of data and finds patterns and makes predictions without any other guidance.[44] Supervised learning requires labeling the training data with the expected answers, and comes in two main varieties: classification (where the program must learn to predict what category the input belongs in) and regression (where the program must deduce a numeric function based on numeric input).[45]\\nIn reinforcement learning, the agent is rewarded for good responses and punished for bad ones. The agent learns to choose responses that are classified as \"good\".[46] Transfer learning is when the knowledge gained from one problem is applied to a new problem.[47] Deep learning is a type of machine learning that runs inputs through biologically inspired artificial neural networks for all of these types of learning.[48]\\nComputational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization.[49]\\n\\n\\nNatural language processing\\nNatural language processing (NLP) allows programs to read, write and communicate in human languages.[50] Specific problems include speech recognition, speech synthesis, machine translation, information extraction, information retrieval and question answering.[51]\\nEarly work, based on Noam Chomsky\\'s generative grammar and semantic networks, had difficulty with word-sense disambiguation[f] unless restricted to small domains called \"micro-worlds\" (due to the common sense knowledge problem[29]). Margaret Masterman believed that it was meaning and not grammar that was the key to understanding languages, and that thesauri and not dictionaries should be the basis of computational language structure.\\nModern deep learning techniques for NLP include word embedding (representing words, typically as vectors encoding their meaning),[52] transformers (a deep learning architecture using an attention mechanism),[53] and others.[54] In 2019, generative pre-trained transformer (or \"GPT\") language models began to generate coherent text,[55][56] and by 2023, these models were able to get human-level scores on the bar exam, SAT test, GRE test, and many other real-world applications.[57]\\n\\nPerception\\nMachine perception is the ability to use input from sensors (such as cameras, microphones, wireless signals, active lidar, sonar, radar, and tactile sensors) to deduce aspects of the world. Computer vision is the ability to analyze visual input.[58]\\nThe field includes speech recognition,[59] image classification,[60] facial recognition, object recognition,[61] object tracking,[62] and robotic perception.[63]\\n\\nSocial intelligence\\nKismet, a robot head which was made in the 1990s; it is a machine that can recognize and simulate emotions.[64]\\nAffective computing is a field that comprises systems that recognize, interpret, process, or simulate human feeling, emotion, and mood.[65] For example, some virtual assistants are programmed to speak conversationally or even to banter humorously; it makes them appear more sensitive to the emotional dynamics of human interaction, or to otherwise facilitate human–computer interaction.\\nHowever, this tends to give naïve users an unrealistic conception of the intelligence of existing computer agents.[66] Moderate successes related to affective computing include textual sentiment analysis and, more recently, multimodal sentiment analysis, wherein AI classifies the effects displayed by a videotaped subject.[67]\\n\\nGeneral intelligence\\nA machine with artificial general intelligence would be able to solve a wide variety of problems with breadth and versatility similar to human intelligence.[68]\\n\\nTechniques\\nAI research uses a wide variety of techniques to accomplish the goals above.[b]\\n\\nSearch and optimization\\nAI can solve many problems by intelligently searching through many possible solutions.[69] There are two very different kinds of search used in AI: state space search and local search.\\n\\nState space search\\nState space search searches through a tree of possible states to try to find a goal state.[70] For example, planning algorithms search through trees of goals and subgoals, attempting to find a path to a target goal, a process called means-ends analysis.[71]\\nSimple exhaustive searches[72] are rarely sufficient for most real-world problems: the search space (the number of places to search) quickly grows to astronomical numbers. The result is a search that is too slow or never completes.[15] \"Heuristics\" or \"rules of thumb\" can help prioritize choices that are more likely to reach a goal.[73]\\nAdversarial search is used for game-playing programs, such as chess or Go. It searches through a tree of possible moves and countermoves, looking for a winning position.[74]\\n\\nLocal search\\nIllustration of gradient descent for 3 different starting points; two parameters (represented by the plan coordinates) are adjusted in order to minimize the loss function (the height) Local search uses mathematical optimization to find a solution to a problem. It begins with some form of guess and refines it incrementally.[75]\\nGradient descent is a type of local search that optimizes a set of numerical parameters by incrementally adjusting them to minimize a loss function. Variants of gradient descent are commonly used to train neural networks,[76] through the backpropagation algorithm.\\nAnother type of local search is evolutionary computation, which aims to iteratively improve a set of candidate solutions by \"mutating\" and \"recombining\" them, selecting only the fittest to survive each generation.[77]\\nDistributed search processes can coordinate via swarm intelligence algorithms. Two popular swarm algorithms used in search are particle swarm optimization (inspired by bird flocking) and ant colony optimization (inspired by ant trails).[78]\\n\\nLogic\\nFormal logic is used for reasoning and knowledge representation.[79]\\nFormal logic comes in two main forms: propositional logic (which operates on statements that are true or false and uses logical connectives such as \"and\", \"or\", \"not\" and \"implies\")[80] and predicate logic (which also operates on objects, predicates and relations and uses quantifiers such as \"Every X is a Y\" and \"There are some Xs that are Ys\").[81]\\nDeductive reasoning in logic is the process of proving a new statement (conclusion) from other statements that are given and assumed to be true (the premises).[82] Proofs can be structured as proof trees, in which nodes are labelled by sentences, and children nodes are connected to parent nodes by inference rules.\\nGiven a problem and a set of premises, problem-solving reduces to searching for a proof tree whose root node is labelled by a solution of the problem and whose leaf nodes are labelled by premises or axioms. In the case of Horn clauses, problem-solving search can be performed by reasoning forwards from the premises or backwards from the problem.[83] In the more general case of the clausal form of first-order logic, resolution is a single, axiom-free rule of inference, in which a problem is solved by proving a contradiction from premises that include the negation of the problem to be solved.[84]\\nInference in both Horn clause logic and first-order logic is undecidable, and therefore intractable. However, backward reasoning with Horn clauses, which underpins computation in the logic programming language Prolog, is Turing complete. Moreover, its efficiency is competitive with computation in other symbolic programming languages.[85]\\nFuzzy logic assigns a \"degree of truth\" between 0 and 1. It can therefore handle propositions that are vague and partially true.[86]\\nNon-monotonic logics, including logic programming with negation as failure, are designed to handle default reasoning.[28] Other specialized versions of logic have been developed to describe many complex domains.\\n\\nProbabilistic methods for uncertain reasoning\\nA simple Bayesian network, with the associated conditional probability tables\\nMany problems in AI (including reasoning, planning, learning, perception, and robotics) require the agent to operate with incomplete or uncertain information. AI researchers have devised a number of tools to solve these problems using methods from probability theory and economics.[87] Precise mathematical tools have been developed that analyze how an agent can make choices and plan, using decision theory, decision analysis,[88] and information value theory.[89] These tools include models such as Markov decision processes,[90] dynamic decision networks,[91] game theory and mechanism design.[92]\\nBayesian networks[93] are a tool that can be used for reasoning (using the Bayesian inference algorithm),[g][95] learning (using the expectation–maximization algorithm),[h][97] planning (using decision networks)[98] and perception (using dynamic Bayesian networks).[91]\\nProbabilistic algorithms can also be used for filtering, prediction, smoothing, and finding explanations for streams of data, thus helping perception systems analyze processes that occur over time (e.g., hidden Markov models or Kalman filters).[91]\\n\\nExpectation–maximization clustering of Old Faithful eruption data starts from a random guess but then successfully converges on an accurate clustering of the two physically distinct modes of eruption.\\nClassifiers and statistical learning methods\\nThe simplest AI applications can be divided into two types: classifiers (e.g., \"if shiny then diamond\"), on one hand, and controllers (e.g., \"if diamond then pick up\"), on the other hand. Classifiers[99] are functions that use pattern matching to determine the closest match. They can be fine-tuned based on chosen examples using supervised learning. Each pattern (also called an \"observation\") is labeled with a certain predefined class. All the observations combined with their class labels are known as a data set. When a new observation is received, that observation is classified based on previous experience.[45]\\nThere are many kinds of classifiers in use.[100] The decision tree is the simplest and most widely used symbolic machine learning algorithm.[101] K-nearest neighbor algorithm was the most widely used analogical AI until the mid-1990s, and Kernel methods such as the support vector machine (SVM) displaced k-nearest neighbor in the 1990s.[102]\\nThe naive Bayes classifier is reportedly the \"most widely used learner\"[103] at Google, due in part to its scalability.[104]\\nNeural networks are also used as classifiers.[105]\\n\\nArtificial neural networks\\nA neural network is an interconnected group of nodes, akin to the vast network of neurons in the human brain.\\nAn artificial neural network is based on a collection of nodes also known as artificial neurons, which loosely model the neurons in a biological brain. It is trained to recognise patterns; once trained, it can recognise those patterns in fresh data. There is an input, at least one hidden layer of nodes and an output. Each node applies a function and once the weight crosses its specified threshold, the data is transmitted to the next layer. A network is typically called a deep neural network if it has at least 2 hidden layers.[105]\\nLearning algorithms for neural networks use local search to choose the weights that will get the right output for each input during training. The most common training technique is the backpropagation algorithm.[106] Neural networks learn to model complex relationships between inputs and outputs and find patterns in data. In theory, a neural network can learn any function.[107]\\nIn feedforward neural networks the signal passes in only one direction.[108] The term perceptron typically refers to a single-layer neural network.[109] In contrast, deep learning uses many layers.[110] Recurrent neural networks (RNNs) feed the output signal back into the input, which allows short-term memories of previous input events. Long short-term memory networks (LSTMs) are recurrent neural networks that better preserve longterm dependencies and are less sensitive to the vanishing gradient problem.[111] Convolutional neural networks (CNNs) use layers of kernels to more efficiently process local patterns. This local processing is especially important in image processing, where the early CNN layers typically identify simple local patterns such as edges and curves, with subsequent layers detecting more complex patterns like textures, and eventually whole objects.[112]\\n\\nDeep learning\\nDeep learning is a subset of machine learning, which is itself a subset of artificial intelligence.[113]\\nDeep learning uses several layers of neurons between the network\\'s inputs and outputs.[110] The multiple layers can progressively extract higher-level features from the raw input. For example, in image processing, lower layers may identify edges, while higher layers may identify the concepts relevant to a human such as digits, letters, or faces.[114]\\nDeep learning has profoundly improved the performance of programs in many important subfields of artificial intelligence, including computer vision, speech recognition, natural language processing, image classification,[115] and others. The reason that deep learning performs so well in so many applications is not known as of 2021.[116] The sudden success of deep learning in 2012–2015 did not occur because of some new discovery or theoretical breakthrough (deep neural networks and backpropagation had been described by many people, as far back as the 1950s)[i] but because of two factors: the incredible increase in computer power (including the hundred-fold increase in speed by switching to GPUs) and the availability of vast amounts of training data, especially the giant curated datasets used for benchmark testing, such as ImageNet.[j]\\n\\nGPT\\nGenerative pre-trained transformers (GPT) are large language models (LLMs) that generate text based on the semantic relationships between words in sentences. Text-based GPT models are pre-trained on a large corpus of text that can be from the Internet. The pretraining consists of predicting the next token (a token being usually a word, subword, or punctuation). Throughout this pretraining, GPT models accumulate knowledge about the world and can then generate human-like text by repeatedly predicting the next token. Typically, a subsequent training phase makes the model more truthful, useful, and harmless, usually with a technique called reinforcement learning from human feedback (RLHF). Current GPT models are prone to generating falsehoods called \"hallucinations\". These can be reduced with RLHF and quality data, but the problem has been getting worse for reasoning systems.[124] Such systems are used in chatbots, which allow people to ask a question or request a task in simple text.[125][126]\\nCurrent models and services include ChatGPT, Claude, Gemini, Copilot, and Meta AI.[127] Multimodal GPT models can process different types of data (modalities) such as images, videos, sound, and text.[128]\\n\\nHardware and software\\nMain articles: Programming languages for artificial intelligence and Hardware for artificial intelligence\\nRaspberry Pi AI Kit\\nIn the late 2010s, graphics processing units (GPUs) that were increasingly designed with AI-specific enhancements and used with specialized TensorFlow software had replaced previously used central processing unit (CPUs) as the dominant means for large-scale (commercial and academic) machine learning models\\' training.[129] Specialized programming languages such as Prolog were used in early AI research,[130] but general-purpose programming languages like Python have become predominant.[131]\\nThe transistor density in integrated circuits has been observed to roughly double every 18 months—a trend known as Moore\\'s law, named after the Intel co-founder Gordon Moore, who first identified it. Improvements in GPUs have been even faster,[132] a trend sometimes called Huang\\'s law,[133] named after Nvidia co-founder and CEO Jensen Huang.\\n\\nApplications\\nMain article: Applications of artificial intelligenceAI and machine learning technology is used in most of the essential applications of the 2020s, including:\\nsearch engines (such as Google Search)\\ntargeting online advertisements\\nrecommendation systems (offered by Netflix, YouTube or Amazon) driving internet traffic\\ntargeted advertising (AdSense, Facebook)\\nvirtual assistants (such as Siri or Alexa)\\nautonomous vehicles (including drones, ADAS and self-driving cars)\\nautomatic language translation (Microsoft Translator, Google Translate)\\nfacial recognition (Apple\\'s FaceID or Microsoft\\'s DeepFace and Google\\'s FaceNet)\\nimage labeling (used by Facebook, Apple\\'s Photos and TikTok).\\nThe deployment of AI may be overseen by a chief automation officer (CAO).\\n\\nHealth and medicine\\nMain article: Artificial intelligence in healthcare\\nIt has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.[134]\\nAlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[135] In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.[136] In 2024, researchers used machine learning to accelerate the search for Parkinson\\'s disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson\\'s disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.[137][138]\\n\\nGames\\nMain article: Artificial intelligence in video games\\nGame playing programs have been used since the 1950s to demonstrate and test AI\\'s most advanced techniques.[139] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[140] In 2011, in a Jeopardy! quiz show exhibition match, IBM\\'s question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[141] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world.[142] Other programs handle imperfect-information games, such as the poker-playing program Pluribus.[143] DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games.[144] In 2019, DeepMind\\'s AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.[145] In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world\\'s best Gran Turismo drivers using deep reinforcement learning.[146] In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.[147]\\n\\nMathematics\\nLarge language models, such as GPT-4, Gemini, Claude, Llama or Mistral, are increasingly used in mathematics. These probabilistic models are versatile, but can also produce wrong answers in the form of hallucinations. They sometimes need a large database of mathematical problems to learn from, but also methods such as supervised fine-tuning[148] or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections.[149] A February 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.[150] One technique to improve their performance involves training the models to produce correct reasoning steps, rather than just the correct result.[151] The Alibaba Group developed a version of its Qwen models called Qwen2-Math, that achieved state-of-the-art performance on several mathematical benchmarks, including 84% accuracy on the MATH dataset of competition mathematics problems.[152] In January 2025, Microsoft proposed the technique rStar-Math that leverages Monte Carlo tree search and step-by-step reasoning, enabling a relatively small language model like Qwen-7B to solve 53% of the AIME 2024 and 90% of the MATH benchmark problems.[153]\\nAlternatively, dedicated models for mathematical problem solving with higher precision for the outcome including proof of theorems have been developed such as AlphaTensor, AlphaGeometry, AlphaProof and AlphaEvolve[154] all from Google DeepMind,[155] Llemma from EleutherAI[156] or Julius.[157]\\nWhen natural language is used to describe mathematical problems, converters can transform such prompts into a formal language such as Lean to define mathematical tasks. The experimental model Gemini Deep Think accepts natural language prompts directly and achieved gold medal results in the International Math Olympiad of 2025.[158]\\nSome models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.[159]\\nTopological deep learning integrates various topological approaches.\\n\\nFinance\\nFinance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.[160]\\nAccording to Nicolas Firzli, director of the World Pensions & Investments Forum, it may be too early to see the emergence of highly innovative AI-informed financial products and services. He argues that \"the deployment of AI tools will simply further automatise things: destroying tens of thousands of jobs in banking, financial planning, and pension advice in the process, but I\\'m not sure it will unleash a new wave of [e.g., sophisticated] pension innovation.\"[161]\\n\\nMilitary\\nMain article: Military applications of artificial intelligence\\nVarious countries are deploying AI military applications.[162] The main applications enhance command and control, communications, sensors, integration and interoperability.[163] Research is targeting intelligence collection and analysis, logistics, cyber operations, information operations, and semiautonomous and autonomous vehicles.[162] AI technologies enable coordination of sensors and effectors, threat detection and identification, marking of enemy positions, target acquisition, coordination and deconfliction of distributed Joint Fires between networked combat vehicles, both human-operated and autonomous.[163]\\nAI has been used in military operations in Iraq, Syria, Israel and Ukraine.[162][164][165][166]\\n\\nGenerative AI\\nVincent van Gogh in watercolour created by generative AI softwareThese paragraphs are an excerpt from Generative artificial intelligence.[edit]\\nGenerative artificial intelligence (Generative AI or GenAI) is a subfield of artificial intelligence that uses generative models to generate text, images, videos, audio, software code or other forms of data.[167] These models are designed to learn the underlying patterns and structures of their training data and use them to generate new data[168] in response to input, which often takes the form of natural language prompts.[169][170]\\nThe prevalence of generative AI tools has increased significantly since the AI boom in the 2020s. This boom was made possible by improvements in deep neural networks, particularly large language models (LLMs), which are based on the transformer architecture. Generative AI applications include chatbots such as ChatGPT, Claude, Copilot, DeepSeek, Google Gemini and Grok; text-to-image models such as Stable Diffusion, Midjourney, and DALL-E; and text-to-video models such as Veo, LTX and Sora.[171][172][173] Technology companies developing generative AI include Alibaba, Anthropic, Baidu, DeepSeek, Google, Lightricks,[174] Meta AI, Microsoft, Mistral AI, OpenAI, Perplexity AI, xAI,[175] and Yandex.[176]\\nCompanies in a variety of sectors have used generative AI, including those in software development, healthcare,[177] finance,[178] entertainment,[179] customer service,[180] sales and marketing,[181] art, writing,[182] and product design.[183]\\n\\n\\nAgents\\nMain article: Agentic AI\\nAI agents are software entities designed to perceive their environment, make decisions, and take actions autonomously to achieve specific goals. These agents can interact with users, their environment, or other agents. AI agents are used in various applications, including virtual assistants, chatbots, autonomous vehicles, game-playing systems, and industrial robotics. AI agents operate within the constraints of their programming, available computational resources, and hardware limitations. This means they are restricted to performing tasks within their defined scope and have finite memory and processing capabilities. In real-world applications, AI agents often face time constraints for decision-making and action execution. Many AI agents incorporate learning algorithms, enabling them to improve their performance over time through experience or training. Using machine learning, AI agents can adapt to new situations and optimise their behaviour for their designated tasks.[184][185][186]\\n\\nWeb search\\nMicrosoft introduced Copilot Search in February 2023 under the name Bing Chat, as a built-in feature for Microsoft Edge and Bing mobile app. Copilot Search provides AI-generated summaries[187] and step-by-step reasoning based of information from web publishers, ranked in Bing Search.[188] \\nFor safety, Copilot uses AI-based classifiers and filters to reduce potentially harmful content.[189]\\nGoogle officially pushed its AI Search at its Google I/O event on 20 May 2025.[190] It keeps people looking at Google instead of clicking on a search result. AI Overviews uses Gemini 2.5 to provide contextual answers to user queries based on web content.[191]\\n\\nSexuality\\nApplications of AI in this domain include AI-enabled menstruation and fertility trackers that analyze user data to offer predictions,[192] AI-integrated sex toys (e.g., teledildonics),[193] AI-generated sexual education content,[194] and AI agents that simulate sexual and romantic partners (e.g., Replika).[195] AI is also used for the production of non-consensual deepfake pornography, raising significant ethical and legal concerns.[196]\\nAI technologies have also been used to attempt to identify online gender-based violence and online sexual grooming of minors.[197][198]\\n\\nOther industry-specific tasks\\nThere are also thousands of successful AI applications used to solve specific problems for specific industries or institutions. In a 2017 survey, one in five companies reported having incorporated \"AI\" in some offerings or processes.[199] A few examples are energy storage, medical diagnosis, military logistics, applications that predict the result of judicial decisions, foreign policy, or supply chain management.\\nAI applications for evacuation and disaster management are growing. AI has been used to investigate patterns in large-scale and small-scale evacuations using historical data from GPS, videos or social media. Furthermore, AI can provide real-time information on the evacuation conditions.[200][201][202]\\nIn agriculture, AI has helped farmers to increase yield and identify areas that need irrigation, fertilization, pesticide treatments. Agronomists use AI to conduct research and development. AI has been used to predict the ripening time for crops such as tomatoes, monitor soil moisture, operate agricultural robots, conduct predictive analytics, classify livestock pig call emotions, automate greenhouses, detect diseases and pests, and save water.\\nArtificial intelligence is used in astronomy to analyze increasing amounts of available data and applications, mainly for \"classification, regression, clustering, forecasting, generation, discovery, and the development of new scientific insights.\" For example, it is used for discovering exoplanets, forecasting solar activity, and distinguishing between signals and instrumental effects in gravitational wave astronomy. Additionally, it could be used for activities in space, such as space exploration, including the analysis of data from space missions, real-time science decisions of spacecraft, space debris avoidance, and more autonomous operation.\\nDuring the 2024 Indian elections, US$50 million was spent on authorized AI-generated content, notably by creating deepfakes of allied (including sometimes deceased) politicians to better engage with voters, and by translating speeches to various local languages.[203]\\n\\nEthics\\nMain article: Ethics of artificial intelligence\\nStreet art in Tel Aviv[204][205]\\nAI has potential benefits and potential risks.[206] AI may be able to advance science and find solutions for serious problems: Demis Hassabis of DeepMind hopes to \"solve intelligence, and then use that to solve everything else\".[207] However, as the use of AI has become widespread, several unintended consequences and risks have been identified.[208][209] In-production systems can sometimes not factor ethics and bias into their AI training processes, especially when the AI algorithms are inherently unexplainable in deep learning.[210]\\n\\nRisks and harm\\nPrivacy and copyright\\nFurther information: Information privacy and Artificial intelligence and copyright\\nMachine learning algorithms require large amounts of data. The techniques used to acquire this data have raised concerns about privacy, surveillance and copyright.\\nAI-powered devices and services, such as virtual assistants and IoT products, continuously collect personal information, raising concerns about intrusive data gathering and unauthorized access by third parties. The loss of privacy is further exacerbated by AI\\'s ability to process and combine vast amounts of data, potentially leading to a surveillance society where individual activities are constantly monitored and analyzed without adequate safeguards or transparency.\\nSensitive user data collected may include online activity records, geolocation data, video, or audio.[211] For example, in order to build speech recognition algorithms, Amazon has recorded millions of private conversations and allowed temporary workers to listen to and transcribe some of them.[212] Opinions about this widespread surveillance range from those who see it as a necessary evil to those for whom it is clearly unethical and a violation of the right to privacy.[213]\\nAI developers argue that this is the only way to deliver valuable applications and have developed several techniques that attempt to preserve privacy while still obtaining the data, such as data aggregation, de-identification and differential privacy.[214] Since 2016, some privacy experts, such as Cynthia Dwork, have begun to view privacy in terms of fairness. Brian Christian wrote that experts have pivoted \"from the question of \\'what they know\\' to the question of \\'what they\\'re doing with it\\'.\"[215]\\nGenerative AI is often trained on unlicensed copyrighted works, including in domains such as images or computer code; the output is then used under the rationale of \"fair use\". Experts disagree about how well and under what circumstances this rationale will hold up in courts of law; relevant factors may include \"the purpose and character of the use of the copyrighted work\" and \"the effect upon the potential market for the copyrighted work\".[216][217] Website owners can indicate that they do not want their content scraped via a \"robots.txt\" file.[218] However, some companies will scrape content regardless[219][220] because the robots.txt file has no real authority. In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[221][222] Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.[223]\\n\\nDominance by tech giants\\nThe commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft.[224][225][226] Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.[227][228]\\n\\nPower needs and environmental impacts\\nSee also: Environmental impacts of artificial intelligence\\nFueled by growth in artificial intelligence, data centers\\' demand for power increased in the 2020s.[229]\\nIn January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use.[230] This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.[231]\\nProdigious power consumption by AI is responsible for the growth of fossil fuel use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.[232]\\nA 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation....\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.[233] Data centers\\' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.[234]\\nIn 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for US$650 million.[235] Nvidia CEO Jensen Huang said nuclear power is a good option for the data centers.[236]\\nIn September 2024, Microsoft announced an agreement with Constellation Energy to re-open the Three Mile Island nuclear power plant to provide Microsoft with 100% of all electric power produced by the plant for 20 years. Reopening the plant, which suffered a partial nuclear meltdown of its Unit 2 reactor in 1979, will require Constellation to get through strict regulatory processes which will include extensive safety scrutiny from the US Nuclear Regulatory Commission. If approved (this will be the first ever US re-commissioning of a nuclear plant), over 835 megawatts of power – enough for 800,000 homes – of energy will be produced. The cost for re-opening and upgrading is estimated at US$1.6 billion and is dependent on tax breaks for nuclear power contained in the 2022 US Inflation Reduction Act.[237] The US government and the state of Michigan are investing almost US$2 billion to reopen the Palisades Nuclear reactor on Lake Michigan. Closed since 2022, the plant is planned to be reopened in October 2025. The Three Mile Island facility will be renamed the Crane Clean Energy Center after Chris Crane, a nuclear proponent and former CEO of Exelon who was responsible for Exelon\\'s spinoff of Constellation.[238]\\nAfter the last approval in September 2023, Taiwan suspended the approval of data centers north of Taoyuan with a capacity of more than 5 MW in 2024, due to power supply shortages.[239] Taiwan aims to phase out nuclear power by 2025.[239] On the other hand, Singapore imposed a ban on the opening of data centers in 2019 due to electric power, but in 2022, lifted this ban.[239]\\nAlthough most nuclear plants in Japan have been shut down after the 2011 Fukushima nuclear accident, according to an October 2024 Bloomberg article in Japanese, cloud gaming services company Ubitus, in which Nvidia has a stake, is looking for land in Japan near a nuclear power plant for a new data center for generative AI.[240] Ubitus CEO Wesley Kuo said nuclear power plants are the most efficient, cheap and stable power for AI.[240]\\nOn 1 November 2024, the Federal Energy Regulatory Commission (FERC) rejected an application submitted by Talen Energy for approval to supply some electricity from the nuclear power station Susquehanna to Amazon\\'s data center.[241] \\nAccording to the Commission Chairman Willie L. Phillips, it is a burden on the electricity grid as well as a significant cost shifting concern to households and other business sectors.[241]\\nIn 2025, a report prepared by the International Energy Agency estimated the greenhouse gas emissions from the energy consumption of AI at 180 million tons. By 2035, these emissions could rise to 300–500 million tonnes depending on what measures will be taken. This is below 1.5% of the energy sector emissions. The emissions reduction potential of AI was estimated at 5% of the energy sector emissions, but rebound effects (for example if people switch from public transport to autonomous cars) can reduce it.[242]\\n\\nMisinformation\\nSee also: Content moderation\\nYouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[243] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[244] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took some steps to mitigate the problem.[245]\\nIn the early 2020s, generative AI began to create images, audio, and texts that are virtually indistinguishable from real photographs, recordings, or human writing,[246] while realistic AI-generated videos became feasible in the mid-2020s.[247][248][249] It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda;[250] one such potential malicious use is deepfakes for computational propaganda.[251] AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.[252] The ability to influence electorates has been proved in at least one study. This same study shows more inaccurate statements from the models when they advocate for candidates of the political right.[253]\\nAI researchers at Microsoft, OpenAI, universities and other organisations have suggested using \"personhood credentials\" as a way to overcome online deception enabled by AI models.[254]\\n\\nAlgorithmic bias and fairness\\nMain articles: Algorithmic bias and Fairness (machine learning)\\nMachine learning applications can be biased[k] if they learn from biased data.[256] The developers may not be aware that the bias exists.[257] Discriminatory behavior by some LLMs can be observed in their output.[258] Bias can be introduced by the way training data is selected and by the way a model is deployed.[259][256] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[260] The field of fairness studies how to prevent harms from algorithmic biases.\\nOn 28 June 2015, Google Photos\\'s new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,[261] a problem called \"sample size disparity\".[262] Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.[263]\\nCOMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[264] In 2017, several researchers[l] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[266]\\nA program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".[267] Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn\\'t work.\"[268]\\nCriticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist.[269] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.[m]\\nBias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[262]\\nThere are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.[255]\\nAt the 2022 ACM Conference on Fairness, Accountability, and Transparency a paper reported that a CLIP‑based (Contrastive Language-Image Pre-training) robotic system reproduced harmful gender‑ and race‑linked stereotypes in a simulated manipulation task. The authors recommended robot‑learning methods which physically manifest such harms be “paused, reworked, or even wound down when appropriate, until outcomes can be proven safe, effective, and just.”[271][272][273]\\n\\nLack of transparency\\nSee also: Explainable AI, Algorithmic transparency, and Right to explanation\\nMany AI systems are so complex that their designers cannot explain how they reach their decisions.[274] Particularly with deep neural networks, in which there are many non-linear relationships between inputs and outputs. But some popular explainability techniques exist.[275]\\nIt is impossible to be certain that a program is operating correctly if no one knows how exactly it works. There have been many cases where a machine learning program passed rigorous tests, but nevertheless learned something different than what the programmers intended. For example, a system that could identify skin diseases better than medical professionals was found to actually have a strong tendency to classify images with a ruler as \"cancerous\", because pictures of malignancies typically include a ruler to show the scale.[276] Another machine learning system designed to help effectively allocate medical resources was found to classify patients with asthma as being at \"low risk\" of dying from pneumonia. Having asthma is actually a severe risk factor, but since the patients having asthma would usually get much more medical care, they were relatively unlikely to die according to the training data. The correlation between asthma and low risk of dying from pneumonia was real, but misleading.[277]\\nPeople who have been harmed by an algorithm\\'s decision have a right to an explanation.[278] Doctors, for example, are expected to clearly and completely explain to their colleagues the reasoning behind any decision they make. Early drafts of the European Union\\'s General Data Protection Regulation in 2016 included an explicit statement that this right exists.[n] Industry experts noted that this is an unsolved problem with no solution in sight. Regulators argued that nevertheless the harm is real: if the problem has no solution, the tools should not be used.[279]\\nDARPA established the XAI (\"Explainable Artificial Intelligence\") program in 2014 to try to solve these problems.[280]\\nSeveral approaches aim to address the transparency problem. SHAP enables to visualise the contribution of each feature to the output.[281] LIME can locally approximate a model\\'s outputs with a simpler, interpretable model.[282] Multitask learning provides a large number of outputs in addition to the target classification. These other outputs can help developers deduce what the network has learned.[283] Deconvolution, DeepDream and other generative methods can allow developers to see what different layers of a deep network for computer vision have learned, and produce output that can suggest what the network is learning.[284] For generative pre-trained transformers, Anthropic developed a technique based on dictionary learning that associates patterns of neuron activations with human-understandable concepts.[285]\\n\\nBad actors and weaponized AI\\nMain articles: Lethal autonomous weapon, Artificial intelligence arms race, and AI safety\\nArtificial intelligence provides a number of tools that are useful to bad actors, such as authoritarian governments, terrorists, criminals or rogue states.\\nA lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.[o] Widely available AI tools can be used by bad actors to develop inexpensive autonomous weapons and, if produced at scale, they are potentially weapons of mass destruction.[287] Even when used in conventional warfare, they currently cannot reliably choose targets and could potentially kill an innocent person.[287] In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations\\' Convention on Certain Conventional Weapons, however the United States and others disagreed.[288] By 2015, over fifty countries were reported to be researching battlefield robots.[289]\\nAI tools make it easier for authoritarian governments to efficiently control their citizens in several ways. Face and voice recognition allow widespread surveillance. Machine learning, operating this data, can classify potential enemies of the state and prevent them from hiding. Recommendation systems can precisely target propaganda and misinformation for maximum effect. Deepfakes and generative AI aid in producing misinformation. Advanced AI can make authoritarian centralized decision-making more competitive than liberal and decentralized systems such as markets. It lowers the cost and difficulty of digital warfare and advanced spyware.[290] All these technologies have been available since 2020 or earlier—AI facial recognition systems are already being used for mass surveillance in China.[291][292]\\nThere are many other ways in which AI is expected to help bad actors, some of which can not be foreseen. For example, machine-learning AI is able to design tens of thousands of toxic molecules in a matter of hours.[293]\\n\\nTechnological unemployment\\nMain articles: Workplace impact of artificial intelligence and Technological unemployment\\nEconomists have frequently highlighted the risks of redundancies from AI, and speculated about unemployment if there is no adequate social policy for full employment.[294]\\nIn the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that \"we\\'re in uncharted territory\" with AI.[295] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[296] Risk estimates vary; for example, in the 2010s, Michael Osborne and Carl Benedikt Frey estimated 47% of U.S. jobs are at \"high risk\" of potential automation, while an OECD report classified only 9% of U.S. jobs as \"high risk\".[p][298] The methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.[294] In April 2023, it was reported that 70% of the jobs for Chinese video game illustrators had been eliminated by generative artificial intelligence.[299][300]\\nUnlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist stated in 2015 that \"the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution\" is \"worth taking seriously\".[301] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[302] In July 2025, Ford CEO Jim Farley predicted that \"artificial intelligence is going to replace literally half of all white-collar workers in the U.S.\"[303]\\nFrom the early days of the development of artificial intelligence, there have been arguments, for example, those put forward by Joseph Weizenbaum, about whether tasks that can be done by computers actually should be done by them, given the difference between computers and humans, and between quantitative calculation and qualitative, value-based judgement.[304]\\n\\nExistential risk\\nMain article: Existential risk from artificial intelligence\\nIt has been argued AI will become so powerful that humanity may irreversibly lose control of it. This could, as physicist Stephen Hawking stated, \"spell the end of the human race\".[305] This scenario has been common in science fiction, when a computer or robot suddenly develops a human-like \"self-awareness\" (or \"sentience\" or \"consciousness\") and becomes a malevolent character.[q] These sci-fi scenarios are misleading in several ways.\\nFirst, AI does not require human-like sentience to be an existential risk. Modern AI programs are given specific goals and use learning and intelligence to achieve them. Philosopher Nick Bostrom argued that if one gives almost any goal to a sufficiently powerful AI, it may choose to destroy humanity to achieve it (he used the example of an automated paperclip factory that destroys the world to get more iron for paperclips).[307] Stuart Russell gives the example of household robot that tries to find a way to kill its owner to prevent it from being unplugged, reasoning that \"you can\\'t fetch the coffee if you\\'re dead.\"[308] In order to be safe for humanity, a superintelligence would have to be genuinely aligned with humanity\\'s morality and values so that it is \"fundamentally on our side\".[309]\\nSecond, Yuval Noah Harari argues that AI does not require a robot body or physical control to pose an existential risk. The essential parts of civilization are not physical. Things like ideologies, law, government, money and the economy are built on language; they exist because there are stories that billions of people believe. The current prevalence of misinformation suggests that an AI could use language to convince people to believe anything, even to take actions that are destructive.[310] Geoffrey Hinton said in 2025 that modern AI is particularly \"good at persuasion\" and getting better all the time. He asks \"Suppose you wanted to invade the capital of the US. Do you have to go there and do it yourself? No. You just have to be good at persuasion.\"[311]\\nThe opinions amongst experts and industry insiders are mixed, with sizable fractions both concerned and unconcerned by risk from eventual superintelligent AI.[312] Personalities such as Stephen Hawking, Bill Gates, and Elon Musk,[313] as well as AI pioneers such as Yoshua Bengio, Stuart Russell, Demis Hassabis, and Sam Altman, have expressed concerns about existential risk from AI.\\nIn May 2023, Geoffrey Hinton announced his resignation from Google in order to be able to \"freely speak out about the risks of AI\" without \"considering how this impacts Google\".[314] He notably mentioned risks of an AI takeover,[315] and stressed that in order to avoid the worst outcomes, establishing safety guidelines will require cooperation among those competing in use of AI.[316]\\nIn 2023, many leading AI experts endorsed the joint statement that \"Mitigating the risk of extinction from AI should be a global priority alongside other societal-scale risks such as pandemics and nuclear war\".[317]\\nSome other researchers were more optimistic. AI pioneer Jürgen Schmidhuber did not sign the joint statement, emphasising that in 95% of all cases, AI research is about making \"human lives longer and healthier and easier.\"[318] While the tools that are now being used to improve lives can also be used by bad actors, \"they can also be used against the bad actors.\"[319][320] Andrew Ng also argued that \"it\\'s a mistake to fall for the doomsday hype on AI—and that regulators who do will only benefit vested interests.\"[321] Yann LeCun \"scoffs at his peers\\' dystopian scenarios of supercharged misinformation and even, eventually, human extinction.\"[322] In the early 2010s, experts argued that the risks are too distant in the future to warrant research or that humans will be valuable from the perspective of a superintelligent machine.[323] However, after 2016, the study of current and future risks and possible solutions became a serious area of research.[324]\\n\\nEthical machines and alignment\\nMain articles: Machine ethics, AI safety, Friendly artificial intelligence, Artificial moral agents, and Human Compatible\\nSee also: Human-AI interaction\\nFriendly AI are machines that have been designed from the beginning to minimize risks and to make choices that benefit humans. Eliezer Yudkowsky, who coined the term, argues that developing friendly AI should be a higher research priority: it may require a large investment and it must be completed before AI becomes an existential risk.[325]\\nMachines with intelligence have the potential to use their intelligence to make ethical decisions. The field of machine ethics provides machines with ethical principles and procedures for resolving ethical dilemmas.[326]\\nThe field of machine ethics is also called computational morality,[326]\\nand was founded at an AAAI symposium in 2005.[327]\\nOther approaches include Wendell Wallach\\'s \"artificial moral agents\"[328] and Stuart J. Russell\\'s three principles for developing provably beneficial machines.[329]\\n\\nOpen source\\nSee also: Open-source artificial intelligence and Lists of open-source artificial intelligence software\\nActive organizations in the AI open-source community include Hugging Face,[330] Google,[331] EleutherAI and Meta.[332] Various AI models, such as Llama 2, Mistral or Stable Diffusion, have been made open-weight,[333][334] meaning that their architecture and trained parameters (the \"weights\") are publicly available. Open-weight models can be freely fine-tuned, which allows companies to specialize them with their own data and for their own use-case.[335] Open-weight models are useful for research and innovation but can also be misused. Since they can be fine-tuned, any built-in security measure, such as objecting to harmful requests, can be trained away until it becomes ineffective. Some researchers warn that future AI models may develop dangerous capabilities (such as the potential to drastically facilitate bioterrorism) and that once released on the Internet, they cannot be deleted everywhere if needed. They recommend pre-release audits and cost-benefit analyses.[336]\\n\\nFrameworks\\nArtificial intelligence projects can be guided by ethical considerations during the design, development, and implementation of an AI system. An AI framework such as the Care and Act Framework, developed by the Alan Turing Institute and based on the SUM values, outlines four main ethical dimensions, defined as follows:[337][338]\\n\\nRespect the dignity of individual people\\nConnect with other people sincerely, openly, and inclusively\\nCare for the wellbeing of everyone\\nProtect social values, justice, and the public interest\\nOther developments in ethical frameworks include those decided upon during the Asilomar Conference, the Montreal Declaration for Responsible AI, and the IEEE\\'s Ethics of Autonomous Systems initiative, among others;[339] however, these principles are not without criticism, especially regarding the people chosen to contribute to these frameworks.[340]\\nPromotion of the wellbeing of the people and communities that these technologies affect requires consideration of the social and ethical implications at all stages of AI system design, development and implementation, and collaboration between job roles such as data scientists, product managers, data engineers, domain experts, and delivery managers.[341]\\nThe UK AI Safety Institute released in 2024 a testing toolset called \\'Inspect\\' for AI safety evaluations available under an MIT open-source licence which is freely available on GitHub and can be improved with third-party packages. It can be used to evaluate AI models in a range of areas including core knowledge, ability to reason, and autonomous capabilities.[342]\\n\\nRegulation\\nMain articles: Regulation of artificial intelligence, Regulation of algorithms, and AI safety\\nThe first global AI Safety Summit was held in the United Kingdom in November 2023 with a declaration calling for international cooperation.\\nThe regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating AI; it is therefore related to the broader regulation of algorithms.[343] The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally.[344] According to AI Index at Stanford, the annual number of AI-related laws passed in the 127 survey countries jumped from one passed in 2016 to 37 passed in 2022 alone.[345][346] Between 2016 and 2020, more than 30 countries adopted dedicated strategies for AI.[347] Most EU member states had released national AI strategies, as had Canada, China, India, Japan, Mauritius, the Russian Federation, Saudi Arabia, United Arab Emirates, U.S., and Vietnam. Others were in the process of elaborating their own AI strategy, including Bangladesh, Malaysia and Tunisia.[347] The Global Partnership on Artificial Intelligence was launched in June 2020, stating a need for AI to be developed in accordance with human rights and democratic values, to ensure public confidence and trust in the technology.[347] Henry Kissinger, Eric Schmidt, and Daniel Huttenlocher published a joint statement in November 2021 calling for a government commission to regulate AI.[348] In 2023, OpenAI leaders published recommendations for the governance of superintelligence, which they believe may happen in less than 10 years.[349] In 2023, the United Nations also launched an advisory body to provide recommendations on AI governance; the body comprises technology company executives, government officials and academics.[350] On 1 August 2024, the EU Artificial Intelligence Act entered into force, establishing the first comprehensive EU-wide AI regulation.[351] In 2024, the Council of Europe created the first international legally binding treaty on AI, called the \"Framework Convention on Artificial Intelligence and Human Rights, Democracy and the Rule of Law\". It was adopted by the European Union, the United States, the United Kingdom, and other signatories.[352]\\nIn a 2022 Ipsos survey, attitudes towards AI varied greatly by country; 78% of Chinese citizens, but only 35% of Americans, agreed that \"products and services using AI have more benefits than drawbacks\".[345] A 2023 Reuters/Ipsos poll found that 61% of Americans agree, and 22% disagree, that AI poses risks to humanity.[353] In a 2023 Fox News poll, 35% of Americans thought it \"very important\", and an additional 41% thought it \"somewhat important\", for the federal government to regulate AI, versus 13% responding \"not very important\" and 8% responding \"not at all important\".[354][355]\\nIn November 2023, the first global AI Safety Summit was held in Bletchley Park in the UK to discuss the near and far term risks of AI and the possibility of mandatory and voluntary regulatory frameworks.[356] 28 countries including the United States, China, and the European Union issued a declaration at the start of the summit, calling for international co-operation to manage the challenges and risks of artificial intelligence.[357][358] In May 2024 at the AI Seoul Summit, 16 global AI tech companies agreed to safety commitments on the development of AI.[359][360]\\n\\nHistory\\nMain article: History of artificial intelligence\\nFor a chronological guide, see Timeline of artificial intelligence.\\nIn 2024, AI patents in China and the US numbered more than three-fourths of AI patents worldwide.[361] Though China had more AI patents, the US had 35% more patents per AI patent-applicant company than China.[361]\\nThe study of mechanical or \"formal\" reasoning began with philosophers and mathematicians in antiquity. The study of logic led directly to Alan Turing\\'s theory of computation, which suggested that a machine, by shuffling symbols as simple as \"0\" and \"1\", could simulate any conceivable form of mathematical reasoning.[362][363] This, along with concurrent discoveries in cybernetics, information theory and neurobiology, led researchers to consider the possibility of building an \"electronic brain\".[r] They developed several areas of research that would become part of AI,[365] such as McCulloch and Pitts design for \"artificial neurons\" in 1943,[117] and Turing\\'s influential 1950 paper \\'Computing Machinery and Intelligence\\', which introduced the Turing test and showed that \"machine intelligence\" was plausible.[366][363]\\nThe field of AI research was founded at a workshop at Dartmouth College in 1956.[s][6] The attendees became the leaders of AI research in the 1960s.[t] They and their students produced programs that the press described as \"astonishing\":[u] computers were learning checkers strategies, solving word problems in algebra, proving logical theorems and speaking English.[v][7] Artificial intelligence laboratories were set up at a number of British and U.S. universities in the latter 1950s and early 1960s.[363]\\nResearchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field.[370] In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".[371] In 1967 Marvin Minsky agreed, writing that \"within a generation\\xa0... the problem of creating \\'artificial intelligence\\' will substantially be solved\".[372] They had, however, underestimated the difficulty of the problem.[w] In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[374] and ongoing pressure from the U.S. Congress to fund more productive projects.[375] Minsky and Papert\\'s book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether.[376] The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.[9]\\nIn the early 1980s, AI research was revived by the commercial success of expert systems,[377] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan\\'s fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[8] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[10]\\nUp to this point, most of AI\\'s funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition,[378] and began to look into \"sub-symbolic\" approaches.[379] Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive.[x] Judea Pearl, Lotfi Zadeh, and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[87][384] But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others.[385] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[386]\\nAI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[387] By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\" (a tendency known as the AI effect).[388]\\nHowever, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.[68]\\nDeep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[11]\\nFor many specific tasks, other methods were abandoned.[y]\\nDeep learning\\'s success was based on both hardware improvements (faster computers,[390] graphics processing units, cloud computing[391]) and access to large amounts of data[392] (including curated datasets,[391] such as ImageNet). Deep learning\\'s success led to an enormous increase in interest and funding in AI.[z] The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.[347]\\n\\nThe number of Google searches for the term \"AI\" accelerated in 2022.\\nIn 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[324]\\nIn the late 2010s and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program taught only the game\\'s rules and developed a strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text.[393] ChatGPT, launched on 30 November 2022, became the fastest-growing consumer software application in history, gaining over 100 million users in two months.[394] It marked what is widely regarded as AI\\'s breakout year, bringing it into the public consciousness.[395] These programs, and others, inspired an aggressive AI boom, where large companies began investing billions of dollars in AI research. According to AI Impacts, about US$50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".[396] About 800,000 \"AI\"-related U.S. job openings existed in 2022.[397] According to PitchBook research, 22% of newly funded startups in 2024 claimed to be AI companies.[398]\\n\\nPhilosophy\\nMain article: Philosophy of artificial intelligence\\nPhilosophical debates have historically sought to determine the nature of intelligence and how to make intelligent machines.[399] Another major focus has been whether machines can be conscious, and the associated ethical implications.[400] Many other topics in philosophy are relevant to AI, such as epistemology and free will.[401] Rapid advancements have intensified public discussions on the philosophy and ethics of AI.[400]\\n\\nDefining artificial intelligence\\nSee also: Synthetic intelligence, Intelligent agent, Artificial mind, Virtual intelligence, and Dartmouth workshop\\nAlan Turing wrote in 1950 \"I propose to consider the question \\'can machines think\\'?\"[402] He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".[402] He devised the Turing test, which measures the ability of a machine to simulate human conversation.[366] Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks.\"[403]\\n\\nThe Turing test can provide some evidence of intelligence, but it penalizes non-human intelligent behavior.[404]\\nRussell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure.[1] However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts\", they wrote, \"do not define the goal of their field as making \\'machines that fly so exactly like pigeons that they can fool other pigeons.\\'\"[405] AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".[406]\\nMcCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".[407] Another AI founder, Marvin Minsky, similarly describes it as \"the ability to solve hard problems\".[408] The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.[1] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine – and no other philosophical discussion is required, or may not even be possible.\\nAnother definition has been adopted by Google,[409] a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\\nAs a result of the many circulating definitions scholars have started to critically analyze and order the AI discourse itself[410] including discussing the many AI narratives and myths to be found within societal, political and academic discourses.[411] Similarly, in practice, some authors have suggested that the term \\'AI\\' is often used too broadly and vaguely. This raises the question of where the line should be drawn between AI and classical algorithms,[412] with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".[413]\\nThere has been debate over whether large language models exhibit genuine intelligence or merely simulate it by imitating human text.[414]\\n\\nEvaluating approaches to AI\\nNo established unifying theory or paradigm has guided AI research for most of its history.[aa] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\\n\\nSymbolic AI and its limits\\nSymbolic AI (or \"GOFAI\")[416] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests. In the 1960s, Newell and Simon proposed the physical symbol systems hypothesis: \"A physical symbol system has the necessary and sufficient means of general intelligent action.\"[417]\\nHowever, the symbolic approach failed on many tasks that humans solve easily, such as learning, recognizing an object or commonsense reasoning. Moravec\\'s paradox is the discovery that high-level \"intelligent\" tasks were easy for AI, but low level \"instinctive\" tasks were extremely difficult.[418] Philosopher Hubert Dreyfus had argued since the 1960s that human expertise depends on unconscious instinct rather than conscious symbol manipulation, and on having a \"feel\" for the situation, rather than explicit symbolic knowledge.[419] Although his arguments had been ridiculed and ignored when they were first presented, eventually, AI research came to agree with him.[ab][16]\\nThe issue is not resolved: sub-symbolic reasoning can make many of the same inscrutable mistakes that human intuition does, such as algorithmic bias. Critics such as Noam Chomsky argue continuing research into symbolic AI will still be necessary to attain general intelligence,[421][422] in part because sub-symbolic AI is a move away from explainable AI: it can be difficult or impossible to understand why a modern statistical AI program made a particular decision. The emerging field of neuro-symbolic artificial intelligence attempts to bridge the two approaches.\\n\\nNeat vs. scruffy\\nMain article: Neats and scruffies\\n\"Neats\" hope that intelligent behavior is described using simple, elegant principles (such as logic, optimization, or neural networks). \"Scruffies\" expect that it necessarily requires solving a large number of unrelated problems. Neats defend their programs with theoretical rigor, scruffies rely mainly on incremental testing to see if they work. This issue was actively discussed in the 1970s and 1980s,[423] but eventually was seen as irrelevant. Modern AI has elements of both.\\n\\nSoft vs. hard computing\\nMain article: Soft computing\\nFinding a provably correct or optimal solution is intractable for many important problems.[15] Soft computing is a set of techniques, including genetic algorithms, fuzzy logic and neural networks, that are tolerant of imprecision, uncertainty, partial truth and approximation. Soft computing was introduced in the late 1980s and most successful AI programs in the 21st century are examples of soft computing with neural networks.\\n\\nNarrow vs. general AI\\nMain articles: Weak artificial intelligence and Artificial general intelligence\\nAI researchers are divided as to whether to pursue the goals of artificial general intelligence and superintelligence directly or to solve as many specific problems as possible (narrow AI) in hopes these solutions will lead indirectly to the field\\'s long-term goals.[424][425] General intelligence is difficult to define and difficult to measure, and modern AI has had more verifiable successes by focusing on specific problems with specific solutions. The sub-field of artificial general intelligence studies this area exclusively.\\n\\nMachine consciousness, sentience, and mind\\nMain articles: Philosophy of artificial intelligence and Artificial consciousness\\nThere is no settled consensus in philosophy of mind on whether a machine can have a mind, consciousness and mental states in the same sense that human beings do. This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"[426] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\\n\\nConsciousness\\nMain articles: Hard problem of consciousness and Theory of mind\\nDavid Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.[427] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett\\'s consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[428]\\n\\nComputationalism and functionalism\\nMain articles: Computational theory of mind and Functionalism (philosophy of mind)\\nComputationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[429]\\nPhilosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"[ac] Searle challenges this claim with his Chinese room argument, which attempts to show that even a computer capable of perfectly simulating human behavior would not have a mind.[433]\\n\\nAI welfare and rights\\nIt is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree.[434] But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.[435][436] Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights.[435] Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.[437]\\nIn 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.[438] Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part in society on their own.[439][440]\\nProgress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.[436][435]\\n\\nFuture\\nSuperintelligence and the singularity\\nA superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[425] If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".[441]\\nHowever, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[442]\\n\\nTranshumanism\\nMain article: Transhumanism\\nRobot designer Hans Moravec, cyberneticist Kevin Warwick and inventor Ray Kurzweil have predicted that humans and machines may merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in the writings of Aldous Huxley and Robert Ettinger.[443]\\nEdward Fredkin argues that \"artificial intelligence is the next step in evolution\", an idea first proposed by Samuel Butler\\'s \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.[444]\\n\\nIn fiction\\nMain article: Artificial intelligence in fiction\\nThe word \"robot\" itself was coined by Karel Čapek in his 1921 play R.U.R., the title standing for \"Rossum\\'s Universal Robots\".\\nThought-capable artificial beings have appeared as storytelling devices since antiquity,[445] and have been a persistent theme in science fiction.[446]\\nA common trope in these works began with Mary Shelley\\'s Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke\\'s and Stanley Kubrick\\'s 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[447]\\nIsaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov\\'s laws are often brought up during lay discussions of machine ethics;[448] while almost all artificial intelligence researchers are familiar with Asimov\\'s laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[449]\\nSeveral works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek\\'s R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.[450]\\n\\nSee also\\nArtificial consciousness\\xa0– Field in cognitive science\\nArtificial intelligence and elections\\xa0– Impact of AI on political elections\\nArtificial intelligence content detection\\xa0– Software to detect AI-generated content\\nArtificial intelligence in Wikimedia projects – Use of artificial intelligence to develop Wikipedia and other Wikimedia projects\\nAssociation for the Advancement of Artificial Intelligence (AAAI)\\nBehavior selection algorithm\\xa0– Algorithm that selects actions for intelligent agents\\nBusiness process automation\\xa0– Automation of business processes\\nCase-based reasoning\\xa0– Process of solving new problems based on the solutions of similar past problems\\nComputational intelligence\\xa0– Ability of a computer to learn a specific task from data or experimental observation\\nDARWIN EU – A European Union initiative coordinated by the European Medicines Agency (EMA) to generate and utilize real world evidence (RWE) to support the evaluation and supervision of medicines across the EU\\nDigital immortality\\xa0– Hypothetical concept of storing a personality in digital form\\nEmergent algorithm\\xa0– Algorithm exhibiting emergent behavior\\nFemale gendering of AI technologies\\xa0– Gender biases in digital technologyPages displaying short descriptions of redirect targets\\nGlossary of artificial intelligence\\xa0– List of concepts in artificial intelligence\\nIntelligence amplification\\xa0– Use of information technology to augment human intelligence\\nIntelligent agent\\xa0– Software agent which acts autonomously\\nIntelligent automation\\xa0– Software process that combines robotic process automation and artificial intelligence\\nList of artificial intelligence books\\nList of artificial intelligence journals\\nList of artificial intelligence projects\\nMind uploading\\xa0– Hypothetical process of digitally emulating a brain\\nOrganoid intelligence – Use of brain cells and brain organoids for intelligent computing\\nPseudorandomness\\xa0– Appearing random but actually being generated by a deterministic, causal process\\nRobotic process automation\\xa0– Form of business process automation technology\\nThe Last Day\\xa0– 1967 Welsh science fiction novel\\nWetware computer\\xa0– Computer composed of organic material\\nExplanatory notes\\n\\n\\n^ a b This list of intelligent traits is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2021), Luger & Stubblefield (2004), Poole, Mackworth & Goebel (1998) and Nilsson (1998)\\n\\n^ a b This list of tools is based on the topics covered by the major AI textbooks, including: Russell & Norvig (2021), Luger & Stubblefield (2004), Poole, Mackworth & Goebel (1998) and Nilsson (1998)\\n\\n^ It is among the reasons that expert systems proved to be inefficient for capturing knowledge.[30][31]\\n\\n^ \\n\"Rational agent\" is general term used in economics, philosophy and theoretical artificial intelligence. It can refer to anything that directs its behavior to accomplish goals, such as a person, an animal, a corporation, a nation, or in the case of AI, a computer program.\\n\\n^ Alan Turing discussed the centrality of learning as early as 1950, in his classic paper \"Computing Machinery and Intelligence\".[42] In 1956, at the original Dartmouth AI summer conference, Ray Solomonoff wrote a report on unsupervised probabilistic machine learning: \"An Inductive Inference Machine\".[43]\\n\\n^ See AI winter §\\xa0Machine translation and the ALPAC report of 1966.\\n\\n^ \\nCompared with symbolic logic, formal Bayesian inference is computationally expensive. For inference to be tractable, most observations must be conditionally independent of one another. AdSense uses a Bayesian network with over 300\\xa0million edges to learn which ads to serve.[94]\\n\\n^ Expectation–maximization, one of the most popular algorithms in machine learning, allows clustering in the presence of unknown latent variables.[96]\\n\\n^ \\nSome form of deep neural networks (without a specific learning algorithm) were described by:\\nWarren S. McCulloch and Walter Pitts (1943)[117]\\nAlan Turing (1948);[118]\\nKarl Steinbuch and Roger David Joseph (1961).[119]\\nDeep or recurrent networks that learned (or used gradient descent) were developed by:\\nFrank Rosenblatt(1957);[118]\\nOliver Selfridge (1959);[119]\\nAlexey Ivakhnenko and Valentin Lapa (1965);[120]\\nKaoru Nakano (1971);[121]\\nShun-Ichi Amari (1972);[121]\\nJohn Joseph Hopfield (1982).[121]\\nPrecursors to backpropagation were developed by:\\nHenry J. Kelley (1960);[118]\\nArthur E. Bryson (1962);[118]\\nStuart Dreyfus (1962);[118]\\nArthur E. Bryson and Yu-Chi Ho (1969);[118]\\nBackpropagation was independently developed by:\\nSeppo Linnainmaa (1970);[122]\\nPaul Werbos (1974).[118]\\n\\n^ Geoffrey Hinton said, of his work on neural networks in the 1990s, \"our labeled datasets were thousands of times too small. [And] our computers were millions of times too slow.\"[123]\\n\\n^ In statistics, a bias is a systematic error or deviation from the correct value. But in the context of fairness, it refers to a tendency in favor or against a certain group or individual characteristic, usually in a way that is considered unfair or harmful. A statistically unbiased AI system that produces disparate outcomes for different demographic groups may thus be viewed as biased in the ethical sense.[255]\\n\\n^ Including Jon Kleinberg (Cornell University), Sendhil Mullainathan (University of Chicago), Cynthia Chouldechova (Carnegie Mellon) and Sam Corbett-Davis (Stanford)[265]\\n\\n^ Moritz Hardt (a director at the Max Planck Institute for Intelligent Systems) argues that machine learning \"is fundamentally the wrong tool for a lot of domains, where you\\'re trying to design interventions and mechanisms that change the world.\"[270]\\n\\n^ When the law was passed in 2018, it still contained a form of this provision.\\n\\n^ This is the United Nations\\' definition, and includes things like land mines as well.[286]\\n\\n^ See table 4; 9% is both the OECD average and the U.S. average.[297]\\n\\n^ Sometimes called a \"robopocalypse\"[306]\\n\\n^ \"Electronic brain\" was the term used by the press around this time.[362][364]\\n\\n^ \\nDaniel Crevier wrote, \"the conference is generally recognized as the official birthdate of the new science.\"[367] Russell and Norvig called the conference \"the inception of artificial intelligence.\"[117]\\n\\n^ \\nRussell and Norvig wrote \"for the next 20 years the field would be dominated by these people and their students.\"[368]\\n\\n^ \\nRussell and Norvig wrote, \"it was astonishing whenever a computer did anything kind of smartish\".[369]\\n\\n^ \\nThe programs described are Arthur Samuel\\'s checkers program for the IBM 701, Daniel Bobrow\\'s STUDENT, Newell and Simon\\'s Logic Theorist and Terry Winograd\\'s SHRDLU.\\n\\n^ Russell and Norvig write: \"in almost all cases, these early systems failed on more difficult problems\"[373]\\n\\n^ \\nEmbodied approaches to AI[380] were championed by Hans Moravec[381] and Rodney Brooks[382] and went by many names: Nouvelle AI.[382] Developmental robotics.[383]\\n\\n^ Matteo Wong wrote in The Atlantic: \"Whereas for decades, computer-science fields such as natural-language processing, computer vision, and robotics used extremely different methods, now they all use a programming method called \"deep learning\". As a result, their code and approaches have become more similar, and their models are easier to integrate into one another.\"[389]\\n\\n^ Jack Clark wrote in Bloomberg: \"After a half-decade of quiet breakthroughs in artificial intelligence, 2015 has been a landmark year. Computers are smarter and learning faster than ever\", and noted that the number of software projects that use machine learning at Google increased from a \"sporadic usage\" in 2012 to more than 2,700 projects in 2015.[391]\\n\\n^ Nils Nilsson wrote in 1983: \"Simply put, there is wide disagreement in the field about what AI is all about.\"[415]\\n\\n^ \\nDaniel Crevier wrote that \"time has proven the accuracy and perceptiveness of some of Dreyfus\\'s comments. Had he formulated them less aggressively, constructive actions they suggested might have been taken much earlier.\"[420]\\n\\n^ \\nSearle presented this definition of \"Strong AI\" in 1999.[430] Searle\\'s original formulation was \"The appropriately programmed computer really is a mind, in the sense that computers given the right programs can be literally said to understand and have other cognitive states.\"[431] Strong AI is defined similarly by Russell and Norvig: \"Stong AI – the assertion that machines that do so are actually thinking (as opposed to simulating thinking).\"[432]\\n\\n\\nReferences\\n\\n^ a b c Russell & Norvig (2021), pp.\\xa01–4.\\n\\n^ AI set to exceed human brain power Archived 19 February 2008 at the Wayback Machine CNN.com (26 July 2006)\\n\\n^ Kaplan, Andreas; Haenlein, Michael (2019). \"Siri, Siri, in my hand: Who\\'s the fairest in the land? On the interpretations, illustrations, and implications of artificial intelligence\". Business Horizons. 62: 15–25. doi:10.1016/j.bushor.2018.08.004. [the question of the source is a pastiche of: Snow White]\\n\\n^ Russell & Norvig (2021, §1.2).\\n\\n^ \"Tech companies want to build artificial general intelligence. But who decides when AGI is attained?\". AP News. 4 April 2024. Retrieved 20 May 2025.\\n\\n^ a b Dartmouth workshop: Russell & Norvig (2021, p.\\xa018), McCorduck (2004, pp.\\xa0111–136), NRC (1999, pp.\\xa0200–201)The proposal: McCarthy et al. (1955)\\n\\n^ a b Successful programs of the 1960s: McCorduck (2004, pp.\\xa0243–252), Crevier (1993, pp.\\xa052–107), Moravec (1988, p.\\xa09), Russell & Norvig (2021, pp.\\xa019–21)\\n\\n^ a b Funding initiatives in the early 1980s: Fifth Generation Project (Japan), Alvey (UK), Microelectronics and Computer Technology Corporation (US), Strategic Computing Initiative (US): McCorduck (2004, pp.\\xa0426–441), Crevier (1993, pp.\\xa0161–162, 197–203, 211, 240), Russell & Norvig (2021, p.\\xa023), NRC (1999, pp.\\xa0210–211), Newquist (1994, pp.\\xa0235–248)\\n\\n^ a b First AI Winter, Lighthill report, Mansfield Amendment: Crevier (1993, pp.\\xa0115–117), Russell & Norvig (2021, pp.\\xa021–22), NRC (1999, pp.\\xa0212–213), Howe (1994), Newquist (1994, pp.\\xa0189–201)\\n\\n^ a b Second AI Winter: Russell & Norvig (2021, p.\\xa024), McCorduck (2004, pp.\\xa0430–435), Crevier (1993, pp.\\xa0209–210), NRC (1999, pp.\\xa0214–216), Newquist (1994, pp.\\xa0301–318)\\n\\n^ a b Deep learning revolution, AlexNet: Goldman (2022), Russell & Norvig (2021, p.\\xa026), McKinsey (2018)\\n\\n^ Toews (2023).\\n\\n^ Problem-solving, puzzle solving, game playing, and deduction: Russell & Norvig (2021, chpt. 3–5), Russell & Norvig (2021, chpt. 6) (constraint satisfaction), Poole, Mackworth & Goebel (1998, chpt. 2, 3, 7, 9), Luger & Stubblefield (2004, chpt. 3, 4, 6, 8), Nilsson (1998, chpt. 7–12)\\n\\n^ Uncertain reasoning: Russell & Norvig (2021, chpt. 12–18), Poole, Mackworth & Goebel (1998, pp.\\xa0345–395), Luger & Stubblefield (2004, pp.\\xa0333–381), Nilsson (1998, chpt. 7–12)\\n\\n^ a b c Intractability and efficiency and the combinatorial explosion: Russell & Norvig (2021, p.\\xa021)\\n\\n^ a b c Psychological evidence of the prevalence of sub-symbolic reasoning and knowledge: Kahneman (2011), Dreyfus & Dreyfus (1986), Wason & Shapiro (1966), Kahneman, Slovic & Tversky (1982)\\n\\n^ Knowledge representation and knowledge engineering: Russell & Norvig (2021, chpt. 10), Poole, Mackworth & Goebel (1998, pp.\\xa023–46, 69–81, 169–233, 235–277, 281–298, 319–345), Luger & Stubblefield (2004, pp.\\xa0227–243), Nilsson (1998, chpt. 17.1–17.4, 18)\\n\\n^ Smoliar & Zhang (1994).\\n\\n^ Neumann & Möller (2008).\\n\\n^ Kuperman, Reichley & Bailey (2006).\\n\\n^ McGarry (2005).\\n\\n^ Bertini, Del Bimbo & Torniai (2006).\\n\\n^ Russell & Norvig (2021), pp.\\xa0272.\\n\\n^ Representing categories and relations: Semantic networks, description logics, inheritance (including frames, and scripts): Russell & Norvig (2021, §10.2 & 10.5), Poole, Mackworth & Goebel (1998, pp.\\xa0174–177), Luger & Stubblefield (2004, pp.\\xa0248–258), Nilsson (1998, chpt. 18.3)\\n\\n^ Representing events and time:Situation calculus, event calculus, fluent calculus (including solving the frame problem): Russell & Norvig (2021, §10.3), Poole, Mackworth & Goebel (1998, pp.\\xa0281–298), Nilsson (1998, chpt. 18.2)\\n\\n^ Causal calculus: Poole, Mackworth & Goebel (1998, pp.\\xa0335–337)\\n\\n^ Representing knowledge about knowledge: Belief calculus, modal logics: Russell & Norvig (2021, §10.4), Poole, Mackworth & Goebel (1998, pp.\\xa0275–277)\\n\\n^ a b Default reasoning, Frame problem, default logic, non-monotonic logics, circumscription, closed world assumption, abduction: Russell & Norvig (2021, §10.6), Poole, Mackworth & Goebel (1998, pp.\\xa0248–256, 323–335), Luger & Stubblefield (2004, pp.\\xa0335–363), Nilsson (1998, ~18.3.3)\\n(Poole et al. places abduction under \"default reasoning\". Luger et al. places this under \"uncertain reasoning\").\\n\\n^ a b Breadth of commonsense knowledge: Lenat & Guha (1989, Introduction), Crevier (1993, pp.\\xa0113–114), Moravec (1988, p.\\xa013), Russell & Norvig (2021, pp.\\xa0241, 385, 982) (qualification problem)\\n\\n^ Newquist (1994), p.\\xa0296.\\n\\n^ Crevier (1993), pp.\\xa0204–208.\\n\\n^ Russell & Norvig (2021), p.\\xa0528.\\n\\n^ Automated planning: Russell & Norvig (2021, chpt. 11).\\n\\n^ Automated decision making, Decision theory: Russell & Norvig (2021, chpt. 16–18).\\n\\n^ Classical planning: Russell & Norvig (2021, Section 11.2).\\n\\n^ Sensorless or \"conformant\" planning, contingent planning, replanning (a.k.a. online planning): Russell & Norvig (2021, Section 11.5).\\n\\n^ Uncertain preferences: Russell & Norvig (2021, Section 16.7)\\nInverse reinforcement learning: Russell & Norvig (2021, Section 22.6)\\n\\n^ Information value theory: Russell & Norvig (2021, Section 16.6).\\n\\n^ Markov decision process: Russell & Norvig (2021, chpt. 17).\\n\\n^ Game theory and multi-agent decision theory: Russell & Norvig (2021, chpt. 18).\\n\\n^ Learning: Russell & Norvig (2021, chpt. 19–22), Poole, Mackworth & Goebel (1998, pp.\\xa0397–438), Luger & Stubblefield (2004, pp.\\xa0385–542), Nilsson (1998, chpt. 3.3, 10.3, 17.5, 20)\\n\\n^ Turing (1950).\\n\\n^ Solomonoff (1956).\\n\\n^ Unsupervised learning: Russell & Norvig (2021, pp.\\xa0653) (definition), Russell & Norvig (2021, pp.\\xa0738–740) (cluster analysis), Russell & Norvig (2021, pp.\\xa0846–860) (word embedding)\\n\\n^ a b Supervised learning: Russell & Norvig (2021, §19.2) (Definition), Russell & Norvig (2021, Chpt. 19–20) (Techniques)\\n\\n^ Reinforcement learning: Russell & Norvig (2021, chpt. 22), Luger & Stubblefield (2004, pp.\\xa0442–449)\\n\\n^ Transfer learning: Russell & Norvig (2021, pp.\\xa0281), The Economist (2016)\\n\\n^ \"Artificial Intelligence (AI): What Is AI and How Does It Work? | Built In\". builtin.com. Retrieved 30 October 2023.\\n\\n^ Computational learning theory: Russell & Norvig (2021, pp.\\xa0672–674), Jordan & Mitchell (2015)\\n\\n^ Natural language processing (NLP): Russell & Norvig (2021, chpt. 23–24), Poole, Mackworth & Goebel (1998, pp.\\xa091–104), Luger & Stubblefield (2004, pp.\\xa0591–632)\\n\\n^ Subproblems of NLP: Russell & Norvig (2021, pp.\\xa0849–850)\\n\\n^ Russell & Norvig (2021), pp.\\xa0856–858.\\n\\n^ Dickson (2022).\\n\\n^ Modern statistical and deep learning approaches to NLP: Russell & Norvig (2021, chpt. 24), Cambria & White (2014)\\n\\n^ Vincent (2019).\\n\\n^ Russell & Norvig (2021), pp.\\xa0875–878.\\n\\n^ Bushwick (2023).\\n\\n^ Computer vision: Russell & Norvig (2021, chpt. 25), Nilsson (1998, chpt. 6)\\n\\n^ Russell & Norvig (2021), pp.\\xa0849–850.\\n\\n^ Russell & Norvig (2021), pp.\\xa0895–899.\\n\\n^ Russell & Norvig (2021), pp.\\xa0899–901.\\n\\n^ Challa et al. (2011).\\n\\n^ Russell & Norvig (2021), pp.\\xa0931–938.\\n\\n^ MIT AIL (2014).\\n\\n^ Affective computing: Thro (1993), Edelson (1991), Tao & Tan (2005), Scassellati (2002)\\n\\n^ Waddell (2018).\\n\\n^ Poria et al. (2017).\\n\\n^ a b \\nArtificial general intelligence: Russell & Norvig (2021, pp.\\xa032–33, 1020–1021)Proposal for the modern version: Pennachin & Goertzel (2007)Warnings of overspecialization in AI from leading researchers: Nilsson (1995), McCarthy (2007), Beal & Winston (2009)\\n\\n^ Search algorithms: Russell & Norvig (2021, chpts. 3–5), Poole, Mackworth & Goebel (1998, pp.\\xa0113–163), Luger & Stubblefield (2004, pp.\\xa079–164, 193–219), Nilsson (1998, chpts. 7–12)\\n\\n^ State space search: Russell & Norvig (2021, chpt. 3)\\n\\n^ Russell & Norvig (2021), sect. 11.2.\\n\\n^ Uninformed searches (breadth first search, depth-first search and general state space search): Russell & Norvig (2021, sect. 3.4), Poole, Mackworth & Goebel (1998, pp.\\xa0113–132), Luger & Stubblefield (2004, pp.\\xa079–121), Nilsson (1998, chpt. 8)\\n\\n^ Heuristic or informed searches (e.g., greedy best first and A*): Russell & Norvig (2021, sect. 3.5), Poole, Mackworth & Goebel (1998, pp.\\xa0132–147), Poole & Mackworth (2017, sect. 3.6), Luger & Stubblefield (2004, pp.\\xa0133–150)\\n\\n^ Adversarial search: Russell & Norvig (2021, chpt. 5)\\n\\n^ Local or \"optimization\" search: Russell & Norvig (2021, chpt. 4)\\n\\n^ Singh Chauhan, Nagesh (18 December 2020). \"Optimization Algorithms in Neural Networks\". KDnuggets. Retrieved 13 January 2024.\\n\\n^ Evolutionary computation: Russell & Norvig (2021, sect. 4.1.2)\\n\\n^ Merkle & Middendorf (2013).\\n\\n^ Logic: Russell & Norvig (2021, chpts. 6–9), Luger & Stubblefield (2004, pp.\\xa035–77), Nilsson (1998, chpt. 13–16)\\n\\n^ Propositional logic: Russell & Norvig (2021, chpt. 6), Luger & Stubblefield (2004, pp.\\xa045–50), Nilsson (1998, chpt. 13)\\n\\n^ First-order logic and features such as equality: Russell & Norvig (2021, chpt. 7), Poole, Mackworth & Goebel (1998, pp.\\xa0268–275), Luger & Stubblefield (2004, pp.\\xa050–62), Nilsson (1998, chpt. 15)\\n\\n^ Logical inference: Russell & Norvig (2021, chpt. 10)\\n\\n^ logical deduction as search: Russell & Norvig (2021, sects. 9.3, 9.4), Poole, Mackworth & Goebel (1998, pp.\\xa0~46–52), Luger & Stubblefield (2004, pp.\\xa062–73), Nilsson (1998, chpt. 4.2, 7.2)\\n\\n^ Resolution and unification: Russell & Norvig (2021, sections 7.5.2, 9.2, 9.5)\\n\\n^ Warren, D.H.; Pereira, L.M.; Pereira, F. (1977). \"Prolog-the language and its implementation compared with Lisp\". ACM SIGPLAN Notices. 12 (8): 109–115. doi:10.1145/872734.806939.\\n\\n^ Fuzzy logic: Russell & Norvig (2021, pp.\\xa0214, 255, 459), Scientific American (1999)\\n\\n^ a b Stochastic methods for uncertain reasoning: Russell & Norvig (2021, chpt. 12–18, 20), Poole, Mackworth & Goebel (1998, pp.\\xa0345–395), Luger & Stubblefield (2004, pp.\\xa0165–191, 333–381), Nilsson (1998, chpt. 19)\\n\\n^ decision theory and decision analysis: Russell & Norvig (2021, chpt. 16–18), Poole, Mackworth & Goebel (1998, pp.\\xa0381–394)\\n\\n^ Information value theory: Russell & Norvig (2021, sect. 16.6)\\n\\n^ Markov decision processes and dynamic decision networks: Russell & Norvig (2021, chpt. 17)\\n\\n^ a b c Stochastic temporal models: Russell & Norvig (2021, chpt. 14)\\nHidden Markov model: Russell & Norvig (2021, sect. 14.3)\\nKalman filters: Russell & Norvig (2021, sect. 14.4)\\nDynamic Bayesian networks: Russell & Norvig (2021, sect. 14.5)\\n\\n^ Game theory and mechanism design: Russell & Norvig (2021, chpt. 18)\\n\\n^ Bayesian networks: Russell & Norvig (2021, sects. 12.5–12.6, 13.4–13.5, 14.3–14.5, 16.5, 20.2–20.3), Poole, Mackworth & Goebel (1998, pp.\\xa0361–381), Luger & Stubblefield (2004, pp.\\xa0~182–190, ≈363–379), Nilsson (1998, chpt. 19.3–19.4)\\n\\n^ Domingos (2015), chpt. 6.\\n\\n^ Bayesian inference algorithm: Russell & Norvig (2021, sect. 13.3–13.5), Poole, Mackworth & Goebel (1998, pp.\\xa0361–381), Luger & Stubblefield (2004, pp.\\xa0~363–379), Nilsson (1998, chpt. 19.4 & 7)\\n\\n^ Domingos (2015), p.\\xa0210.\\n\\n^ Bayesian learning and the expectation–maximization algorithm: Russell & Norvig (2021, chpt. 20), Poole, Mackworth & Goebel (1998, pp.\\xa0424–433), Nilsson (1998, chpt. 20), Domingos (2015, p.\\xa0210)\\n\\n^ Bayesian decision theory and Bayesian decision networks: Russell & Norvig (2021, sect. 16.5)\\n\\n^ Statistical learning methods and classifiers: Russell & Norvig (2021, chpt. 20),\\n\\n^ Ciaramella, Alberto; Ciaramella, Marco (2024). Introduction to Artificial Intelligence: from data analysis to generative AI. Intellisemantic Editions. ISBN\\xa0978-8-8947-8760-3.\\n\\n^ Decision trees: Russell & Norvig (2021, sect. 19.3), Domingos (2015, p.\\xa088)\\n\\n^ Non-parameteric learning models such as K-nearest neighbor and support vector machines: Russell & Norvig (2021, sect. 19.7), Domingos (2015, p.\\xa0187) (k-nearest neighbor)\\nDomingos (2015, p.\\xa088) (kernel methods)\\n\\n^ Domingos (2015), p.\\xa0152.\\n\\n^ Naive Bayes classifier: Russell & Norvig (2021, sect. 12.6), Domingos (2015, p.\\xa0152)\\n\\n^ a b Neural networks: Russell & Norvig (2021, chpt. 21), Domingos (2015, Chapter 4)\\n\\n^ Gradient calculation in computational graphs, backpropagation, automatic differentiation: Russell & Norvig (2021, sect. 21.2), Luger & Stubblefield (2004, pp.\\xa0467–474), Nilsson (1998, chpt. 3.3)\\n\\n^ Universal approximation theorem: Russell & Norvig (2021, p.\\xa0752)\\nThe theorem: Cybenko (1988), Hornik, Stinchcombe & White (1989)\\n\\n^ Feedforward neural networks: Russell & Norvig (2021, sect. 21.1)\\n\\n^ Perceptrons: Russell & Norvig (2021, pp.\\xa021, 22, 683, 22)\\n\\n^ a b Deep learning: Russell & Norvig (2021, chpt. 21), Goodfellow, Bengio & Courville (2016), Hinton et al. (2016), Schmidhuber (2015)\\n\\n^ Recurrent neural networks: Russell & Norvig (2021, sect. 21.6)\\n\\n^ Convolutional neural networks: Russell & Norvig (2021, sect. 21.3)\\n\\n^ Sindhu V, Nivedha S, Prakash M (February 2020). \"An Empirical Science Research on Bioinformatics in Machine Learning\". Journal of Mechanics of Continua and Mathematical Sciences (7). doi:10.26782/jmcms.spl.7/2020.02.00006.\\n\\n^ Deng & Yu (2014), pp.\\xa0199–200.\\n\\n^ Ciresan, Meier & Schmidhuber (2012).\\n\\n^ Russell & Norvig (2021), p.\\xa0750.\\n\\n^ a b c Russell & Norvig (2021), p.\\xa017.\\n\\n^ a b c d e f g Russell & Norvig (2021), p.\\xa0785.\\n\\n^ a b Schmidhuber (2022), sect. 5.\\n\\n^ Schmidhuber (2022), sect. 6.\\n\\n^ a b c Schmidhuber (2022), sect. 7.\\n\\n^ Schmidhuber (2022), sect. 8.\\n\\n^ Quoted in Christian (2020, p.\\xa022)\\n\\n^ Metz, Cade; Weise, Karen (5 May 2025). \"A.I. Hallucinations Are Getting Worse, Even as New Systems Become More Powerful\". The New York Times. ISSN\\xa00362-4331. Retrieved 6 May 2025.\\n\\n^ Smith (2023).\\n\\n^ \"Explained: Generative AI\". MIT News | Massachusetts Institute of Technology. 9 November 2023.\\n\\n^ \"AI Writing and Content Creation Tools\". MIT Sloan Teaching & Learning Technologies. Archived from the original on 25 December 2023. Retrieved 25 December 2023.\\n\\n^ Marmouyet (2023).\\n\\n^ Kobielus (2019).\\n\\n^ Thomason, James (21 May 2024). \"Mojo Rising: The resurgence of AI-first programming languages\". VentureBeat. Archived from the original on 27 June 2024. Retrieved 26 May 2024.\\n\\n^ Wodecki, Ben (5 May 2023). \"7 AI Programming Languages You Need to Know\". AI Business. Archived from the original on 25 July 2024. Retrieved 5 October 2024.\\n\\n^ Plumb, Taryn (18 September 2024). \"Why Jensen Huang and Marc Benioff see \\'gigantic\\' opportunity for agentic AI\". VentureBeat. Archived from the original on 5 October 2024. Retrieved 4 October 2024.\\n\\n^ Mims, Christopher (19 September 2020). \"Huang\\'s Law Is the New Moore\\'s Law, and Explains Why Nvidia Wants Arm\". Wall Street Journal. ISSN\\xa00099-9660. Archived from the original on 2 October 2023. Retrieved 19 January 2025.\\n\\n^ Dankwa-Mullan, Irene (2024). \"Health Equity and Ethical Considerations in Using Artificial Intelligence in Public Health and Medicine\". Preventing Chronic Disease. 21 240245: E64. doi:10.5888/pcd21.240245. ISSN\\xa01545-1151. PMC\\xa011364282. PMID\\xa039173183.\\n\\n^ Jumper, J; Evans, R; Pritzel, A (2021). \"Highly accurate protein structure prediction with AlphaFold\". Nature. 596 (7873): 583–589. Bibcode:2021Natur.596..583J. doi:10.1038/s41586-021-03819-2. PMC\\xa08371605. PMID\\xa034265844.\\n\\n^ \"AI discovers new class of antibiotics to kill drug-resistant bacteria\". New Scientist. 20 December 2023. Archived from the original on 16 September 2024. Retrieved 5 October 2024.\\n\\n^ \"AI speeds up drug design for Parkinson\\'s ten-fold\". University of Cambridge. Cambridge University. 17 April 2024. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\\n\\n^ Horne, Robert I.; Andrzejewska, Ewa A.; Alam, Parvez; Brotzakis, Z. Faidon; Srivastava, Ankit; Aubert, Alice; Nowinska, Magdalena; Gregory, Rebecca C.; Staats, Roxine; Possenti, Andrea; Chia, Sean; Sormanni, Pietro; Ghetti, Bernardino; Caughey, Byron; Knowles, Tuomas P. J.; Vendruscolo, Michele (17 April 2024). \"Discovery of potent inhibitors of α-synuclein aggregation using structure-based iterative learning\". Nature Chemical Biology. 20 (5). Nature: 634–645. doi:10.1038/s41589-024-01580-x. PMC\\xa011062903. PMID\\xa038632492.\\n\\n^ Grant, Eugene F.; Lardner, Rex (25 July 1952). \"The Talk of the Town – It\". The New Yorker. ISSN\\xa00028-792X. Archived from the original on 16 February 2020. Retrieved 28 January 2024.\\n\\n^ Anderson, Mark Robert (11 May 2017). \"Twenty years on from Deep Blue vs Kasparov: how a chess match started the big data revolution\". The Conversation. Archived from the original on 17 September 2024. Retrieved 28 January 2024.\\n\\n^ Markoff, John (16 February 2011). \"Computer Wins on \\'Jeopardy!\\': Trivial, It\\'s Not\". The New York Times. ISSN\\xa00362-4331. Archived from the original on 22 October 2014. Retrieved 28 January 2024.\\n\\n^ Byford, Sam (27 May 2017). \"AlphaGo retires from competitive Go after defeating world number one 3–0\". The Verge. Archived from the original on 7 June 2017. Retrieved 28 January 2024.\\n\\n^ Brown, Noam; Sandholm, Tuomas (30 August 2019). \"Superhuman AI for multiplayer poker\". Science. 365 (6456): 885–890. Bibcode:2019Sci...365..885B. doi:10.1126/science.aay2400. PMID\\xa031296650.\\n\\n^ \"MuZero: Mastering Go, chess, shogi and Atari without rules\". Google DeepMind. 23 December 2020. Retrieved 28 January 2024.\\n\\n^ Sample, Ian (30 October 2019). \"AI becomes grandmaster in \\'fiendishly complex\\' StarCraft II\". The Guardian. ISSN\\xa00261-3077. Archived from the original on 29 December 2020. Retrieved 28 January 2024.\\n\\n^ Wurman, P. R.; Barrett, S.; Kawamoto, K. (2022). \"Outracing champion Gran Turismo drivers with deep reinforcement learning\" (PDF). Nature. 602 (7896): 223–228. Bibcode:2022Natur.602..223W. doi:10.1038/s41586-021-04357-7. PMID\\xa035140384.\\n\\n^ Wilkins, Alex (13 March 2024). \"Google AI learns to play open-world video games by watching them\". New Scientist. Archived from the original on 26 July 2024. Retrieved 21 July 2024.\\n\\n^ Wu, Zhengxuan; Arora, Aryaman; Wang, Zheng; Geiger, Atticus; Jurafsky, Dan; Manning, Christopher D.; Potts, Christopher (2024). \"ReFT: Representation Finetuning for Language Models\". NeurIPS. arXiv:2404.03592.\\n\\n^ \"Improving mathematical reasoning with process supervision\". OpenAI. 31 May 2023. Retrieved 26 January 2025.\\n\\n^ Srivastava, Saurabh (29 February 2024). \"Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap\". arXiv:2402.19450 [cs.AI].\\n\\n^ Lightman, Hunter; Kosaraju, Vineet; Burda, Yura; Edwards, Harri; Baker, Bowen; Lee, Teddy; Leike, Jan; Schulman, John; Sutskever, Ilya; Cobbe, Karl (2023). \"Let\\'s Verify Step by Step\". arXiv:2305.20050v1 [cs.LG].\\n\\n^ Franzen, Carl (8 August 2024). \"Alibaba claims no. 1 spot in AI math models with Qwen2-Math\". VentureBeat. Retrieved 16 February 2025.\\n\\n^ Franzen, Carl (9 January 2025). \"Microsoft\\'s new rStar-Math technique upgrades small models to outperform OpenAI\\'s o1-preview at math problems\". VentureBeat. Retrieved 26 January 2025.\\n\\n^ Gina Genkina: New AI Model Advances the \"Kissing Problem\" and More. AlphaEvolve made several mathematical discoveries and practical optimizations IEEE Spectrum 14 May 2025. Retrieved 7 June 2025\\n\\n^ Roberts, Siobhan (25 July 2024). \"AI achieves silver-medal standard solving International Mathematical Olympiad problems\". The New York Times. Archived from the original on 26 September 2024. Retrieved 7 August 2024.\\n\\n^ Azerbayev, Zhangir; Schoelkopf, Hailey; Paster, Keiran; Santos, Marco Dos; McAleer\\', Stephen; Jiang, Albert Q.; Deng, Jia; Biderman, Stella; Welleck, Sean (16 October 2023). \"Llemma: An Open Language Model For Mathematics\". EleutherAI Blog. Retrieved 26 January 2025.\\n\\n^ \"Julius AI\". julius.ai.\\n\\n^ Metz, Cade (21 July 2025). \"Google A.I. System Wins Gold Medal in International Math Olympiad\". The New York Times. ISSN\\xa00362-4331. Retrieved 24 July 2025.\\n\\n^ McFarland, Alex (12 July 2024). \"8 Best AI for Math Tools (January 2025)\". Unite.AI. Retrieved 26 January 2025.\\n\\n^ Matthew Finio & Amanda Downie: IBM Think 2024 Primer, \"What is Artificial Intelligence (AI) in Finance?\" 8 December 2023\\n\\n^ M. Nicolas, J. Firzli: Pensions Age / European Pensions magazine, \"Artificial Intelligence: Ask the Industry\", May–June 2024. https://videovoice.org/ai-in-finance-innovation-entrepreneurship-vs-over-regulation-with-the-eus-artificial-intelligence-act-wont-work-as-intended/ Archived 11 September 2024 at the Wayback Machine.\\n\\n^ a b c Congressional Research Service (2019). Artificial Intelligence and National Security (PDF). Washington, DC: Congressional Research Service. Archived (PDF) from the original on 8 May 2020. Retrieved 25 February 2024.PD-notice\\n\\n^ a b Slyusar, Vadym (2019). Artificial intelligence as the basis of future control networks (Preprint). doi:10.13140/RG.2.2.30247.50087.\\n\\n^ Iraqi, Amjad (3 April 2024). \"\\'Lavender\\': The AI machine directing Israel\\'s bombing spree in Gaza\". +972 Magazine. Archived from the original on 10 October 2024. Retrieved 6 April 2024.\\n\\n^ Davies, Harry; McKernan, Bethan; Sabbagh, Dan (1 December 2023). \"\\'The Gospel\\': how Israel uses AI to select bombing targets in Gaza\". The Guardian. Archived from the original on 6 December 2023. Retrieved 4 December 2023.\\n\\n^ Marti, J Werner (10 August 2024). \"Drohnen haben den Krieg in der Ukraine revolutioniert, doch sie sind empfindlich auf Störsender – deshalb sollen sie jetzt autonom operieren\". Neue Zürcher Zeitung (in German). Archived from the original on 10 August 2024. Retrieved 10 August 2024.\\n\\n^ Banh, Leonardo; Strobel, Gero (2023). \"Generative artificial intelligence\". Electronic Markets. 33 (1) 63. doi:10.1007/s12525-023-00680-1.\\n\\n^ Pasick, Adam (27 March 2023). \"Artificial Intelligence Glossary: Neural Networks and Other Terms Explained\". The New York Times. ISSN\\xa00362-4331. Archived from the original on 1 September 2023. Retrieved 22 April 2023.\\n\\n^ Griffith, Erin; Metz, Cade (27 January 2023). \"Anthropic Said to Be Closing In on $300 Million in New A.I. Funding\". The New York Times. Archived from the original on 9 December 2023. Retrieved 14 March 2023.\\n\\n^ Lanxon, Nate; Bass, Dina; Davalos, Jackie (10 March 2023). \"A Cheat Sheet to AI Buzzwords and Their Meanings\". Bloomberg News. Archived from the original on 17 November 2023. Retrieved 14 March 2023.\\n\\n^ Roose, Kevin (21 October 2022). \"A Coming-Out Party for Generative A.I., Silicon Valley\\'s New Craze\". The New York Times. Archived from the original on 15 February 2023. Retrieved 14 March 2023.\\n\\n^ Shahaf, Tal; Shahaf, Tal (23 October 2025). \"Lightricks unveils powerful AI video model challenging OpenAI and Google\". Ynetglobal. Retrieved 22 December 2025.\\n\\n^ Metz, Cade (15 February 2024). \"OpenAI Unveils A.I. That Instantly Generates Eye-Popping Videos\". The New York Times. ISSN\\xa00362-4331. Archived from the original on 15 February 2024. Retrieved 16 February 2024.\\n\\n^ TechForge (24 October 2025). \"Open-source AI video from Lightricks offers 4K, sound, and faster rendering\". AI News. Retrieved 22 December 2025.\\n\\n^ \"The race of the AI labs heats up\". The Economist. 30 January 2023. Archived from the original on 17 November 2023. Retrieved 14 March 2023.\\n\\n^ Petrella, Stephanie; Miller, Chris; Cooper, Benjamin (2021). \"Russia\\'s Artificial Intelligence Strategy: The Role of State-Owned Firms\". Orbis. 65 (1): 75–100. doi:10.1016/j.orbis.2020.11.004.\\n\\n^ Raza, Marium M.; Venkatesh, Kaushik P.; Kvedar, Joseph C. (7 March 2024). \"Generative AI and large language models in health care: pathways to implementation\". npj Digital Medicine. 7 (1): 62. doi:10.1038/s41746-023-00988-4. ISSN\\xa02398-6352. PMC\\xa010920625. PMID\\xa038454007.\\n\\n^ Mogaji, Emmanuel (7 January 2025). \"How generative AI is transforming financial services – and what it means for customers\". The Conversation. Retrieved 10 April 2025.\\n\\n^ Bean, Thomas H. Davenport and Randy (19 June 2023). \"The Impact of Generative AI on Hollywood and Entertainment\". MIT Sloan Management Review. Archived from the original on 6 August 2024. Retrieved 10 April 2025.\\n\\n^ Brynjolfsson, Erik; Li, Danielle; Raymond, Lindsey R. (April 2023), Generative AI at Work (Working Paper), Working Paper Series, doi:10.3386/w31161, archived from the original on 28 March 2024, retrieved 21 January 2024\\n\\n^ \"Don\\'t fear an AI-induced jobs apocalypse just yet\". The Economist. 6 March 2023. Archived from the original on 17 November 2023. Retrieved 14 March 2023.\\n\\n^ Coyle, Jake (27 September 2023). \"In Hollywood writers\\' battle against AI, humans win (for now)\". AP News. Associated Press. Archived from the original on 3 April 2024. Retrieved 26 January 2024.\\n\\n^ \"How Generative AI Can Augment Human Creativity\". Harvard Business Review. 16 June 2023. ISSN\\xa00017-8012. Archived from the original on 20 June 2023. Retrieved 20 June 2023.\\n\\n^ Poole, David; Mackworth, Alan (2023). Artificial Intelligence, Foundations of Computational Agents (3rd\\xa0ed.). Cambridge University Press. doi:10.1017/9781009258227. ISBN\\xa0978-1-0092-5819-7.\\n\\n^ Russell, Stuart; Norvig, Peter (2020). Artificial Intelligence: A Modern Approach (4th\\xa0ed.). Pearson. ISBN\\xa0978-0-1346-1099-3.\\n\\n^ \"Why agents are the next frontier of generative AI\". McKinsey Digital. 24 July 2024. Archived from the original on 3 October 2024. Retrieved 10 August 2024.\\n\\n^ \"Introducing Copilot Search in Bing\". blogs.bing.com. 4 April 2025.\\n\\n^ Peters, Jay (14 March 2023). \"The Bing AI bot has been secretly running GPT-4\". The Verge. Retrieved 31 August 2025.\\n\\n^ \"Security for Microsoft 365 Copilot\". learn.microsoft.com.\\n\\n^ O\\'Flaherty, Kate (21 May 2025). \"Google AI Overviews — Everything You Need To Know\". Forbes.\\n\\n^ \"Generative AI in Search: Let Google do the searching for you\". Google. 14 May 2024.\\n\\n^ Figueiredo, Mayara Costa; Ankrah, Elizabeth; Powell, Jacquelyn E.; Epstein, Daniel A.; Chen, Yunan (12 January 2024). \"Powered by AI: Examining How AI Descriptions Influence Perceptions of Fertility Tracking Applications\". Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. 7 (4): 1–24. doi:10.1145/3631414.\\n\\n^ Power, Jennifer; Pym, Tinonee; James, Alexandra; Waling, Andrea (5 July 2024). \"Smart Sex Toys: A Narrative Review of Recent Research on Cultural, Health and Safety Considerations\". Current Sexual Health Reports. 16 (3): 199–215. doi:10.1007/s11930-024-00392-3. ISSN\\xa01548-3592.\\n\\n^ Marcantonio, Tiffany L.; Avery, Gracie; Thrash, Anna; Leone, Ruschelle M. (10 September 2024). \"Large Language Models in an App: Conducting a Qualitative Synthetic Data Analysis of How Snapchat\\'s \\'My AI\\' Responds to Questions About Sexual Consent, Sexual Refusals, Sexual Assault, and Sexting\". The Journal of Sex Research. 62 (9): 1905–1919. doi:10.1080/00224499.2024.2396457. PMC\\xa011891083. PMID\\xa039254628.\\n\\n^ Hanson, Kenneth R.; Bolthouse, Hannah (2024). \"\"Replika Removing Erotic Role-Play Is Like Grand Theft Auto Removing Guns or Cars\": Reddit Discourse on Artificial Intelligence Chatbots and Sexual Technologies\". Socius: Sociological Research for a Dynamic World. 10 23780231241259627. doi:10.1177/23780231241259627. ISSN\\xa02378-0231.\\n\\n^ Mania, Karolina (2024). \"Legal Protection of Revenge and Deepfake Porn Victims in the European Union: Findings from a Comparative Legal Study\". Trauma, Violence, & Abuse. 25 (1): 117–129. doi:10.1177/15248380221143772. PMID\\xa036565267.\\n\\n^ Singh, Suyesha; Nambiar, Vaishnavi (2024). \"Role of Artificial Intelligence in the Prevention of Online Child Sexual Abuse: A Systematic Review of Literature\". Journal of Applied Security Research. 19 (4): 586–627. doi:10.1080/19361610.2024.2331885.\\n\\n^ Razi, Afsaneh; Kim, Seunghyun; Alsoubai, Ashwaq; Stringhini, Gianluca; Solorio, Thamar; De Choudhury, Munmun; Wisniewski, Pamela J. (13 October 2021). \"A Human-Centered Systematic Literature Review of the Computational Approaches for Online Sexual Risk Detection\". Proceedings of the ACM on Human-Computer Interaction. 5 (CSCW2): 1–38. doi:10.1145/3479609.\\n\\n^ Ransbotham, Sam; Kiron, David; Gerbert, Philipp; Reeves, Martin (6 September 2017). \"Reshaping Business With Artificial Intelligence\". MIT Sloan Management Review. Archived from the original on 13 February 2024.\\n\\n^ Sun, Yuran; Zhao, Xilei; Lovreglio, Ruggiero; Kuligowski, Erica (2024). \"AI for large-scale evacuation modeling: Promises and challenges\". Interpretable Machine Learning for the Analysis, Design, Assessment, and Informed Decision Making for Civil Infrastructure. pp.\\xa0185–204. doi:10.1016/B978-0-12-824073-1.00014-9. ISBN\\xa0978-0-12-824073-1.\\n\\n^ Gomaa, Islam; Adelzadeh, Masoud; Gwynne, Steven; Spencer, Bruce; Ko, Yoon; Bénichou, Noureddine; Ma, Chunyun; Elsagan, Nour; Duong, Dana; Zalok, Ehab; Kinateder, Max (1 November 2021). \"A Framework for Intelligent Fire Detection and Evacuation System\". Fire Technology. 57 (6): 3179–3185. doi:10.1007/s10694-021-01157-3.\\n\\n^ Zhao, Xilei; Lovreglio, Ruggiero; Nilsson, Daniel (1 May 2020). \"Modelling and interpreting pre-evacuation decision-making using machine learning\". Automation in Construction. 113 103140. doi:10.1016/j.autcon.2020.103140. hdl:10179/17315.\\n\\n^ \"India\\'s latest election embraced AI technology. Here are some ways it was used constructively\". PBS News. 12 June 2024. Archived from the original on 17 September 2024. Retrieved 28 October 2024.\\n\\n^ \"Экономист Дарон Асемоглу написал книгу об угрозах искусственного интеллекта — и о том, как правильное управление может обратить его на пользу человечеству Спецкор \"Медузы\" Маргарита Лютова узнала у ученого, как скоро мир сможет приблизиться к этой утопии\". Meduza (in Russian). Archived from the original on 20 June 2023. Retrieved 21 June 2023.\\n\\n^ \"Learning, thinking, artistic collaboration and other such human endeavours in the age of AI\". The Hindu. 2 June 2023. Archived from the original on 21 June 2023. Retrieved 21 June 2023.\\n\\n^ Müller, Vincent C. (30 April 2020). \"Ethics of Artificial Intelligence and Robotics\". Stanford Encyclopedia of Philosophy Archive. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\\n\\n^ Simonite (2016).\\n\\n^ Russell & Norvig (2021), p.\\xa0987.\\n\\n^ \"Assessing potential future artificial intelligence risks, benefits and policy imperatives\". OECD. 14 November 2024. Retrieved 1 August 2025.\\n\\n^ Laskowski (2023).\\n\\n^ GAO (2022).\\n\\n^ Valinsky (2019).\\n\\n^ Russell & Norvig (2021), p.\\xa0991.\\n\\n^ Russell & Norvig (2021), pp.\\xa0991–992.\\n\\n^ Christian (2020), p.\\xa063.\\n\\n^ Vincent (2022).\\n\\n^ Kopel, Matthew. \"Copyright Services: Fair Use\". Cornell University Library. Archived from the original on 26 September 2024. Retrieved 26 April 2024.\\n\\n^ Burgess, Matt. \"How to Stop Your Data From Being Used to Train AI\". Wired. ISSN\\xa01059-1028. Archived from the original on 3 October 2024. Retrieved 26 April 2024.\\n\\n^ \"Exclusive: Multiple AI companies bypassing web standard to scrape publisher sites, licensing firm says\". Reuters. Archived from the original on 10 November 2024. Retrieved 13 November 2025.\\n\\n^ Shilov, Anton (21 June 2024). \"Several AI companies said to be ignoring robots dot txt exclusion, scraping content without permission: report\". Tom\\'s Hardware. Retrieved 13 November 2025.\\n\\n^ Reisner (2023).\\n\\n^ Alter & Harris (2023).\\n\\n^ \"Getting the Innovation Ecosystem Ready for AI. An IP policy toolkit\" (PDF). WIPO.\\n\\n^ Hammond, George (27 December 2023). \"Big Tech is spending more than VC firms on AI startups\". Ars Technica. Archived from the original on 10 January 2024.\\n\\n^ Wong, Matteo (24 October 2023). \"The Future of AI Is GOMA\". The Atlantic. Archived from the original on 5 January 2024.\\n\\n^ \"Big tech and the pursuit of AI dominance\". The Economist. 26 March 2023. Archived from the original on 29 December 2023.\\n\\n^ Fung, Brian (19 December 2023). \"Where the battle to dominate AI may be won\". CNN Business. Archived from the original on 13 January 2024.\\n\\n^ Metz, Cade (5 July 2023). \"In the Age of A.I., Tech\\'s Little Guys Need Big Friends\". The New York Times. Archived from the original on 8 July 2024. Retrieved 5 October 2024.\\n\\n^ Bhattarai, Abha; Lerman, Rachel (25 December 2025). \"10 charts that show where the economy is heading / 3. AI related investments\". The Washington Post. Archived from the original on 27 December 2025. Source: MSCI\\n\\n^ \"Electricity 2024 – Analysis\". IEA. 24 January 2024. Retrieved 13 July 2024.\\n\\n^ Calvert, Brian (28 March 2024). \"AI already uses as much energy as a small country. It\\'s only the beginning\". Vox. New York, New York. Archived from the original on 3 July 2024. Retrieved 5 October 2024.\\n\\n^ Halper, Evan; O\\'Donovan, Caroline (21 June 2024). \"AI is exhausting the power grid. Tech firms are seeking a miracle solution\". Washington Post.\\n\\n^ Davenport, Carly. \"AI Data Centers and the Coming YS Power Demand Surge\" (PDF). Goldman Sachs. Archived from the original (PDF) on 26 July 2024. Retrieved 5 October 2024.\\n\\n^ Ryan, Carol (12 April 2024). \"Energy-Guzzling AI Is Also the Future of Energy Savings\". Wall Street Journal. Dow Jones.\\n\\n^ Hiller, Jennifer (1 July 2024). \"Tech Industry Wants to Lock Up Nuclear Power for AI\". Wall Street Journal. Dow Jones. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\\n\\n^ Kendall, Tyler (28 September 2024). \"Nvidia\\'s Huang Says Nuclear Power an Option to Feed Data Centers\". Bloomberg.\\n\\n^ Halper, Evan (20 September 2024). \"Microsoft deal would reopen Three Mile Island nuclear plant to power AI\". Washington Post.\\n\\n^ Hiller, Jennifer (20 September 2024). \"Three Mile Island\\'s Nuclear Plant to Reopen, Help Power Microsoft\\'s AI Centers\". Wall Street Journal. Dow Jones. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\\n\\n^ a b c Niva Yadav (19 August 2024). \"Taiwan to stop large data centers in the North, cites insufficient power\". DatacenterDynamics. Archived from the original on 8 November 2024. Retrieved 7 November 2024.\\n\\n^ a b Mochizuki, Takashi; Oda, Shoko (18 October 2024). \"エヌビディア出資の日本企業、原発近くでＡＩデータセンター新設検討\". Bloomberg (in Japanese). Archived from the original on 8 November 2024. Retrieved 7 November 2024.\\n\\n^ a b Naureen S Malik and Will Wade (5 November 2024). \"Nuclear-Hungry AI Campuses Need New Plan to Find Power Fast\". Bloomberg.\\n\\n^ \"Energy and AI Executive summary\". International Energy Agency. Retrieved 10 April 2025.\\n\\n^ Nicas (2018).\\n\\n^ Rainie, Lee; Keeter, Scott; Perrin, Andrew (22 July 2019). \"Trust and Distrust in America\". Pew Research Center. Archived from the original on 22 February 2024.\\n\\n^ Kosoff, Maya (8 February 2018). \"YouTube Struggles to Contain Its Conspiracy Problem\". Vanity Fair. Retrieved 10 April 2025.\\n\\n^ Berry, David M. (19 March 2025). \"Synthetic media and computational capitalism: towards a critical theory of artificial intelligence\". AI & Society. 40 (7): 5257–5269. doi:10.1007/s00146-025-02265-2. ISSN\\xa01435-5655.\\n\\n^ \"Unreal: A quantum leap in AI video\". The Week. 17 June 2025. Retrieved 20 June 2025.\\n\\n^ Snow, Jackie (16 June 2025). \"AI video is getting real. Beware what comes next\". Quartz. Retrieved 20 June 2025.\\n\\n^ Chow, Andrew R.; Perrigo, Billy (3 June 2025). \"Google\\'s New AI Tool Generates Convincing Deepfakes of Riots, Conflict, and Election Fraud\". Time. Retrieved 20 June 2025.\\n\\n^ Williams (2023).\\n\\n^ Olanipekun, Samson Olufemi (2025). \"Computational propaganda and misinformation: AI technologies as tools of media manipulation\". World Journal of Advanced Research and Reviews. 25 (1): 911–923. doi:10.30574/wjarr.2025.25.1.0131. ISSN\\xa02581-9615.\\n\\n^ Taylor & Hern (2023).\\n\\n^ Lin, Hause; Czarnek, Gabriela; Lewis, Benjamin; White, Joshua P.; Berinsky, Adam J.; Costello, Thomas; Pennycook, Gordon; Rand, David G. (2025). \"Persuading voters using human–artificial intelligence dialogues\". Nature. 648 (8093): 394–401. Bibcode:2025Natur.648..394L. doi:10.1038/s41586-025-09771-9. PMID\\xa041345316.\\n\\n^ \"To fight AI, we need \\'personhood credentials,\\' say AI firms\". Archived from the original on 24 April 2025. Retrieved 9 May 2025.\\n\\n^ a b Samuel, Sigal (19 April 2022). \"Why it\\'s so damn hard to make AI fair and unbiased\". Vox. Archived from the original on 5 October 2024. Retrieved 24 July 2024.\\n\\n^ a b Rose (2023).\\n\\n^ CNA (2019).\\n\\n^ Mazeika, Mantas; Yin, Xuwang; Tamirisa, Rishub; Lim, Jaehyuk; Lee, Bruce W.; Ren, Richard; Phan, Long; Mu, Norman; Khoja, Adam (2025), Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs, Figure 16, arXiv:2502.08640\\n\\n^ Goffrey (2008), p.\\xa017.\\n\\n^ Berdahl et al. (2023); Goffrey (2008, p.\\xa017); Rose (2023); Russell & Norvig (2021, p.\\xa0995)\\n\\n^ Christian (2020), p.\\xa025.\\n\\n^ a b Russell & Norvig (2021), p.\\xa0995.\\n\\n^ Grant & Hill (2023).\\n\\n^ Larson & Angwin (2016).\\n\\n^ Christian (2020), p.\\xa067–70.\\n\\n^ Christian (2020, pp.\\xa067–70); Russell & Norvig (2021, pp.\\xa0993–994)\\n\\n^ Russell & Norvig (2021, p.\\xa0995); Lipartito (2011, p.\\xa036); Goodman & Flaxman (2017, p.\\xa06); Christian (2020, pp.\\xa039–40, 65)\\n\\n^ Quoted in Christian (2020, p.\\xa065).\\n\\n^ Russell & Norvig (2021, p.\\xa0994); Christian (2020, pp.\\xa040, 80–81)\\n\\n^ Quoted in Christian (2020, p.\\xa080)\\n\\n^ Hundt, Andrew; Agnew, William; Zeng, Vicky; Kacianka, Severin; Gombolay, Matthew (21–24 June 2022). \"Robots Enact Malignant Stereotypes\". Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency (FAccT \\'22). Seoul, South Korea: Association for Computing Machinery. doi:10.1145/3531146.3533138.\\n\\n^ For accessible summaries, see the Georgia Tech release and ScienceDaily coverage of the study’s findings.\"Flawed AI Makes Robots Racist, Sexist\". Georgia Tech Research News. 23 June 2022.\\n\\n^ \"Robots turn racist and sexist with flawed AI, study finds\". ScienceDaily. 21 June 2022.\\n\\n^ Sample (2017).\\n\\n^ \"Black Box AI\". 16 June 2023. Archived from the original on 15 June 2024. Retrieved 5 October 2024.\\n\\n^ Christian (2020), p.\\xa0110.\\n\\n^ Christian (2020), pp.\\xa088–91.\\n\\n^ Christian (2020, p.\\xa083); Russell & Norvig (2021, p.\\xa0997)\\n\\n^ Christian (2020), p.\\xa091.\\n\\n^ Christian (2020), p.\\xa083.\\n\\n^ Verma (2021).\\n\\n^ Rothman (2020).\\n\\n^ Christian (2020), pp.\\xa0105–108.\\n\\n^ Christian (2020), pp.\\xa0108–112.\\n\\n^ Ropek, Lucas (21 May 2024). \"New Anthropic Research Sheds Light on AI\\'s \\'Black Box\\'\". Gizmodo. Archived from the original on 5 October 2024. Retrieved 23 May 2024.\\n\\n^ Russell & Norvig (2021), p.\\xa0989.\\n\\n^ a b Russell & Norvig (2021), pp.\\xa0987–990.\\n\\n^ Russell & Norvig (2021), p.\\xa0988.\\n\\n^ Robitzski (2018); Sainato (2015)\\n\\n^ Harari (2018).\\n\\n^ Buckley, Chris; Mozur, Paul (22 May 2019). \"How China Uses High-Tech Surveillance to Subdue Minorities\". The New York Times. Archived from the original on 25 November 2019. Retrieved 2 July 2019.\\n\\n^ Whittaker, Zack (3 May 2019). \"Security lapse exposed a Chinese smart city surveillance system\". TechCrunch. Archived from the original on 7 March 2021. Retrieved 14 September 2020.\\n\\n^ Urbina et al. (2022).\\n\\n^ a b McGaughey (2022).\\n\\n^ Ford & Colvin (2015);McGaughey (2022)\\n\\n^ IGM Chicago (2017).\\n\\n^ Arntz, Gregory & Zierahn (2016), p.\\xa033.\\n\\n^ Lohr (2017); Frey & Osborne (2017); Arntz, Gregory & Zierahn (2016, p.\\xa033)\\n\\n^ Zhou, Viola (11 April 2023). \"AI is already taking video game illustrators\\' jobs in China\". Rest of World. Archived from the original on 21 February 2024. Retrieved 17 August 2023.\\n\\n^ Carter, Justin (11 April 2023). \"China\\'s game art industry reportedly decimated by growing AI use\". Game Developer. Archived from the original on 17 August 2023. Retrieved 17 August 2023.\\n\\n^ Morgenstern (2015).\\n\\n^ Mahdawi (2017); Thompson (2014)\\n\\n^ Ma, Jason (5 July 2025). \"Ford CEO Jim Farley warns AI will wipe out half of white-collar jobs, but the \\'essential economy\\' has a huge shortage of workers\". Fortune. Retrieved 21 October 2025.\\n\\n^ Tarnoff, Ben (4 August 2023). \"Lessons from Eliza\". The Guardian Weekly. pp.\\xa034–39.\\n\\n^ Cellan-Jones (2014).\\n\\n^ Russell & Norvig 2021, p.\\xa01001.\\n\\n^ Bostrom (2014).\\n\\n^ Russell (2019).\\n\\n^ Bostrom (2014); Müller & Bostrom (2014); Bostrom (2015).\\n\\n^ Harari (2023).\\n\\n^ Stewart (2025).\\n\\n^ Müller & Bostrom (2014).\\n\\n^ Leaders\\' concerns about the existential risks of AI around 2015: Rawlinson (2015), Holley (2015), Gibbs (2014), Sainato (2015)\\n\\n^ \"\"Godfather of artificial intelligence\" talks impact and potential of new AI\". CBS News. 25 March 2023. Archived from the original on 28 March 2023. Retrieved 28 March 2023.\\n\\n^ Pittis, Don (4 May 2023). \"Canadian artificial intelligence leader Geoffrey Hinton piles on fears of computer takeover\". CBC. Archived from the original on 7 July 2024. Retrieved 5 October 2024.\\n\\n^ \"\\'50–50 chance\\' that AI outsmarts humanity, Geoffrey Hinton says\". Bloomberg BNN. 14 June 2024. Archived from the original on 14 June 2024. Retrieved 6 July 2024.\\n\\n^ Valance (2023).\\n\\n^ Taylor, Josh (7 May 2023). \"Rise of artificial intelligence is inevitable but should not be feared, \\'father of AI\\' says\". The Guardian. Archived from the original on 23 October 2023. Retrieved 26 May 2023.\\n\\n^ Colton, Emma (7 May 2023). \"\\'Father of AI\\' says tech fears misplaced: \\'You cannot stop it\\'\". Fox News. Archived from the original on 26 May 2023. Retrieved 26 May 2023.\\n\\n^ Jones, Hessie (23 May 2023). \"Juergen Schmidhuber, Renowned \\'Father Of Modern AI,\\' Says His Life\\'s Work Won\\'t Lead To Dystopia\". Forbes. Archived from the original on 26 May 2023. Retrieved 26 May 2023.\\n\\n^ McMorrow, Ryan (19 December 2023). \"Andrew Ng: \\'Do we think the world is better off with more or less intelligence?\\'\". Financial Times. Archived from the original on 25 January 2024. Retrieved 30 December 2023.\\n\\n^ Levy, Steven (22 December 2023). \"How Not to Be Stupid About AI, With Yann LeCun\". Wired. Archived from the original on 28 December 2023. Retrieved 30 December 2023.\\n\\n^ Arguments that AI is not an imminent risk: Brooks (2014), Geist (2015), Madrigal (2015), Lee (2014)\\n\\n^ a b Christian (2020), pp.\\xa067, 73.\\n\\n^ Yudkowsky (2008).\\n\\n^ a b Anderson & Anderson (2011).\\n\\n^ AAAI (2014).\\n\\n^ Wallach (2010).\\n\\n^ Russell (2019), p.\\xa0173.\\n\\n^ Stewart, Ashley; Melton, Monica. \"Hugging Face CEO says he\\'s focused on building a \\'sustainable model\\' for the $4.5 billion open-source-AI startup\". Business Insider. Archived from the original on 25 September 2024. Retrieved 14 April 2024.\\n\\n^ Wiggers, Kyle (9 April 2024). \"Google open sources tools to support AI model development\". TechCrunch. Archived from the original on 10 September 2024. Retrieved 14 April 2024.\\n\\n^ Heaven, Will Douglas (12 May 2023). \"The open-source AI boom is built on Big Tech\\'s handouts. How long will it last?\". MIT Technology Review. Retrieved 14 April 2024.\\n\\n^ Brodsky, Sascha (19 December 2023). \"Mistral AI\\'s New Language Model Aims for Open Source Supremacy\". AI Business. Archived from the original on 5 September 2024. Retrieved 5 October 2024.\\n\\n^ Edwards, Benj (22 February 2024). \"Stability announces Stable Diffusion 3, a next-gen AI image generator\". Ars Technica. Archived from the original on 5 October 2024. Retrieved 14 April 2024.\\n\\n^ Marshall, Matt (29 January 2024). \"How enterprises are using open source LLMs: 16 examples\". VentureBeat. Archived from the original on 26 September 2024. Retrieved 5 October 2024.\\n\\n^ Piper, Kelsey (2 February 2024). \"Should we make our most powerful AI models open source to all?\". Vox. Archived from the original on 5 October 2024. Retrieved 14 April 2024.\\n\\n^ Alan Turing Institute (2019). \"Understanding artificial intelligence ethics and safety\" (PDF). Archived (PDF) from the original on 11 September 2024. Retrieved 5 October 2024.\\n\\n^ Alan Turing Institute (2023). \"AI Ethics and Governance in Practice\" (PDF). Archived (PDF) from the original on 11 September 2024. Retrieved 5 October 2024.\\n\\n^ Floridi, Luciano; Cowls, Josh (23 June 2019). \"A Unified Framework of Five Principles for AI in Society\". Harvard Data Science Review. 1 (1). doi:10.1162/99608f92.8cd550d1.\\n\\n^ Buruk, Banu; Ekmekci, Perihan Elif; Arda, Berna (1 September 2020). \"A critical perspective on guidelines for responsible and trustworthy artificial intelligence\". Medicine, Health Care and Philosophy. 23 (3): 387–399. doi:10.1007/s11019-020-09948-1. PMID\\xa032236794.\\n\\n^ Kamila, Manoj Kumar; Jasrotia, Sahil Singh (1 January 2023). \"Ethical issues in the development of artificial intelligence: recognizing the risks\". International Journal of Ethics and Systems. 41 (ahead-of-print): 45–63. doi:10.1108/IJOES-05-2023-0107.\\n\\n^ \"AI Safety Institute releases new AI safety evaluations platform\". UK Government. 10 May 2024. Archived from the original on 5 October 2024. Retrieved 14 May 2024.\\n\\n^ Regulation of AI to mitigate risks: Berryhill et al. (2019), Barfield & Pagallo (2018), Iphofen & Kritikos (2019), Wirtz, Weyerer & Geyer (2018), Buiten (2019)\\n\\n^ Law Library of Congress (U.S.). Global Legal Research Directorate (2019).\\n\\n^ a b Vincent (2023).\\n\\n^ Stanford University (2023).\\n\\n^ a b c d UNESCO (2021).\\n\\n^ Kissinger (2021).\\n\\n^ Altman, Brockman & Sutskever (2023).\\n\\n^ VOA News (25 October 2023). \"UN Announces Advisory Body on Artificial Intelligence\". Voice of America. Archived from the original on 18 September 2024. Retrieved 5 October 2024.\\n\\n^ \"AI Act enters into force - European Commission\". commission.europa.eu. Retrieved 11 August 2025.\\n\\n^ \"Council of Europe opens first ever global treaty on AI for signature\". Council of Europe. 5 September 2024. Archived from the original on 17 September 2024. Retrieved 17 September 2024.\\n\\n^ Edwards (2023).\\n\\n^ Kasperowicz (2023).\\n\\n^ Fox News (2023).\\n\\n^ Milmo, Dan (3 November 2023). \"Hope or Horror? The great AI debate dividing its pioneers\". The Guardian Weekly. pp.\\xa010–12.\\n\\n^ \"The Bletchley Declaration by Countries Attending the AI Safety Summit, 1–2 November 2023\". GOV.UK. 1 November 2023. Archived from the original on 1 November 2023. Retrieved 2 November 2023.\\n\\n^ \"Countries agree to safe and responsible development of frontier AI in landmark Bletchley Declaration\". GOV.UK (Press release). Archived from the original on 1 November 2023. Retrieved 1 November 2023.\\n\\n^ \"Second global AI summit secures safety commitments from companies\". Reuters. 21 May 2024. Retrieved 23 May 2024.\\n\\n^ \"Frontier AI Safety Commitments, AI Seoul Summit 2024\". gov.uk. 21 May 2024. Archived from the original on 23 May 2024. Retrieved 23 May 2024.\\n\\n^ a b Buntz, Brian (3 November 2024). \"Quality vs. quantity: US and China chart different paths in global AI patent race in 2024 / Geographical breakdown of AI patents in 2024\". Research & Development World. R&D World. Archived from the original on 9 December 2024.\\n\\n^ a b Russell & Norvig 2021, p.\\xa09.\\n\\n^ a b c Copeland, J., ed. (2004). The Essential Turing: the ideas that gave birth to the computer age. Oxford, England: Clarendon Press. ISBN\\xa00-1982-5079-7.\\n\\n^ \"Google books ngram\". Archived from the original on 5 October 2024. Retrieved 5 October 2024.\\n\\n^ AI\\'s immediate precursors: McCorduck (2004, pp.\\xa051–107), Crevier (1993, pp.\\xa027–32), Russell & Norvig (2021, pp.\\xa08–17), Moravec (1988, p.\\xa03)\\n\\n^ a b Turing\\'s original publication of the Turing test in \"Computing machinery and intelligence\": Turing (1950)\\nHistorical influence and philosophical implications: Haugeland (1985, pp.\\xa06–9), Crevier (1993, p.\\xa024), McCorduck (2004, pp.\\xa070–71), Russell & Norvig (2021, pp.\\xa02, 984)\\n\\n^ Crevier (1993), pp.\\xa047–49.\\n\\n^ Russell & Norvig (2003), p.\\xa017.\\n\\n^ Russell & Norvig (2003), p.\\xa018.\\n\\n^ Newquist (1994), pp.\\xa086–86.\\n\\n^ Simon (1965, p.\\xa096) quoted in Crevier (1993, p.\\xa0109)\\n\\n^ Minsky (1967, p.\\xa02) quoted in Crevier (1993, p.\\xa0109)\\n\\n^ Russell & Norvig (2021), p.\\xa021.\\n\\n^ Lighthill (1973).\\n\\n^ NRC 1999, pp.\\xa0212–213.\\n\\n^ Russell & Norvig (2021), p.\\xa022.\\n\\n^ Expert systems: Russell & Norvig (2021, pp.\\xa023, 292), Luger & Stubblefield (2004, pp.\\xa0227–331), Nilsson (1998, chpt. 17.4), McCorduck (2004, pp.\\xa0327–335, 434–435), Crevier (1993, pp.\\xa0145–162, 197–203), Newquist (1994, pp.\\xa0155–183)\\n\\n^ Russell & Norvig (2021), p.\\xa024.\\n\\n^ Nilsson (1998), p.\\xa07.\\n\\n^ McCorduck (2004), pp.\\xa0454–462.\\n\\n^ Moravec (1988).\\n\\n^ a b Brooks (1990).\\n\\n^ Developmental robotics: Weng et al. (2001), Lungarella et al. (2003), Asada et al. (2009), Oudeyer (2010)\\n\\n^ Russell & Norvig (2021), p.\\xa025.\\n\\n^ Crevier (1993, pp.\\xa0214–215), Russell & Norvig (2021, pp.\\xa024, 26)\\n\\n^ Russell & Norvig (2021), p.\\xa026.\\n\\n^ Formal and narrow methods adopted in the 1990s: Russell & Norvig (2021, pp.\\xa024–26), McCorduck (2004, pp.\\xa0486–487)\\n\\n^ AI widely used in the late 1990s: Kurzweil (2005, p.\\xa0265), NRC (1999, pp.\\xa0216–222), Newquist (1994, pp.\\xa0189–201)\\n\\n^ Wong (2023).\\n\\n^ Moore\\'s Law and AI: Russell & Norvig (2021, pp.\\xa014, 27)\\n\\n^ a b c Clark (2015b).\\n\\n^ Big data: Russell & Norvig (2021, p.\\xa026)\\n\\n^ Sagar, Ram (3 June 2020). \"OpenAI Releases GPT-3, The Largest Model So Far\". Analytics India Magazine. Archived from the original on 4 August 2020. Retrieved 15 March 2023.\\n\\n^ Milmo, Dan (2 February 2023). \"ChatGPT reaches 100 million users two months after launch\". The Guardian. ISSN\\xa00261-3077. Archived from the original on 3 February 2023. Retrieved 31 December 2024.\\n\\n^ Gorichanaz, Tim (29 November 2023). \"ChatGPT turns 1: AI chatbot\\'s success says as much about humans as technology\". The Conversation. Archived from the original on 31 December 2024. Retrieved 31 December 2024.\\n\\n^ DiFeliciantonio (2023).\\n\\n^ Goswami (2023).\\n\\n^ \"Nearly 1 in 4 new startups is an AI company\". PitchBook. 24 December 2024. Retrieved 3 January 2025.\\n\\n^ Grayling, Anthony; Ball, Brian (1 August 2024). \"Philosophy is crucial in the age of AI\". The Conversation. Archived from the original on 5 October 2024. Retrieved 4 October 2024.\\n\\n^ a b Jarow, Oshan (15 June 2024). \"Will AI ever become conscious? It depends on how you think about biology\". Vox. Archived from the original on 21 September 2024. Retrieved 4 October 2024.\\n\\n^ McCarthy, John. \"The Philosophy of AI and the AI of Philosophy\". jmc.stanford.edu. Archived from the original on 23 October 2018. Retrieved 3 October 2024.\\n\\n^ a b Turing (1950), p.\\xa01.\\n\\n^ Turing (1950), Under \"The Argument from Consciousness\".\\n\\n^ Kirk-Giannini, Cameron Domenico; Goldstein, Simon (16 October 2023). \"AI is closer than ever to passing the Turing test for \\'intelligence\\'. What happens when it does?\". The Conversation. Archived from the original on 25 September 2024. Retrieved 17 August 2024.\\n\\n^ Russell & Norvig (2021), p.\\xa03.\\n\\n^ Maker (2006).\\n\\n^ McCarthy (1999).\\n\\n^ Minsky (1986).\\n\\n^ \"What Is Artificial Intelligence (AI)?\". Google Cloud Platform. Archived from the original on 31 July 2023. Retrieved 16 October 2023.\\n\\n^ Suchman, Lucy (2023). \"The uncontroversial \\'thingness\\' of AI\". Big Data & Society. 10 (2) 20539517231206794. doi:10.1177/20539517231206794.\\n\\n^ Rehak, Rainer (2025). \"AI Narrative Breakdown. A Critical Assessment of Power and Promise\". Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency. pp.\\xa01250–1260. doi:10.1145/3715275.3732083. ISBN\\xa0979-8-4007-1482-5.\\n\\n^ \"One of the Biggest Problems in Regulating AI Is Agreeing on a Definition\". Carnegie Endowment for International Peace. Retrieved 31 July 2024.\\n\\n^ \"AI or BS? How to tell if a marketing tool really uses artificial intelligence\". The Drum. Retrieved 31 July 2024.\\n\\n^ Musser, George (1 September 2023). \"How AI Knows Things No One Told It\". Scientific American. Retrieved 17 July 2025.\\n\\n^ Nilsson (1983), p.\\xa010.\\n\\n^ Haugeland (1985), pp.\\xa0112–117.\\n\\n^ Physical symbol system hypothesis: Newell & Simon (1976, p.\\xa0116)\\nHistorical significance: McCorduck (2004, p.\\xa0153), Russell & Norvig (2021, p.\\xa019)\\n\\n^ Moravec\\'s paradox: Moravec (1988, pp.\\xa015–16), Minsky (1986, p.\\xa029), Pinker (2007, pp.\\xa0190–191)\\n\\n^ Dreyfus\\' critique of AI: Dreyfus (1972), Dreyfus & Dreyfus (1986)\\nHistorical significance and philosophical implications: Crevier (1993, pp.\\xa0120–132), McCorduck (2004, pp.\\xa0211–239), Russell & Norvig (2021, pp.\\xa0981–982), Fearn (2007, chpt. 3)\\n\\n^ Crevier (1993), p.\\xa0125.\\n\\n^ Langley (2011).\\n\\n^ Katz (2012).\\n\\n^ Neats vs. scruffies, the historic debate: McCorduck (2004, pp.\\xa0421–424, 486–489), Crevier (1993, p.\\xa0168), Nilsson (1983, pp.\\xa010–11), Russell & Norvig (2021, p.\\xa024)\\nA classic example of the \"scruffy\" approach to intelligence: Minsky (1986)\\nA modern example of neat AI and its aspirations in the 21st century: Domingos (2015)\\n\\n^ Pennachin & Goertzel (2007).\\n\\n^ a b Roberts (2016).\\n\\n^ Russell & Norvig (2021), p.\\xa0986.\\n\\n^ Chalmers (1995).\\n\\n^ Dennett (1991).\\n\\n^ Horst (2005).\\n\\n^ Searle (1999).\\n\\n^ Searle (1980), p.\\xa01.\\n\\n^ Russell & Norvig (2021), p.\\xa09817.\\n\\n^ Searle\\'s Chinese room argument: Searle (1980). Searle\\'s original presentation of the thought experiment., Searle (1999).\\nDiscussion: Russell & Norvig (2021, pp.\\xa0985), McCorduck (2004, pp.\\xa0443–445), Crevier (1993, pp.\\xa0269–271)\\n\\n^ Leith, Sam (7 July 2022). \"Nick Bostrom: How can we be certain a machine isn\\'t conscious?\". The Spectator. Archived from the original on 26 September 2024. Retrieved 23 February 2024.\\n\\n^ a b c Thomson, Jonny (31 October 2022). \"Why don\\'t robots have rights?\". Big Think. Archived from the original on 13 September 2024. Retrieved 23 February 2024.\\n\\n^ a b Kateman, Brian (24 July 2023). \"AI Should Be Terrified of Humans\". Time. Archived from the original on 25 September 2024. Retrieved 23 February 2024.\\n\\n^ Wong, Jeff (10 July 2023). \"What leaders need to know about robot rights\". Fast Company.\\n\\n^ Hern, Alex (12 January 2017). \"Give robots \\'personhood\\' status, EU committee argues\". The Guardian. ISSN\\xa00261-3077. Archived from the original on 5 October 2024. Retrieved 23 February 2024.\\n\\n^ Dovey, Dana (14 April 2018). \"Experts Don\\'t Think Robots Should Have Rights\". Newsweek. Archived from the original on 5 October 2024. Retrieved 23 February 2024.\\n\\n^ Cuddy, Alice (13 April 2018). \"Robot rights violate human rights, experts warn EU\". euronews. Archived from the original on 19 September 2024. Retrieved 23 February 2024.\\n\\n^ The Intelligence explosion and technological singularity: Russell & Norvig (2021, pp.\\xa01004–1005), Omohundro (2008), Kurzweil (2005)\\nI. J. Good\\'s \"intelligence explosion\": Good (1965)\\nVernor Vinge\\'s \"singularity\": Vinge (1993)\\n\\n^ Russell & Norvig (2021), p.\\xa01005.\\n\\n^ Transhumanism: Moravec (1988), Kurzweil (2005), Russell & Norvig (2021, p.\\xa01005)\\n\\n^ AI as evolution: Edward Fredkin is quoted in McCorduck (2004, p.\\xa0401), Butler (1863), Dyson (1998)\\n\\n^ AI in myth: McCorduck (2004, pp.\\xa04–5)\\n\\n^ McCorduck (2004), pp.\\xa0340–400.\\n\\n^ Buttazzo (2001).\\n\\n^ Anderson (2008).\\n\\n^ McCauley (2007).\\n\\n^ Galvan (1997).\\n\\n\\nTextbooks\\n\\nLuger, George; Stubblefield, William (2004). Artificial Intelligence: Structures and Strategies for Complex Problem Solving (5th\\xa0ed.). Benjamin/Cummings. ISBN\\xa0978-0-8053-4780-7. Archived from the original on 26 July 2020. Retrieved 17 December 2019.\\nNilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN\\xa0978-1-5586-0467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nPoole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN\\xa0978-0-1951-0270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020. Later edition: Poole, David; Mackworth, Alan (2017). Artificial Intelligence: Foundations of Computational Agents (2nd\\xa0ed.). Cambridge University Press. ISBN\\xa0978-1-1071-9539-4. Archived from the original on 7 December 2017. Retrieved 6 December 2017.\\nRich, Elaine; Knight, Kevin; Nair, Shivashankar (2010). Artificial Intelligence (3rd\\xa0ed.). New Delhi: Tata McGraw Hill India. ISBN\\xa0978-0-0700-8770-5.\\nRussell, Stuart J.; Norvig, Peter (2021). Artificial Intelligence: A Modern Approach (4th\\xa0ed.). Hoboken: Pearson. ISBN\\xa0978-0-1346-1099-3. LCCN\\xa020190474.\\nRussell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd\\xa0ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN\\xa00-13-790395-2.\\n\\nHistory of AI\\n\\nCrevier, Daniel (1993). AI: The Tumultuous Search for Artificial Intelligence. New York, NY: BasicBooks. ISBN\\xa00-465-02997-3.\\nMcCorduck, Pamela (2004), Machines Who Think (2nd\\xa0ed.), Natick, Massachusetts: A. K. Peters, ISBN\\xa01-5688-1205-1\\nNewquist, H. P. (1994). The Brain Makers: Genius, Ego, And Greed In The Quest For Machines That Think. New York: Macmillan/SAMS. ISBN\\xa0978-0-6723-0412-5.\\n\\nOther sources\\n\\nAI & ML in Fusion\\nAI & ML in Fusion, video lecture Archived 2 July 2023 at the Wayback Machine\\nAlter, Alexandra; Harris, Elizabeth A. (20 September 2023), \"Franzen, Grisham and Other Prominent Authors Sue OpenAI\", The New York Times, archived from the original on 14 September 2024, retrieved 5 October 2024\\nAltman, Sam; Brockman, Greg; Sutskever, Ilya (22 May 2023). \"Governance of Superintelligence\". openai.com. Archived from the original on 27 May 2023. Retrieved 27 May 2023.\\nAnderson, Susan Leigh (2008). \"Asimov\\'s \\'three laws of robotics\\' and machine metaethics\". AI & Society. 22 (4): 477–493. doi:10.1007/s00146-007-0094-5.\\nAnderson, Michael; Anderson, Susan Leigh (2011). Machine Ethics. Cambridge University Press.\\nArntz, Melanie; Gregory, Terry; Zierahn, Ulrich (2016), \"The risk of automation for jobs in OECD countries: A comparative analysis\", OECD Social, Employment, and Migration Working Papers 189\\nAsada, M.; Hosoda, K.; Kuniyoshi, Y.; Ishiguro, H.; Inui, T.; Yoshikawa, Y.; Ogino, M.; Yoshida, C. (2009). \"Cognitive developmental robotics: a survey\". IEEE Transactions on Autonomous Mental Development. 1 (1): 12–34. Bibcode:2009ITAMD...1...12A. doi:10.1109/tamd.2009.2021702.\\n\"Ask the AI experts: What\\'s driving today\\'s progress in AI?\". McKinsey & Company. Archived from the original on 13 April 2018. Retrieved 13 April 2018.\\nBarfield, Woodrow; Pagallo, Ugo (2018). Research handbook on the law of artificial intelligence. Cheltenham, UK: Edward Elgar Publishing. ISBN\\xa0978-1-7864-3904-8. OCLC\\xa01039480085.\\nBeal, J.; Winston, Patrick (2009), \"The New Frontier of Human-Level Artificial Intelligence\", IEEE Intelligent Systems, 24 (4): 21–24, Bibcode:2009IISys..24d..21B, doi:10.1109/MIS.2009.75, hdl:1721.1/52357\\nBerdahl, Carl Thomas; Baker, Lawrence; Mann, Sean; Osoba, Osonde; Girosi, Federico (7 February 2023). \"Strategies to Improve the Impact of Artificial Intelligence on Health Equity: Scoping Review\". JMIR AI. 2 e42936. doi:10.2196/42936. PMC\\xa011041459. PMID\\xa038875587.\\nBerryhill, Jamie; Heang, Kévin Kok; Clogher, Rob; McBride, Keegan (2019). Hello, World: Artificial Intelligence and its Use in the Public Sector (PDF). Paris: OECD Observatory of Public Sector Innovation. Archived (PDF) from the original on 20 December 2019. Retrieved 9 August 2020.\\nBertini, Marco; Del Bimbo, Alberto; Torniai, Carlo (2006). \"Automatic annotation and semantic retrieval of video sequences using multimedia ontologies\". Proceedings of the 14th ACM international conference on Multimedia. pp.\\xa0679–682. doi:10.1145/1180639.1180782. ISBN\\xa01-59593-447-2.\\nBostrom, Nick (2014). Superintelligence: Paths, Dangers, Strategies. Oxford University Press.\\nBostrom, Nick (2015). \"What happens when our computers get smarter than we are?\". TED (conference). Archived from the original on 25 July 2020. Retrieved 30 January 2020.\\nBrooks, Rodney (10 November 2014). \"artificial intelligence is a tool, not a threat\". Rethink Robotics. Archived from the original on 12 November 2014.\\nBrooks, Rodney A. (1990). \"Elephants don\\'t play chess\". Robotics and Autonomous Systems. 6 (1–2): 3–15. doi:10.1016/S0921-8890(05)80025-9.\\nBuiten, Miriam C (2019). \"Towards Intelligent Regulation of Artificial Intelligence\". European Journal of Risk Regulation. 10 (1): 41–59. doi:10.1017/err.2019.8. ISSN\\xa01867-299X.\\nBushwick, Sophie (16 March 2023), \"What the New GPT-4 AI Can Do\", Scientific American, archived from the original on 22 August 2023, retrieved 5 October 2024\\nButler, Samuel (13 June 1863). \"Darwin among the Machines\". Letters to the Editor. The Press. Christchurch, New Zealand. Archived from the original on 19 September 2008. Retrieved 16 October 2014 – via Victoria University of Wellington.\\nButtazzo, G. (July 2001). \"Artificial consciousness: Utopia or real possibility?\". Computer. 34 (7): 24–30. Bibcode:2001Compr..34g..24B. doi:10.1109/2.933500.\\nCambria, Erik; White, Bebo (May 2014). \"Jumping NLP Curves: A Review of Natural Language Processing Research [Review Article]\". IEEE Computational Intelligence Magazine. 9 (2): 48–57. doi:10.1109/MCI.2014.2307227.\\nCellan-Jones, Rory (2 December 2014). \"Stephen Hawking warns artificial intelligence could end mankind\". BBC News. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nChalmers, David (1995). \"Facing up to the problem of consciousness\". Journal of Consciousness Studies. 2 (3): 200–219.\\nChalla, Subhash; Moreland, Mark R.; Mušicki, Darko; Evans, Robin J. (2011). Fundamentals of Object Tracking. Cambridge University Press. doi:10.1017/CBO9780511975837. ISBN\\xa0978-0-5218-7628-5.\\nChristian, Brian (2020). The Alignment Problem: Machine learning and human values. W. W. Norton & Company. ISBN\\xa0978-0-3938-6833-3. OCLC\\xa01233266753.\\nCiresan, D.; Meier, U.; Schmidhuber, J. (2012). \"Multi-column deep neural networks for image classification\". 2012 IEEE Conference on Computer Vision and Pattern Recognition. pp.\\xa03642–3649. arXiv:1202.2745. doi:10.1109/cvpr.2012.6248110. ISBN\\xa0978-1-4673-1228-8.\\nClark, Jack (2015b). \"Why 2015 Was a Breakthrough Year in Artificial Intelligence\". Bloomberg.com. Archived from the original on 23 November 2016. Retrieved 23 November 2016.\\nCNA (12 January 2019). \"Commentary: Bad news. Artificial intelligence is biased\". CNA. Archived from the original on 12 January 2019. Retrieved 19 June 2020.\\nCybenko, G. (1988). Continuous valued neural networks with two hidden layers are sufficient (Report). Department of Computer Science, Tufts University.\\nDeng, L.; Yu, D. (2014). \"Deep Learning: Methods and Applications\" (PDF). Foundations and Trends in Signal Processing. 7 (3–4): 197–387. doi:10.1561/2000000039. Archived (PDF) from the original on 14 March 2016. Retrieved 18 October 2014.\\nDennett, Daniel (1991). Consciousness Explained. The Penguin Press. ISBN\\xa0978-0-7139-9037-9.\\nDiFeliciantonio, Chase (3 April 2023). \"AI has already changed the world. This report shows how\". San Francisco Chronicle. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\\nDickson, Ben (2 May 2022). \"Machine learning: What is the transformer architecture?\". TechTalks. Archived from the original on 22 November 2023. Retrieved 22 November 2023.\\nDomingos, Pedro (2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN\\xa0978-0-4650-6570-7.\\nDreyfus, Hubert (1972). What Computers Can\\'t Do. New York: MIT Press. ISBN\\xa0978-0-0601-1082-6.\\nDreyfus, Hubert; Dreyfus, Stuart (1986). Mind over Machine: The Power of Human Intuition and Expertise in the Era of the Computer. Oxford: Blackwell. ISBN\\xa0978-0-0290-8060-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nDyson, George (1998). Darwin among the Machines. Allan Lane Science. ISBN\\xa0978-0-7382-0030-9. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nEdelson, Edward (1991). The Nervous System. New York: Chelsea House. ISBN\\xa0978-0-7910-0464-7. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nEdwards, Benj (17 May 2023). \"Poll: AI poses risk to humanity, according to majority of Americans\". Ars Technica. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\\nFearn, Nicholas (2007). The Latest Answers to the Oldest Questions: A Philosophical Adventure with the World\\'s Greatest Thinkers. New York: Grove Press. ISBN\\xa0978-0-8021-1839-4.\\nFord, Martin; Colvin, Geoff (6 September 2015). \"Will robots create more jobs than they destroy?\". The Guardian. Archived from the original on 16 June 2018. Retrieved 13 January 2018.\\nFox News (2023). \"Fox News Poll\" (PDF). Fox News. Archived (PDF) from the original on 12 May 2023. Retrieved 19 June 2023.\\nFrey, Carl Benedikt; Osborne, Michael A (2017). \"The future of employment: How susceptible are jobs to computerisation?\". Technological Forecasting and Social Change. 114: 254–280. doi:10.1016/j.techfore.2016.08.019.\\n\"From not working to neural networking\". The Economist. 2016. Archived from the original on 31 December 2016. Retrieved 26 April 2018.\\nGalvan, Jill (1 January 1997). \"Entering the Posthuman Collective in Philip K. Dick\\'s \"Do Androids Dream of Electric Sheep?\"\". Science Fiction Studies. 24 (3): 413–429. doi:10.1525/sfs.24.3.0413. JSTOR\\xa04240644.\\nGeist, Edward Moore (9 August 2015). \"Is artificial intelligence really an existential threat to humanity?\". Bulletin of the Atomic Scientists. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nGibbs, Samuel (27 October 2014). \"Elon Musk: artificial intelligence is our biggest existential threat\". The Guardian. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nGoffrey, Andrew (2008). \"Algorithm\". In Fuller, Matthew (ed.). Software studies: a lexicon. Cambridge, Mass.: MIT Press. pp.\\xa015–20. ISBN\\xa0978-1-4356-4787-9.\\nGoldman, Sharon (14 September 2022). \"10 years later, deep learning \\'revolution\\' rages on, say AI pioneers Hinton, LeCun and Li\". VentureBeat. Archived from the original on 5 October 2024. Retrieved 8 December 2023.\\nGood, I. J. (1965), Speculations Concerning the First Ultraintelligent Machine, archived from the original on 10 July 2023, retrieved 5 October 2024\\nGoodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016), Deep Learning, MIT Press., archived from the original on 16 April 2016, retrieved 12 November 2017\\nGoodman, Bryce; Flaxman, Seth (2017). \"EU regulations on algorithmic decision-making and a \\'right to explanation\\'\". AI Magazine. 38 (3): 50. arXiv:1606.08813. doi:10.1609/aimag.v38i3.2741.\\nGovernment Accountability Office (13 September 2022). Consumer Data: Increasing Use Poses Risks to Privacy. gao.gov (Report). Archived from the original on 13 September 2024. Retrieved 5 October 2024.\\nGrant, Nico; Hill, Kashmir (22 May 2023). \"Google\\'s Photo App Still Can\\'t Find Gorillas. And Neither Can Apple\\'s\". The New York Times. Archived from the original on 14 September 2024. Retrieved 5 October 2024.\\nGoswami, Rohan (5 April 2023). \"Here\\'s where the A.I. jobs are\". CNBC. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\\nHarari, Yuval Noah (October 2018). \"Why Technology Favors Tyranny\". The Atlantic. Archived from the original on 25 September 2021. Retrieved 23 September 2021.\\nHarari, Yuval Noah (2023). \"AI and the future of humanity\". YouTube. Archived from the original on 30 September 2024. Retrieved 5 October 2024.\\nHaugeland, John (1985). Artificial Intelligence: The Very Idea. Cambridge, Mass.: MIT Press. ISBN\\xa0978-0-2620-8153-5.\\nHinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition – The shared views of four research groups\". IEEE Signal Processing Magazine. 29 (6): 82–97. Bibcode:2012ISPM...29...82H. doi:10.1109/msp.2012.2205597.\\nHolley, Peter (28 January 2015). \"Bill Gates on dangers of artificial intelligence: \\'I don\\'t understand why some people are not concerned\\'\". The Washington Post. ISSN\\xa00190-8286. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nHornik, Kurt; Stinchcombe, Maxwell; White, Halbert (1989). Multilayer Feedforward Networks are Universal Approximators (PDF). Neural Networks. Vol.\\xa02. Pergamon Press. pp.\\xa0359–366. Archived (PDF) from the original on 21 April 2023. Retrieved 5 October 2024.\\nHorst, Steven (2005). \"The Computational Theory of Mind\". The Stanford Encyclopedia of Philosophy. Archived from the original on 6 March 2016. Retrieved 7 March 2016.\\nHowe, J. (November 1994). \"Artificial Intelligence at Edinburgh University: a Perspective\". Archived from the original on 15 May 2007. Retrieved 30 August 2007.\\nIGM Chicago (30 June 2017). \"Robots and Artificial Intelligence\". igmchicago.org. Archived from the original on 1 May 2019. Retrieved 3 July 2019.\\nIphofen, Ron; Kritikos, Mihalis (3 January 2019). \"Regulating artificial intelligence and robotics: ethics by design in a digital society\". Contemporary Social Science. 16 (2): 170–184. doi:10.1080/21582041.2018.1563803. ISSN\\xa02158-2041.\\nJordan, M. I.; Mitchell, T. M. (16 July 2015). \"Machine learning: Trends, perspectives, and prospects\". Science. 349 (6245): 255–260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID\\xa026185243.\\nKahneman, Daniel; Slovic, Paul; Tversky, Amos (1982). Judgment Under Uncertainty: Heuristics and Biases. Cambridge University Press.\\nKahneman, Daniel (2011). Thinking, Fast and Slow. Macmillan. ISBN\\xa0978-1-4299-6935-2. Archived from the original on 15 March 2023. Retrieved 8 April 2012.\\nKasperowicz, Peter (1 May 2023). \"Regulate AI? GOP much more skeptical than Dems that government can do it right: poll\". Fox News. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\\nKatz, Yarden (1 November 2012). \"Noam Chomsky on Where Artificial Intelligence Went Wrong\". The Atlantic. Archived from the original on 28 February 2019. Retrieved 26 October 2014.\\n\"Kismet\". MIT Artificial Intelligence Laboratory, Humanoid Robotics Group. Archived from the original on 17 October 2014. Retrieved 25 October 2014.\\nKissinger, Henry (1 November 2021). \"The Challenge of Being Human in the Age of AI\". The Wall Street Journal. Archived from the original on 4 November 2021. Retrieved 4 November 2021.\\nKobielus, James (27 November 2019). \"GPUs Continue to Dominate the AI Accelerator Market for Now\". InformationWeek. Archived from the original on 19 October 2021. Retrieved 11 June 2020.\\nKuperman, G. J.; Reichley, R. M.; Bailey, T. C. (1 July 2006). \"Using Commercial Knowledge Bases for Clinical Decision Support: Opportunities, Hurdles, and Recommendations\". Journal of the American Medical Informatics Association. 13 (4): 369–371. doi:10.1197/jamia.M2055. PMC\\xa01513681. PMID\\xa016622160.\\nKurzweil, Ray (2005). The Singularity is Near. Penguin Books. ISBN\\xa0978-0-6700-3384-3.\\nLangley, Pat (2011). \"The changing science of machine learning\". Machine Learning. 82 (3): 275–279. doi:10.1007/s10994-011-5242-y.\\nLarson, Jeff; Angwin, Julia (23 May 2016). \"How We Analyzed the COMPAS Recidivism Algorithm\". ProPublica. Archived from the original on 29 April 2019. Retrieved 19 June 2020.\\nLaskowski, Nicole (November 2023). \"What is Artificial Intelligence and How Does AI Work? TechTarget\". Enterprise AI. Archived from the original on 5 October 2024. Retrieved 30 October 2023.\\nLaw Library of Congress (U.S.). Global Legal Research Directorate, issuing body. (2019). Regulation of artificial intelligence in selected jurisdictions. LCCN\\xa02019668143. OCLC\\xa01110727808.\\nLee, Timothy B. (22 August 2014). \"Will artificial intelligence destroy humanity? Here are 5 reasons not to worry\". Vox. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nLenat, Douglas; Guha, R. V. (1989). Building Large Knowledge-Based Systems. Addison-Wesley. ISBN\\xa0978-0-2015-1752-1.\\nLighthill, James (1973). \"Artificial Intelligence: A General Survey\". Artificial Intelligence: a paper symposium. Science Research Council.\\nLipartito, Kenneth (6 January 2011), The Narrative and the Algorithm: Genres of Credit Reporting from the Nineteenth Century to Today (PDF) (Unpublished manuscript), SSRN\\xa01736283, archived (PDF) from the original on 9 October 2022\\nLohr, Steve (2017). \"Robots Will Take Jobs, but Not as Fast as Some Fear, New Report Says\". The New York Times. Archived from the original on 14 January 2018. Retrieved 13 January 2018.\\nLungarella, M.; Metta, G.; Pfeifer, R.; Sandini, G. (2003). \"Developmental robotics: a survey\". Connection Science. 15 (4): 151–190. Bibcode:2003ConSc..15..151L. doi:10.1080/09540090310001655110.\\n\"Machine Ethics\". aaai.org. Archived from the original on 29 November 2014.\\nMadrigal, Alexis C. (27 February 2015). \"The case against killer robots, from a guy actually working on artificial intelligence\". Fusion.net. Archived from the original on 4 February 2016. Retrieved 31 January 2016.\\nMahdawi, Arwa (26 June 2017). \"What jobs will still be around in 20 years? Read this to prepare your future\". The Guardian. Archived from the original on 14 January 2018. Retrieved 13 January 2018.\\nMaker, Meg Houston (2006), AI@50: AI Past, Present, Future, Dartmouth College, archived from the original on 8 October 2008, retrieved 16 October 2008\\nMarmouyet, Françoise (15 December 2023). \"Google\\'s Gemini: is the new AI model really better than ChatGPT?\". The Conversation. Archived from the original on 4 March 2024. Retrieved 25 December 2023.\\nMinsky, Marvin (1986), The Society of Mind, Simon and Schuster\\nMcCarthy, John; Minsky, Marvin; Rochester, Nathan; Shannon, Claude (1955). \"A Proposal for the Dartmouth Summer Research Project on Artificial Intelligence\". stanford.edu. Archived from the original on 26 August 2007. Retrieved 30 August 2007.\\nMcCarthy, John (2007), \"From Here to Human-Level AI\", Artificial Intelligence, p.\\xa0171\\nMcCarthy, John (1999), What is AI?, archived from the original on 4 December 2022, retrieved 4 December 2022\\nMcCauley, Lee (2007). \"AI armageddon and the three laws of robotics\". Ethics and Information Technology. 9 (2): 153–164. doi:10.1007/s10676-007-9138-2. ProQuest\\xa0222198675.\\nMcGarry, Ken (1 December 2005). \"A survey of interestingness measures for knowledge discovery\". The Knowledge Engineering Review. 20 (1): 39–61. doi:10.1017/S0269888905000408.\\nMcGaughey, Ewan (2022). \"Will Robots Automate Your Job Away? Full Employment, Basic Income and Economic Democracy\". Industrial Law Journal. 51 (3): 511–559. doi:10.1093/indlaw/dwab010. SSRN\\xa03044448.\\nMerkle, Daniel; Middendorf, Martin (2013). \"Swarm Intelligence\". In Burke, Edmund K.; Kendall, Graham (eds.). Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques. Springer Science & Business Media. ISBN\\xa0978-1-4614-6940-7.\\nMinsky, Marvin (1967), Computation: Finite and Infinite Machines, Englewood Cliffs, N.J.: Prentice-Hall\\nMoravec, Hans (1988). Mind Children. Harvard University Press. ISBN\\xa0978-0-6745-7616-2. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nMorgenstern, Michael (9 May 2015). \"Automation and anxiety\". The Economist. Archived from the original on 12 January 2018. Retrieved 13 January 2018.\\nMüller, Vincent C.; Bostrom, Nick (2014). \"Future Progress in Artificial Intelligence: A Poll Among Experts\". AI Matters. 1 (1): 9–11. doi:10.1145/2639475.2639478.\\nNeumann, Bernd; Möller, Ralf (January 2008). \"On scene interpretation with description logics\". Image and Vision Computing. 26 (1): 82–101. doi:10.1016/j.imavis.2007.08.013.\\nNilsson, Nils (1995), \"Eyes on the Prize\", AI Magazine, vol.\\xa016, pp.\\xa09–17\\nNewell, Allen; Simon, H. A. (1976). \"Computer Science as Empirical Inquiry: Symbols and Search\". Communications of the ACM. 19 (3): 113–126. doi:10.1145/360018.360022.\\nNicas, Jack (7 February 2018). \"How YouTube Drives People to the Internet\\'s Darkest Corners\". The Wall Street Journal. ISSN\\xa00099-9660. Archived from the original on 5 October 2024. Retrieved 16 June 2018.\\nNilsson, Nils (1983). \"Artificial Intelligence Prepares for 2001\" (PDF). AI Magazine. 1 (1). Archived (PDF) from the original on 17 August 2020. Retrieved 22 August 2020. Presidential Address to the Association for the Advancement of Artificial Intelligence.\\nNRC (United States National Research Council) (1999). \"Developments in Artificial Intelligence\". Funding a Revolution: Government Support for Computing Research. National Academies Press. ISBN\\xa0978-0-309-52501-5.\\nOmohundro, Steve (2008). The Nature of Self-Improving Artificial Intelligence (PDF). 2007 Singularity Summit. San Francisco, CA.\\nOudeyer, P-Y. (2010). \"On the impact of robotics in behavioral and cognitive sciences: from insect navigation to human cognitive development\". IEEE Transactions on Autonomous Mental Development. 2 (1): 2–16. Bibcode:2010ITAMD...2....2O. doi:10.1109/tamd.2009.2039057.\\nPennachin, C.; Goertzel, B. (2007). \"Contemporary Approaches to Artificial General Intelligence\". Artificial General Intelligence. Cognitive Technologies. Berlin, Heidelberg: Springer. pp.\\xa01–30. doi:10.1007/978-3-540-68677-4_1. ISBN\\xa0978-3-5402-3733-4.\\nPinker, Steven (2007) [1994], The Language Instinct, Perennial Modern Classics, Harper, ISBN\\xa0978-0-0613-3646-1\\nPoria, Soujanya; Cambria, Erik; Bajpai, Rajiv; Hussain, Amir (September 2017). \"A review of affective computing: From unimodal analysis to multimodal fusion\". Information Fusion. 37: 98–125. Bibcode:2017InfFu..37...98P. doi:10.1016/j.inffus.2017.02.003. hdl:1893/25490.\\nRawlinson, Kevin (29 January 2015). \"Microsoft\\'s Bill Gates insists AI is a threat\". BBC News. Archived from the original on 29 January 2015. Retrieved 30 January 2015.\\nReisner, Alex (19 August 2023), \"Revealed: The Authors Whose Pirated Books are Powering Generative AI\", The Atlantic, archived from the original on 3 October 2024, retrieved 5 October 2024\\nRoberts, Jacob (2016). \"Thinking Machines: The Search for Artificial Intelligence\". Distillations. Vol.\\xa02, no.\\xa02. pp.\\xa014–23. Archived from the original on 19 August 2018. Retrieved 20 March 2018.\\nRobitzski, Dan (5 September 2018). \"Five experts share what scares them the most about AI\". Futurism. Archived from the original on 8 December 2019. Retrieved 8 December 2019.\\nRose, Steve (11 July 2023). \"AI Utopia or dystopia?\". The Guardian Weekly. pp.\\xa042–43.\\nRussell, Stuart (2019). Human Compatible: Artificial Intelligence and the Problem of Control. United States: Viking. ISBN\\xa0978-0-5255-5861-3. OCLC\\xa01083694322.\\nSainato, Michael (19 August 2015). \"Stephen Hawking, Elon Musk, and Bill Gates Warn About Artificial Intelligence\". Observer. Archived from the original on 30 October 2015. Retrieved 30 October 2015.\\nSample, Ian (5 November 2017). \"Computer says no: why making AIs fair, accountable and transparent is crucial\". The Guardian. Archived from the original on 10 October 2022. Retrieved 30 January 2018.\\nRothman, Denis (7 October 2020). \"Exploring LIME Explanations and the Mathematics Behind It\". Codemotion. Archived from the original on 25 November 2023. Retrieved 25 November 2023.\\nScassellati, Brian (2002). \"Theory of mind for a humanoid robot\". Autonomous Robots. 12 (1): 13–24. doi:10.1023/A:1013298507114.\\nSchmidhuber, J. (2015). \"Deep Learning in Neural Networks: An Overview\". Neural Networks. 61: 85–117. arXiv:1404.7828. Bibcode:2015NN.....61...85S. doi:10.1016/j.neunet.2014.09.003. PMID\\xa025462637.\\nSchmidhuber, Jürgen (2022). \"Annotated History of Modern AI and Deep Learning\". Archived from the original on 7 August 2023. Retrieved 5 October 2024.\\nSearle, John (1980). \"Minds, Brains and Programs\". Behavioral and Brain Sciences. 3 (3): 417–457. doi:10.1017/S0140525X00005756.\\nSearle, John (1999). Mind, language and society. New York: Basic Books. ISBN\\xa0978-0-4650-4521-1. OCLC\\xa0231867665. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nSimon, H. A. (1965), The Shape of Automation for Men and Management, New York: Harper & Row, OCLC\\xa01483817127\\nSimonite, Tom (31 March 2016). \"How Google Plans to Solve Artificial Intelligence\". MIT Technology Review. Archived from the original on 16 September 2024. Retrieved 5 October 2024.\\nSmith, Craig S. (15 March 2023). \"ChatGPT-4 Creator Ilya Sutskever on AI Hallucinations and AI Democracy\". Forbes. Archived from the original on 18 September 2024. Retrieved 25 December 2023.\\nSmoliar, Stephen W.; Zhang, HongJiang (1994). \"Content based video indexing and retrieval\". IEEE MultiMedia. 1 (2): 62–72. doi:10.1109/93.311653.\\nSolomonoff, Ray (1956). An Inductive Inference Machine (PDF). Dartmouth Summer Research Conference on Artificial Intelligence. Archived (PDF) from the original on 26 April 2011. Retrieved 22 March 2011 – via std.com, pdf scanned copy of the original. Later published asSolomonoff, Ray (1957). \"An Inductive Inference Machine\". IRE Convention Record. Vol.\\xa0Section on Information Theory, part 2. pp.\\xa056–62.\\nStanford University (2023). \"Artificial Intelligence Index Report 2023/Chapter 6: Policy and Governance\" (PDF). AI Index. Archived (PDF) from the original on 19 June 2023. Retrieved 19 June 2023.\\nStewart, Jon (9 October 2025). \"AI: What Could Go Wrong? With Geoffrey Hinton\". The Weekly Show with Jon Stewart (Podcast).\\nTao, Jianhua; Tan, Tieniu (2005). Affective Computing and Intelligent Interaction. Affective Computing: A Review. Lecture Notes in Computer Science. Vol.\\xa03784. Springer. pp.\\xa0981–995. doi:10.1007/11573548. ISBN\\xa0978-3-5402-9621-8.\\nTaylor, Josh; Hern, Alex (2 May 2023). \"\\'Godfather of AI\\' Geoffrey Hinton quits Google and warns over dangers of misinformation\". The Guardian. Archived from the original on 5 October 2024. Retrieved 5 October 2024.\\nThompson, Derek (23 January 2014). \"What Jobs Will the Robots Take?\". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018.\\nThro, Ellen (1993). Robotics: The Marriage of Computers and Machines. New York: Facts on File. ISBN\\xa0978-0-8160-2628-9. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nToews, Rob (3 September 2023). \"Transformers Revolutionized AI. What Will Replace Them?\". Forbes. Archived from the original on 8 December 2023. Retrieved 8 December 2023.\\nTuring, Alan (October 1950). \"Computing Machinery and Intelligence\". Mind. 59 (236): 433–460. doi:10.1093/mind/LIX.236.433. ISSN\\xa01460-2113. JSTOR\\xa02251299. S2CID\\xa014636783.\\nUNESCO Science Report: the Race Against Time for Smarter Development. Paris: UNESCO. 2021. ISBN\\xa0978-9-2310-0450-6. Archived from the original on 18 June 2022. Retrieved 18 September 2021.\\nUrbina, Fabio; Lentzos, Filippa; Invernizzi, Cédric; Ekins, Sean (7 March 2022). \"Dual use of artificial-intelligence-powered drug discovery\". Nature Machine Intelligence. 4 (3): 189–191. doi:10.1038/s42256-022-00465-9. PMC\\xa09544280. PMID\\xa036211133.\\nValance, Christ (30 May 2023). \"Artificial intelligence could lead to extinction, experts warn\". BBC News. Archived from the original on 17 June 2023. Retrieved 18 June 2023.\\nValinsky, Jordan (11 April 2019), \"Amazon reportedly employs thousands of people to listen to your Alexa conversations\", CNN.com, archived from the original on 26 January 2024, retrieved 5 October 2024\\nVerma, Yugesh (25 December 2021). \"A Complete Guide to SHAP – SHAPley Additive exPlanations for Practitioners\". Analytics India Magazine. Archived from the original on 25 November 2023. Retrieved 25 November 2023.\\nVincent, James (7 November 2019). \"OpenAI has published the text-generating AI it said was too dangerous to share\". The Verge. Archived from the original on 11 June 2020. Retrieved 11 June 2020.\\nVincent, James (15 November 2022). \"The scary truth about AI copyright is nobody knows what will happen next\". The Verge. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\\nVincent, James (3 April 2023). \"AI is entering an era of corporate control\". The Verge. Archived from the original on 19 June 2023. Retrieved 19 June 2023.\\nVinge, Vernor (1993). \"The Coming Technological Singularity: How to Survive in the Post-Human Era\". Vision 21: Interdisciplinary Science and Engineering in the Era of Cyberspace: 11. Bibcode:1993vise.nasa...11V. Archived from the original on 1 January 2007. Retrieved 14 November 2011.\\nWaddell, Kaveh (2018). \"Chatbots Have Entered the Uncanny Valley\". The Atlantic. Archived from the original on 24 April 2018. Retrieved 24 April 2018.\\nWallach, Wendell (2010). Moral Machines. Oxford University Press.\\nWason, P. C.; Shapiro, D. (1966). \"Reasoning\". In Foss, B. M. (ed.). New horizons in psychology. Harmondsworth: Penguin. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nWeng, J.; McClelland; Pentland, A.; Sporns, O.; Stockman, I.; Sur, M.; Thelen, E. (2001). \"Autonomous mental development by robots and animals\". Science. 291 (5504): 599–600. doi:10.1126/science.291.5504.599. PMID\\xa011229402.\\n\"What is \\'fuzzy logic\\'? Are there computers that are inherently fuzzy and do not apply the usual binary logic?\". Scientific American. 21 October 1999. Archived from the original on 6 May 2018. Retrieved 5 May 2018.\\nWilliams, Rhiannon (28 June 2023), \"Humans may be more likely to believe disinformation generated by AI\", MIT Technology Review, archived from the original on 16 September 2024, retrieved 5 October 2024\\nWirtz, Bernd W.; Weyerer, Jan C.; Geyer, Carolin (24 July 2018). \"Artificial Intelligence and the Public Sector – Applications and Challenges\". International Journal of Public Administration. 42 (7): 596–615. doi:10.1080/01900692.2018.1498103.\\nWong, Matteo (19 May 2023), \"ChatGPT Is Already Obsolete\", The Atlantic, archived from the original on 18 September 2024, retrieved 5 October 2024\\nYudkowsky, E (2008), \"Artificial Intelligence as a Positive and Negative Factor in Global Risk\" (PDF), Global Catastrophic Risks, Oxford University Press, 2008, Bibcode:2008gcr..book..303Y, archived (PDF) from the original on 19 October 2013, retrieved 24 September 2021\\n\\nExternal links\\n\\n\\nArtificial intelligence  at Wikipedia\\'s sister projects\\n\\nDefinitions from WiktionaryMedia from CommonsQuotations from WikiquoteTextbooks from WikibooksResources from WikiversityData from Wikidata\\n\\n\\n\\n\\nScholia has a topic profile for Artificial intelligence.\\n\\nHauser, Larry. \"Artificial Intelligence\". In Fieser, James; Dowden, Bradley (eds.). Internet Encyclopedia of Philosophy. ISSN\\xa02161-0002. OCLC\\xa037741658.\\nvteArtificial intelligence (AI)\\nHistory\\ntimeline\\nGlossary\\nCompanies\\nProjects\\nConcepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nPolicy gradient\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nUncanny valley\\nRLHF\\nSelf-supervised learning\\nReflection\\nRecursive self-improvement\\nHallucination\\nWord embedding\\nVibe coding\\nSafety (Alignment)\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge\\nNMT\\nReasoning\\nModel Context Protocol\\nIntelligent agent\\nArtificial human companion\\nHumanity\\'s Last Exam\\nLethal autonomous weapons (LAWs)\\nGenerative artificial intelligence (GenAI)\\n(Hypothetical: Artificial general intelligence (AGI))\\n(Hypothetical: Artificial superintelligence (ASI))\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nComputer vision\\nSpeech synthesis\\n15.ai\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nGPT Image\\nIdeogram\\nImagen\\nMidjourney\\nRecraft\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nRunway Gen\\nHailuo AI\\nKling\\nSora\\nVeo\\nMusic generation\\nRiffusion\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\n4.5\\n4.1\\no4-mini\\n5\\n5.1\\n5.2\\nClaude\\nGemini\\nGemini (language model)\\nGemma\\nGrok\\nLaMDA\\nBLOOM\\nDBRX\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDeepSeek\\nQwen\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nChristopher D. Manning\\nClaude Shannon\\nShun\\'ichi Amari\\nKunihiko Fukushima\\nTakeo Kanade\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nGeoffrey Hinton\\nJohn Hopfield\\nJürgen Schmidhuber\\nYann LeCun\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nJames Goodnight\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nOriol Vinyals\\nQuoc V. Le\\nIan Goodfellow\\nDemis Hassabis\\nDavid Silver\\nAndrej Karpathy\\nAshish Vaswani\\nNoam Shazeer\\nAidan Gomez\\nJohn Schulman\\nMustafa Suleyman\\nJan Leike\\nDaniel Kokotajlo\\nFrançois Chollet\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)\\nPolitical\\nRegulation of artificial intelligence\\nEthics of artificial intelligence\\nPrecautionary principle\\nAI alignment\\nEU Artificial Intelligence Act (AI Act)\\n\\n Category\\n\\nArticles related to artificial intelligence\\nvteJohn McCarthy\\nArtificial intelligence\\nCircumscription\\nDartmouth workshop\\nFrame problem\\nGarbage collection\\nLisp\\nALGOL 60\\nMcCarthy evaluation\\nMcCarthy Formalism\\nMcCarthy 91 function\\nSituation calculus\\nSpace fountain\\n\\nvtePhilosophy of mindPhilosophers\\nG. E. M. Anscombe\\nAristotle\\nArmstrong\\nThomas Aquinas\\nJ. L. Austin\\nAlexander Bain\\nGeorge Berkeley\\nHenri Bergson\\nNed Block\\nFranz Brentano\\nC. D. Broad\\nTyler Burge\\nDavid Chalmers\\nPatricia Churchland\\nPaul Churchland\\nAndy Clark\\nDharmakirti\\nDonald Davidson\\nDaniel Dennett\\nRené Descartes\\nFred Dretske\\nFodor\\nGoldman\\nMartin Heidegger\\nDavid Hume\\nEdmund Husserl\\nWilliam James\\nFrank Cameron Jackson\\nImmanuel Kant\\nDavid Lewis (philosopher)\\nJohn Locke\\nGottfried Wilhelm Leibniz\\nMaurice Merleau-Ponty\\nMarvin Minsky\\nThomas Nagel\\nAlva Noë\\nDerek Parfit\\nPlato\\nHilary Putnam\\nRichard Rorty\\nGilbert Ryle\\nJohn Searle\\nWilfrid Sellars\\nBaruch Spinoza\\nAlan Turing\\nMichael Tye\\nVasubandhu\\nLudwig Wittgenstein\\nStephen Yablo\\nZhuangzi\\nmore...\\nTheories\\nBehaviorism\\nBiological naturalism\\nDualism\\nEliminative materialism\\nEmergent materialism\\nEpiphenomenalism\\nFunctionalism\\nInteractionism\\nNaïve realism\\nNeurophenomenology\\nNeutral monism\\nNew mysterianism\\nNondualism\\nOccasionalism\\nParallelism\\nPhenomenalism\\nPhenomenology\\nPhysicalism\\nType physicalism\\nProperty dualism\\nRepresentational\\nSolipsism\\nSubstance dualism\\nConcepts\\nAbstract object\\nAnimal machine\\nChinese room\\nCreativity\\nCognition\\nCognitive closure\\nConcept\\nConsciousness\\nHard problem of consciousness\\nHypostatic abstraction\\nIdea\\nIdentity\\nIntelligence\\nArtificial\\nHuman\\nIntentionality\\nIntrospection\\nIntuition\\nLanguage of thought\\nMental event\\nMental image\\nMental process\\nMental property\\nMental representation\\nMind\\nMind–body problem\\nPain\\nProblem of other minds\\nPropositional attitude\\nQualia\\nTabula rasa\\nUnderstanding\\nZombie\\nRelated\\nMetaphysics\\nPhilosophy of artificial intelligence\\xa0/ information\\xa0/ perception\\xa0/ self\\n\\nCategory\\nPhilosophers category\\nProject\\nTask Force\\n\\nvtePhilosophy of scienceConcepts\\nAnalysis\\nAnalytic–synthetic distinction\\nA priori and a posteriori\\nCausality\\nMill\\'s Methods\\nCommensurability\\nConsilience\\nConstruct\\nCorrelation\\nfunction\\nCreative synthesis\\nDemarcation problem\\nEmpirical evidence\\nExperiment\\ndesign\\nThought\\nExplanatory power\\nFact\\nFalsifiability\\nFeminist method\\nFunctional contextualism\\nHypothesis\\nalternative\\nnull\\nIgnoramus et ignorabimus\\nInductive reasoning\\nIntertheoretic reduction\\nInquiry\\nMeasurement\\nNature\\nObjectivity\\nObservation\\nParadigm\\nProblem of induction\\nResearch\\nScientific evidence\\nEvidence-based practice\\nScientific law\\nScientific method\\nScientific pluralism\\nScientific Revolution\\nTestability\\nTheory\\nchoice\\nladenness\\nscientific\\nUnderdetermination\\nUnity of science\\nVariable\\ncontrol\\ndependent and independent\\nTheories\\nCoherentism\\nConfirmation holism\\nConstructive empiricism\\nConstructive realism\\nConstructivist epistemology\\nContextualism\\nConventionalism\\nDeductive-nomological model\\nEpistemological anarchism\\nEvolutionism\\nFallibilism\\nFoundationalism\\nHypothetico-deductive model\\nInductionism\\nInstrumentalism\\nModel-dependent realism\\nNaturalism\\nPhysicalism\\nPositivism\\xa0/ Reductionism\\xa0/ Determinism\\nPragmatism\\nRationalism\\xa0/ Empiricism\\nReceived view\\xa0/ Semantic view of theories\\nScientific essentialism\\nScientific formalism\\nScientific realism\\xa0/ Anti-realism\\nScientific skepticism\\nScientism\\nStructuralism\\nUniformitarianism\\nVerificationism\\nVitalism\\nPhilosophy of...\\nBiology\\nChemistry\\nPhysics\\nSpace and time\\nSocial science\\nArchaeology\\nEconomics\\nGeography\\nHistory\\nLinguistics\\nPsychology\\nRelated topics\\nCriticism of science\\nDescriptive science\\nEpistemology\\nExact sciences\\nFaith and rationality\\nHard and soft science\\nHistory and philosophy of science\\nNon-science\\nPseudoscience\\nNormative science\\nProtoscience\\nQuestionable cause\\nRelationship between religion and science\\nRhetoric of science\\nScience studies\\nSociology of scientific ignorance\\nSociology of scientific knowledge\\nPhilosophers of sciencePrecursors\\nRoger Bacon\\nFrancis Bacon\\nGalileo Galilei\\nIsaac Newton\\nDavid Hume\\n\\nAuguste Comte\\nHenri Poincaré\\nPierre Duhem\\nRudolf Steiner\\nKarl Pearson\\nCharles Sanders Peirce\\nWilhelm Windelband\\nAlfred North Whitehead\\nBertrand Russell\\nOtto Neurath\\nC. D. Broad\\nMichael Polanyi\\nHans Reichenbach\\nRudolf Carnap\\nKarl Popper\\nCarl Gustav Hempel\\nW. V. O. Quine\\nThomas Kuhn\\nImre Lakatos\\nPaul Feyerabend\\nIan Hacking\\nBas van Fraassen\\nLarry Laudan\\n Category\\n Philosophy portal\\n Science portal\\n\\nvteEvolutionary computationMain Topics\\nEvolutionary algorithm\\nEvolutionary data mining\\nEvolutionary multimodal optimization\\nHuman-based evolutionary computation\\nInteractive evolutionary computation\\nAlgorithms\\nCellular evolutionary algorithm\\nCovariance Matrix Adaptation Evolution Strategy (CMA-ES)\\nCultural algorithm\\nDifferential evolution\\nEvolutionary programming\\nGenetic algorithm\\nGenetic programming\\nGene expression programming\\nEvolution strategy\\nNatural evolution strategy\\nNeuroevolution\\nLearning classifier system\\nRelated techniques\\nSwarm intelligence\\nAnt colony optimization\\nBees algorithm\\nCuckoo search\\nParticle swarm optimization\\nBacterial Colony Optimization\\nMetaheuristic methods\\nFirefly algorithm\\nHarmony search\\nGaussian adaptation\\nMemetic algorithm\\nRelated topics\\nArtificial development\\nArtificial intelligence\\nArtificial life\\nDigital organism\\nEvolutionary robotics\\nFitness function\\nFitness landscape\\nFitness approximation\\nGenetic operators\\nInteractive evolutionary computation\\nNo free lunch in search and optimization\\nMachine learning\\nMating pool\\nPremature convergence\\nProgram synthesis\\nOrganizations\\nACM\\nIEEE\\nACM SIGEVO\\nIEEE CIS\\nConferences\\nCEC\\nGECCO\\nPPSN\\nEvoStar\\nFOGA\\nJournals\\nEvolutionary Computation (journal)\\nIEEE Trans Evol Comput\\nACM Trans Evol Learning Optim\\n\\nvteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware\\nPrinted circuit board\\nPeripheral\\nIntegrated circuit\\nVery-large-scale integration\\nSystem on a chip (SoC)\\nEnergy consumption (green computing)\\nElectronic design automation\\nHardware acceleration\\nProcessor\\nSize / Form\\nComputer systems organization\\nComputer architecture\\nComputational complexity\\nDependability\\nEmbedded system\\nReal-time computing\\nCyber-physical system\\nFault tolerance\\nWireless sensor network\\nNetworks\\nNetwork architecture\\nNetwork protocol\\nNetwork components\\nNetwork scheduler\\nNetwork performance evaluation\\nNetwork service\\nSoftware organization\\nInterpreter\\nMiddleware\\nVirtual machine\\nOperating system\\nSoftware quality\\nSoftware notations and tools\\nProgramming paradigm\\nProgramming language\\nCompiler\\nDomain-specific language\\nModeling language\\nSoftware framework\\nIntegrated development environment\\nSoftware configuration management\\nSoftware library\\nSoftware repository\\nSoftware development\\nControl flow\\nSoftware development process\\nRequirements analysis\\nSoftware design\\nSoftware construction\\nSoftware deployment\\nSoftware engineering\\nSoftware maintenance\\nProgramming team\\nOpen-source model\\nTheory of computation\\nModel of computation\\nStochastic\\nFormal language\\nAutomata theory\\nComputability theory\\nComputational complexity theory\\nLogic\\nSemantics\\nAlgorithms\\nAlgorithm design\\nAnalysis of algorithms\\nAlgorithmic efficiency\\nRandomized algorithm\\nComputational geometry\\nMathematics of computing\\nDiscrete mathematics\\nProbability\\nStatistics\\nMathematical software\\nInformation theory\\nMathematical analysis\\nNumerical analysis\\nTheoretical computer science\\nComputational problem\\nInformation systems\\nDatabase management system\\nInformation storage systems\\nEnterprise information system\\nSocial information systems\\nGeographic information system\\nDecision support system\\nProcess control system\\nMultimedia information system\\nData mining\\nDigital library\\nComputing platform\\nDigital marketing\\nWorld Wide Web\\nInformation retrieval\\nSecurity\\nCryptography\\nFormal methods\\nSecurity hacker\\nSecurity services\\nIntrusion detection system\\nHardware security\\nNetwork security\\nInformation security\\nApplication security\\nHuman-centered computing\\nInteraction design\\nAugmented reality\\nVirtual reality\\nSocial computing\\nUbiquitous computing\\nVisualization\\nAccessibility\\nHuman–computer interaction\\nMobile computing\\nConcurrency\\nConcurrent computing\\nParallel computing\\nDistributed computing\\nMultithreading\\nMultiprocessing\\nArtificial intelligence\\nNatural language processing\\nKnowledge representation and reasoning\\nComputer vision\\nAutomated planning and scheduling\\nSearch methodology\\nControl method\\nPhilosophy of artificial intelligence\\nDistributed artificial intelligence\\nMachine learning\\nSupervised learning\\nUnsupervised learning\\nReinforcement learning\\nMulti-task learning\\nCross-validation\\nGraphics\\nAnimation\\nRendering\\nPhotograph manipulation\\nGraphics processing unit\\nImage compression\\nSolid modeling\\nApplied computing\\nQuantum computing\\nE-commerce\\nEnterprise software\\nComputational mathematics\\nComputational physics\\nComputational chemistry\\nComputational biology\\nComputational social science\\nComputational engineering\\nDifferentiable computing\\nComputational healthcare\\nDigital art\\nElectronic publishing\\nCyberwarfare\\nElectronic voting\\nVideo games\\nWord processing\\nOperations research\\nEducational technology\\nDocument management\\nSpecialized Platform\\nDevelopment\\nThermodynamic computing\\n\\n Category\\n Outline\\n Glossaries\\n\\nvteEmerging technologiesFieldsInformation andcommunications\\nAmbient intelligence\\nInternet of things\\nArtificial intelligence\\nApplications of artificial intelligence\\nMachine translation\\nMachine vision\\nMobile translation\\nProgress in artificial intelligence\\nSemantic Web\\nSpeech recognition\\nAtomtronics\\nCarbon nanotube field-effect transistor\\nCybermethodology\\nAugmented reality\\nFourth-generation optical discs\\n3D optical data storage\\nHolographic data storage\\nGPGPU\\nMemory\\nCBRAM\\nECRAM\\nFRAM\\nMillipede\\nMRAM\\nNRAM\\nPRAM\\nRacetrack memory\\nRRAM\\nSONOS\\nUltraRAM\\nOptical computing\\nRFID\\nChipless RFID\\nSoftware-defined radio\\nThree-dimensional integrated circuit\\nTopics\\nAutomation\\nCollingridge dilemma\\nDifferential technological development\\nDisruptive innovation\\nEphemeralization\\nEthics\\nAI\\nBioethics\\nCyberethics\\nNeuroethics\\nRobot ethics\\nExploratory engineering\\nProactionary principle\\nTechnological change\\nTechnological unemployment\\nTechnological convergence\\nTechnological evolution\\nTechnological paradigm\\nTechnology forecasting\\nAccelerating change\\nFuture-oriented technology analysis\\nHorizon scanning\\nMoore\\'s law\\nTechnological singularity\\nTechnology scouting\\nTechnology in science fiction\\nTechnology readiness level\\nTechnology roadmap\\nTranshumanism\\n\\n List\\n\\nvteRoboticsMain articles\\nOutline\\nGlossary\\nIndex\\nHistory\\nGeography\\nHall of Fame\\nEthics\\nLaws\\nCompetitions\\nAI competitions\\nTypes\\nAerobot\\nAnthropomorphic\\nHumanoid\\nAndroid\\nCyborg\\nGynoid\\nClaytronics\\nCompanion\\nAutomaton\\nAnimatronic\\nAudio-Animatronics\\nIndustrial\\nArticulated\\narm\\nDomestic\\nEducational\\nEntertainment\\nJuggling\\nMilitary\\nMedical\\nService\\nDisability\\nAgricultural\\nFood service\\nRetail\\nBEAM robotics\\nSoft robotics\\nClassifications\\nBiorobotics\\nCloud robotics\\nContinuum robot\\nUnmanned vehicle\\naerial\\nground\\nMobile robot\\nMicrobotics\\nNanorobotics\\nNecrobotics\\nRobotic spacecraft\\nSpace probe\\nSwarm\\nTelerobotics\\nUnderwater\\nremotely-operated\\nRobotic fish\\nLocomotion\\nTracks\\nWalking\\nHexapod\\nClimbing\\nElectric unicycle\\nRobotic fins\\nNavigation and mapping\\nMotion planning\\nSimultaneous localization and mapping\\nVisual odometry\\nVision-guided robot systems\\nResearch\\nEvolutionary\\nKits\\nSimulator\\nSuite\\nOpen-source\\nSoftware\\nAdaptable\\nDevelopmental\\nHuman–robot interaction\\nParadigms\\nPerceptual\\nSituated\\nUbiquitous\\nCompanies\\nABB\\nAmazon Robotics\\nAnybots\\nBarrett Technology\\nBoston Dynamics\\nDoosan Robotics\\nEnergid Technologies\\nFarmWise\\nFANUC\\nFigure AI\\nFoster-Miller\\nHarvest Automation\\nHD Hyundai Robotics\\nHoneybee Robotics\\nIntuitive Surgical\\nIRobot\\nKUKA\\nRainbow Robotics\\nStarship Technologies\\nSymbotic\\nUniversal Robotics\\nWolf Robotics\\nYaskawa\\nRelated\\nCritique of work\\nPowered exoskeleton\\nWorkplace robotics safety\\nRobotic tech vest\\nTechnological unemployment\\nTerrainability\\nFictional robots\\n\\n Category\\n Outline\\n\\nvteExistential risk from artificial intelligenceConcepts\\nAGI\\nAI alignment\\nAI boom\\nAI capability control\\nAI safety\\nAI takeover\\nConsequentialism\\nEffective accelerationism\\nEthics of artificial intelligence\\nExistential risk from artificial intelligence\\nFriendly artificial intelligence\\nInstrumental convergence\\nVulnerable world hypothesis\\nIntelligence explosion\\nJobpocalypse\\nLongtermism\\nMachine ethics\\nRight to reality\\nSuffering risks\\nSuperintelligence\\nTechnological singularity\\nOrganizations\\nAlignment Research Center\\nCenter for AI Safety\\nCenter for Applied Rationality\\nCenter for Human-Compatible Artificial Intelligence\\nCentre for the Study of Existential Risk\\nEleutherAI\\nFuture of Humanity Institute\\nFuture of Life Institute\\nGoogle DeepMind\\nHumanity+\\nInstitute for Ethics and Emerging Technologies\\nLeverhulme Centre for the Future of Intelligence\\nMachine Intelligence Research Institute\\nOpenAI\\nPauseAI\\nSafe Superintelligence\\nPeople\\nScott Alexander\\nSam Altman\\nYoshua Bengio\\nNick Bostrom\\nPaul Christiano\\nEric Drexler\\nSam Harris\\nStephen Hawking\\nDan Hendrycks\\nGeoffrey Hinton\\nBill Joy\\nShane Legg\\nElon Musk\\nSteve Omohundro\\nHuw Price\\nMartin Rees\\nStuart J. Russell\\nIlya Sutskever\\nJaan Tallinn\\nMax Tegmark\\nAlan Turing\\nFrank Wilczek\\nRoman Yampolskiy\\nEliezer Yudkowsky\\nOther\\nArtificial Intelligence Act\\nDo You Trust This Computer?\\nHuman Compatible\\nOpen letter on artificial intelligence\\nOur Final Invention\\nRoko\\'s basilisk\\nStatement on AI Risk\\nSuperintelligence: Paths, Dangers, Strategies\\nThe Precipice\\nIf Anyone Builds It, Everyone Dies\\n Category\\nvteSubfields of and cyberneticians involved in cyberneticsSubfields\\nArtificial intelligence\\nBiological cybernetics\\nBiomedical cybernetics\\nBiorobotics\\nBiosemiotics\\nNeurocybernetics\\nCatastrophe theory\\nComputational neuroscience\\nConnectionism\\nControl theory\\nConversation theory\\nCybernetics in the Soviet Union\\nDecision theory\\nEmergence\\nEngineering cybernetics\\nHomeostasis\\nInformation theory\\nManagement cybernetics\\nMedical cybernetics\\nSecond-order cybernetics\\nCybersemiotics\\nSociocybernetics\\nSynergetics\\nCyberneticians\\nAlexander Lerner\\nAlexey Lyapunov\\nAlfred Radcliffe-Brown\\nAllenna Leonard\\nAnthony Wilden\\nBuckminster Fuller\\nCharles François\\nGenevieve Bell\\nMargaret Boden\\nClaude Bernard\\nCliff Joslyn\\nErich von Holst\\nErnst von Glasersfeld\\nFrancis Heylighen\\nFrancisco Varela\\nFrederic Vester\\nCharles Geoffrey Vickers\\nGordon Pask\\nGordon S. Brown\\nGregory Bateson\\nHeinz von Foerster\\nHumberto Maturana\\nI. A. Richards\\nIgor Aleksander\\nJacque Fresco\\nJakob von Uexküll\\nJason Jixuan Hu\\nJay Wright Forrester\\nJennifer Wilby\\nJohn N. Warfield\\nKevin Warwick\\nLudwig von Bertalanffy\\nMaleyka Abbaszadeh\\nManfred Clynes\\nMargaret Mead\\nMarian Mazur\\nN. Katherine Hayles\\nNatalia Bekhtereva\\nNiklas Luhmann\\nNorbert Wiener\\nPyotr Grigorenko\\nQian Xuesen\\nRanulph Glanville\\nRobert Trappl\\nSergei P. Kurdyumov\\nStafford Beer\\nStuart Kauffman\\nStuart Umpleby\\nTalcott Parsons\\nUlla Mitzdorf\\nValentin Turchin\\nValentin Braitenberg\\nWilliam Ross Ashby\\nWalter Bradford Cannon\\nWalter Pitts\\nWarren McCulloch\\nWilliam Grey Walter\\n\\nvteGlossaries of science and engineering\\nAerospace engineering\\nAgriculture\\nArchaeology\\nArchitecture\\nArtificial intelligence\\nAstronomy\\nBiology\\nBotany\\nCalculus\\nCell biology\\nCellular and molecular biology\\n0–L\\nM–Z\\nChemistry\\nCivil engineering\\nClinical research\\nComputer hardware\\nComputer science\\nDevelopmental and reproductive biology\\nEcology\\nEconomics\\nElectrical and electronics engineering\\nEngineering\\nA–L\\nM–Z\\nEntomology\\nEnvironmental science\\nGenetics and evolutionary biology\\nGeography\\nA–M\\nN–Z\\nArabic toponyms\\nHebrew toponyms\\nWestern and South Asia\\nGeology\\nIchthyology\\nMachine vision\\nMathematics\\nMechanical engineering\\nMedicine\\nMeteorology\\nMycology\\nNanotechnology\\nOrnithology\\nPhysics\\nProbability and statistics\\nPsychiatry\\nQuantum computing\\nRobotics\\nScientific naming\\nStructural engineering\\nVirology\\n\\nAuthority control databases InternationalGNDNationalUnited StatesFranceBnF dataJapanCzech RepublicSpainLatviaIsraelOtherYale LUX\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Artificial_intelligence&oldid=1333172600\"\\nCategories: Artificial intelligenceComputational fields of studyComputational neuroscienceCyberneticsData scienceFormal sciencesIntelligence by typeHidden categories: Webarchive template wayback linksCS1 German-language sources (de)CS1 Russian-language sources (ru)CS1 Japanese-language sources (ja)Articles with short descriptionShort description is different from WikidataUse dmy dates from October 2025Wikipedia indefinitely semi-protected pagesArticles with excerptsPages displaying short descriptions of redirect targets via Module:Annotated linkCS1: long volume valuePages using Sister project links with hidden wikidataArticles with Internet Encyclopedia of Philosophy links\\n\\n\\n\\n\\n\\n\\n This page was last edited on 16 January 2026, at 03:57\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nLegal & safety contacts\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nArtificial intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n173 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import WebBaseLoader to load data from websites\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Create loader for a single web page\n",
    "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Artificial_intelligence\")\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f6c3b",
   "metadata": {},
   "source": [
    "**Loading multiple web pages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb42dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://en.wikipedia.org/wiki/Machine_learning', 'title': 'Machine learning - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nMachine learning - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nHistory\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nRelationships to other fields\\n\\n\\n\\n\\nToggle Relationships to other fields subsection\\n\\n\\n\\n\\n\\n2.1\\nArtificial intelligence\\n\\n\\n\\n\\n\\n\\n\\n\\n2.2\\nData compression\\n\\n\\n\\n\\n\\n\\n\\n\\n2.3\\nData mining\\n\\n\\n\\n\\n\\n\\n\\n\\n2.4\\nGeneralization\\n\\n\\n\\n\\n\\n\\n\\n\\n2.5\\nStatistics\\n\\n\\n\\n\\n\\n\\n\\n\\n2.6\\nStatistical physics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nTheory\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nApproaches\\n\\n\\n\\n\\nToggle Approaches subsection\\n\\n\\n\\n\\n\\n4.1\\nSupervised learning\\n\\n\\n\\n\\n\\n\\n\\n\\n4.2\\nUnsupervised learning\\n\\n\\n\\n\\n\\n\\n4.2.1\\nDimensionality reduction\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4.3\\nSemi-supervised learning\\n\\n\\n\\n\\n\\n\\n\\n\\n4.4\\nReinforcement learning\\n\\n\\n\\n\\n\\n\\n\\n\\n4.5\\nOther types\\n\\n\\n\\n\\n\\n\\n4.5.1\\nSelf-learning\\n\\n\\n\\n\\n\\n\\n\\n\\n4.5.2\\nFeature learning\\n\\n\\n\\n\\n\\n\\n\\n\\n4.5.3\\nSparse dictionary learning\\n\\n\\n\\n\\n\\n\\n\\n\\n4.5.4\\nAnomaly detection\\n\\n\\n\\n\\n\\n\\n\\n\\n4.5.5\\nRobot learning\\n\\n\\n\\n\\n\\n\\n\\n\\n4.5.6\\nAssociation rules\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nModels\\n\\n\\n\\n\\nToggle Models subsection\\n\\n\\n\\n\\n\\n5.1\\nArtificial neural networks\\n\\n\\n\\n\\n\\n\\n\\n\\n5.2\\nDecision trees\\n\\n\\n\\n\\n\\n\\n\\n\\n5.3\\nRandom forest regression\\n\\n\\n\\n\\n\\n\\n\\n\\n5.4\\nSupport-vector machines\\n\\n\\n\\n\\n\\n\\n\\n\\n5.5\\nRegression analysis\\n\\n\\n\\n\\n\\n\\n\\n\\n5.6\\nBayesian networks\\n\\n\\n\\n\\n\\n\\n\\n\\n5.7\\nGaussian processes\\n\\n\\n\\n\\n\\n\\n\\n\\n5.8\\nGenetic algorithms\\n\\n\\n\\n\\n\\n\\n\\n\\n5.9\\nBelief functions\\n\\n\\n\\n\\n\\n\\n\\n\\n5.10\\nRule-based models\\n\\n\\n\\n\\n\\n\\n\\n\\n5.11\\nTraining models\\n\\n\\n\\n\\n\\n\\n5.11.1\\nFederated learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nApplications\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nLimitations\\n\\n\\n\\n\\nToggle Limitations subsection\\n\\n\\n\\n\\n\\n7.1\\nExplainability\\n\\n\\n\\n\\n\\n\\n\\n\\n7.2\\nOverfitting\\n\\n\\n\\n\\n\\n\\n\\n\\n7.3\\nOther limitations and vulnerabilities\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\nModel assessments\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\nEthics\\n\\n\\n\\n\\nToggle Ethics subsection\\n\\n\\n\\n\\n\\n9.1\\nBias\\n\\n\\n\\n\\n\\n\\n\\n\\n9.2\\nFinancial incentives\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10\\nHardware\\n\\n\\n\\n\\nToggle Hardware subsection\\n\\n\\n\\n\\n\\n10.1\\nTensor Processing Units (TPUs)\\n\\n\\n\\n\\n\\n\\n\\n\\n10.2\\nNeuromorphic computing\\n\\n\\n\\n\\n\\n\\n10.2.1\\nPhysical neural networks\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10.3\\nEmbedded machine learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\nSoftware\\n\\n\\n\\n\\nToggle Software subsection\\n\\n\\n\\n\\n\\n11.1\\nFree and open-source software\\n\\n\\n\\n\\n\\n\\n\\n\\n11.2\\nProprietary software with free and open-source editions\\n\\n\\n\\n\\n\\n\\n\\n\\n11.3\\nProprietary software\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n12\\nJournals\\n\\n\\n\\n\\n\\n\\n\\n\\n13\\nConferences\\n\\n\\n\\n\\n\\n\\n\\n\\n14\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n15\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n16\\nSources\\n\\n\\n\\n\\n\\n\\n\\n\\n17\\nFurther reading\\n\\n\\n\\n\\n\\n\\n\\n\\n18\\nExternal links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nMachine learning\\n\\n\\n\\n88 languages\\n\\n\\n\\n\\nAfrikaansالعربيةঅসমীয়াAzərbaycancaتۆرکجهবাংলা閩南語 / Bân-lâm-gíБашҡортсаБеларускаяभोजपुरीБългарскиབོད་ཡིགBosanskiCatalàČeštinaCymraegDanskالدارجةDeutschEestiΕλληνικάEspañolEsperantoEuskaraفارسیFrançaisGaelgGalego한국어Հայերենहिन्दीIdoBahasa IndonesiaIsiZuluÍslenskaItalianoעבריתJawaಕನ್ನಡქართულიКыргызчаLatviešuLietuviųLigureMagyarМакедонскиമലയാളംमराठीBahasa MelayuМонголNederlands日本語Norsk bokmålNorsk nynorskOccitanଓଡ଼ିଆOʻzbekcha / ўзбекчаਪੰਜਾਬੀپنجابیپښتوPolskiPortuguêsQaraqalpaqshaRomânăRuna SimiРусскийᱥᱟᱱᱛᱟᱲᱤShqipSimple EnglishSlovenščinaکوردیСрпски / srpskiSrpskohrvatski / српскохрватскиSuomiSvenskaTagalogதமிழ்తెలుగుไทยTürkçeУкраїнськаاردوئۇيغۇرچە / UyghurcheTiếng ViệtVõro吴语粵語中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikiquoteWikiversityWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\n\\nStudy of algorithms that improve automatically through experience\\nFor the journal, see Machine Learning (journal).\\n\"Statistical learning\" redirects here. For statistical learning in linguistics, see Statistical learning in language acquisition.\\n\\n\\nPart of a series onMachine learningand data mining\\nParadigms\\nSupervised learning\\nUnsupervised learning\\nSemi-supervised learning\\nSelf-supervised learning\\nReinforcement learning\\nMeta-learning\\nOnline learning\\nBatch learning\\nCurriculum learning\\nRule-based learning\\nNeuro-symbolic AI\\nNeuromorphic engineering\\nQuantum machine learning\\n\\nProblems\\nClassification\\nGenerative modeling\\nRegression\\nClustering\\nDimensionality reduction\\nDensity estimation\\nAnomaly detection\\nData cleaning\\nAutoML\\nAssociation rules\\nSemantic analysis\\nStructured prediction\\nFeature engineering\\nFeature learning\\nLearning to rank\\nGrammar induction\\nOntology learning\\nMultimodal learning\\n\\nSupervised learning(classification\\xa0• regression) \\nApprenticeship learning\\nDecision trees\\nEnsembles\\nBagging\\nBoosting\\nRandom forest\\nk-NN\\nLinear regression\\nNaive Bayes\\nArtificial neural networks\\nLogistic regression\\nPerceptron\\nRelevance vector machine (RVM)\\nSupport vector machine (SVM)\\n\\nClustering\\nBIRCH\\nCURE\\nHierarchical\\nk-means\\nFuzzy\\nExpectation–maximization (EM)\\nDBSCAN\\nOPTICS\\nMean shift\\n\\nDimensionality reduction\\nFactor analysis\\nCCA\\nICA\\nLDA\\nNMF\\nPCA\\nPGD\\nt-SNE\\nSDL\\n\\nStructured prediction\\nGraphical models\\nBayes net\\nConditional random field\\nHidden Markov\\n\\nAnomaly detection\\nRANSAC\\nk-NN\\nLocal outlier factor\\nIsolation forest\\n\\nNeural networks\\nAutoencoder\\nDeep learning\\nFeedforward neural network\\nRecurrent neural network\\nLSTM\\nGRU\\nESN\\nreservoir computing\\nBoltzmann machine\\nRestricted\\nGAN\\nDiffusion model\\nSOM\\nConvolutional neural network\\nU-Net\\nLeNet\\nAlexNet\\nDeepDream\\nNeural field\\nNeural radiance field\\nPhysics-informed neural networks\\nTransformer\\nVision\\nMamba\\nSpiking neural network\\nMemtransistor\\nElectrochemical RAM (ECRAM)\\n\\nReinforcement learning\\nQ-learning\\nPolicy gradient\\nSARSA\\nTemporal difference (TD)\\nMulti-agent\\nSelf-play\\n\\nLearning with humans\\nActive learning\\nCrowdsourcing\\nHuman-in-the-loop\\nMechanistic interpretability\\nRLHF\\n\\nModel diagnostics\\nCoefficient of determination\\nConfusion matrix\\nLearning curve\\nROC curve\\n\\nMathematical foundations\\nKernel machines\\nBias–variance tradeoff\\nComputational learning theory\\nEmpirical risk minimization\\nOccam learning\\nPAC learning\\nStatistical learning\\nVC theory\\nTopological deep learning\\n\\nJournals and conferences\\nAAAI\\nECML PKDD\\nNeurIPS\\nICML\\nICLR\\nIJCAI\\nML\\nJMLR\\n\\nRelated articles\\nGlossary of artificial intelligence\\nList of datasets for machine-learning research\\nList of datasets in computer vision and image processing\\nOutline of machine learning\\nvte\\nPart of a series onArtificial intelligence (AI)\\nMajor goals\\nArtificial general intelligence\\nIntelligent agent\\nRecursive self-improvement\\nPlanning\\nComputer vision\\nGeneral game playing\\nKnowledge representation\\nNatural language processing\\nRobotics\\nAI safety\\n\\nApproaches\\nMachine learning\\nSymbolic\\nDeep learning\\nBayesian networks\\nEvolutionary algorithms\\nHybrid intelligent systems\\nSystems integration\\nOpen-source\\nAI data centers\\n\\nApplications\\nBioinformatics\\nDeepfake\\nEarth sciences\\n Finance \\nGenerative AI\\nArt\\nAudio\\nMusic\\nGovernment\\nHealthcare\\nMental health\\nIndustry\\nSoftware development\\nTranslation\\n Military \\nPhysics\\nProjects\\n\\nPhilosophy\\nAI alignment\\nArtificial consciousness\\nThe bitter lesson\\nChinese room\\nFriendly AI\\nEthics\\nExistential risk\\nTuring test\\nUncanny valley\\nHuman–AI interaction\\n\\nHistory\\nTimeline\\nProgress\\nAI winter\\nAI boom\\nAI bubble\\n\\nControversies\\nDeepfake pornography\\nTaylor Swift deepfake pornography controversy\\nGrok deepfake pornography controversy\\nGoogle Gemini image generation controversy\\nPause Giant AI Experiments\\nRemoval of Sam Altman from OpenAI\\nStatement on AI Risk\\nTay (chatbot)\\nThéâtre D\\'opéra Spatial\\nVoiceverse NFT plagiarism scandal\\n\\nGlossary\\nGlossary\\nvte\\nMachine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions.[1] Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\\nML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine. The application of ML to business problems is known as predictive analytics.\\nStatistics and mathematical optimisation (mathematical programming) methods comprise the foundations of machine learning. Data mining is a related field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.[3][4]\\nFrom a theoretical viewpoint, probably approximately correct learning provides a mathematical and statistical framework for describing machine learning. Most traditional machine learning and deep learning algorithms can be described as empirical risk minimisation under this framework.\\n\\n\\nHistory[edit]\\nSee also: Timeline of machine learning\\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[5][6] The synonym self-teaching computers was also used during this time period.[7][8]\\nThe earliest machine learning program was introduced in the 1950s when Arthur Samuel invented a computer program that calculated the winning chance in checkers for each side, but the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.[9] In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells.[10] Hebb\\'s model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.[9] Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.[9]\\nBy the early 1960s, an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyse sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognise patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions.[11] A representative book on research into machine learning during the 1960s was Nils Nilsson\\'s book on Learning Machines, dealing mostly with machine learning for pattern classification.[12] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[13] In 1981, a report was given on using teaching strategies so that an artificial neural network learns to recognise 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[14]\\nTom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P,  improves with experience E.\"[15] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing\\'s proposal in his paper \"Computing Machinery and Intelligence\", in which the question, \"Can machines think?\", is replaced with the question, \"Can machines do what we (as thinking entities) can do?\".[16]\\nModern-day Machine Learning algorithms are broken into 3 algorithm types: Supervised Learning Algorithms, Unsupervised Learning Algorithms, and Reinforcement Learning Algorithms.[17]\\n\\nCurrent Supervised Learning Algorithms have objectives of classification and regression.\\nCurrent Unsupervised Learning Algorithms have objectives of clustering, dimensionality reduction, and association rule.\\nCurrent Reinforcement Learning Algorithms focus on decisions that must be made with respect to some previous, unknown time and are broken down to either be studies of model-based methods or model-free methods.\\nIn 2014 Ian Goodfellow and others introduced generative adversarial networks (GANs) with realistic data synthesis.[18] By 2016 AlphaGo obtained victory against top human players using reinforcement learning techniques.[19]\\n\\nRelationships to other fields[edit]\\nArtificial intelligence[edit]\\nDeep learning is a subset of machine learning, which is itself a subset of artificial intelligence.[20]\\nAs a scientific endeavour, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalised linear models of statistics.[21] Probabilistic reasoning was also employed, especially in automated medical diagnosis.[22]:\\u200a488\\u200a\\nHowever, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[22]:\\u200a488\\u200a By 1980, expert systems had come to dominate AI, and statistics was out of favour.[23] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming(ILP), but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[22]:\\u200a708–710,\\u200a755\\u200a Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines, including John Hopfield, David Rumelhart, and Geoffrey Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.[22]:\\u200a25\\u200a\\nMachine learning (ML), reorganised and recognised as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.[23]\\n\\nData compression[edit]\\nThis section is an excerpt from Data compression § Machine learning.[edit]\\nThere is a close connection between machine learning and compression. A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for \"general intelligence\".[24][25][26]\\nAn alternative view can show compression algorithms implicitly map strings into implicit feature space vectors, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space ℵ, such that C(.) maps an input string x, corresponding to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.[27]\\nAccording to AIXI theory, a connection more directly explained in Hutter Prize, the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file\\'s compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form.\\nExamples of AI-powered audio/video compression software include NVIDIA Maxine, AIVC.[28] Examples of software that can perform AI-powered image compression include OpenCV, TensorFlow, MATLAB\\'s Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.[29]\\nIn unsupervised machine learning, k-means clustering can be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression.[30]\\nData compression aims to reduce the size of data files, enhancing storage efficiency and speeding up data transmission. K-means clustering, an unsupervised machine learning algorithm, is employed to partition a dataset into a specified number of clusters, k, each represented by the centroid of its points. This process condenses extensive datasets into a more compact set of representative points. Particularly beneficial in image and signal processing, k-means clustering aids in data reduction by replacing groups of data points with their centroids, thereby preserving the core information of the original data while significantly decreasing the required storage space.[31]\\nLarge language models (LLMs) are also efficient lossless data compressors on some data sets, as demonstrated by DeepMind\\'s research with the Chinchilla 70B model. Developed by DeepMind, Chinchilla 70B effectively compressed data, outperforming conventional methods such as Portable Network Graphics (PNG) for images and Free Lossless Audio Codec (FLAC) for audio. It achieved compression of image and audio data to 43.4% and 16.4% of their original sizes, respectively. There is, however, some reason to be concerned that the data set used for testing overlaps the LLM training data set, making it possible that the Chinchilla 70B model is only an efficient compression tool on data it has already been trained on.[32][33]\\n\\n\\nData mining[edit]\\nMachine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.[citation needed]\\nMachine learning also has intimate ties to optimisation: Many learning problems are formulated as minimisation of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the preassigned labels of a set of examples).[34]\\n\\nGeneralization[edit]\\nCharacterizing the generalisation of various learning algorithms is an active topic of current research, especially for deep learning algorithms.\\n\\nStatistics[edit]\\nMachine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalisable predictive patterns.[35]\\nConventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.[36]\\nLeo Breiman distinguished two statistical modelling paradigms: data model and algorithmic model,[37] wherein \"algorithmic model\" means more or less the machine learning algorithms like Random Forest.\\nSome statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.[38]\\n\\nStatistical physics[edit]\\nAnalytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyse the weight space of deep neural networks.[39] Statistical physics is thus finding applications in the area of medical diagnostics.[40]\\n\\n Theory[edit]\\nMain articles: Computational learning theory and Statistical learning theory\\nA core objective of a learner is to generalise from its experience.[2][41] Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\\nThe computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the probably approximately correct learning  model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalisation error.\\nFor the best performance in the context of generalisation, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has underfitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalisation will be poorer.[42]\\nIn addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\\n\\nApproaches[edit]\\n\\n\\nIn supervised learning, the training data is labelled with the expected answers, while in unsupervised learning, the model identifies patterns or structures in unlabelled data.\\nMachine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\\n\\nSupervised learning: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs.\\nUnsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\\nReinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that\\'s analogous to rewards, which it tries to maximise.[2]\\nAlthough each algorithm has advantages and limitations, no single algorithm works for all problems.[43][44][45]\\n\\nSupervised learning[edit]\\nMain article: Supervised learning\\nA support-vector machine is a supervised learning model that divides the data into regions separated by a linear boundary. Here, the linear boundary divides the black circles from the white.\\nSupervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.[46] The data, known as training data, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimisation of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.[47] An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.[15]\\nTypes of supervised-learning algorithms include active learning, classification and regression.[48] Classification algorithms are used when the outputs are restricted to a limited set of values, while regression algorithms are used when the outputs can take any numerical value within a range. For example, in a classification algorithm that filters emails, the input is an incoming email, and the output is the folder in which to file the email. In contrast, regression is used for tasks such as predicting a person\\'s height based on factors like age and genetics or forecasting future temperatures based on historical data.[49]\\nSimilarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.\\n\\nUnsupervised learning[edit]\\nMain article: Unsupervised learningSee also: Cluster analysis\\nUnsupervised learning algorithms find structures in data that has not been labelled, classified or categorised. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction,[4] and density estimation.[50]\\nCluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.\\nA special type of unsupervised learning called, self-supervised learning involves training a model by generating the supervisory signal from the data itself.[51][52]\\n\\nDimensionality reduction[edit]\\nDimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables.[53] In other words, it is a process of reducing the dimension of the feature set, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D).\\nThe manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the areas of manifold learning and manifold regularisation.\\n\\nSemi-supervised learning[edit]\\nMain article: Semi-supervised learning\\nSemi-supervised learning falls between unsupervised learning (without any labelled training data) and supervised learning (with completely labelled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabelled data, when used in conjunction with a small amount of labelled data, can produce a considerable improvement in learning accuracy.\\nIn weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.[54]\\n\\nReinforcement learning[edit]\\nMain article: Reinforcement learning\\nIn reinforcement learning, an agent takes actions in an environment: these produce a reward and/or a representation of the state, which is fed back to the agent.\\nReinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment to maximise some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimisation, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcement learning algorithms use dynamic programming techniques.[55] Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.\\n\\nOther types[edit]\\nOther approaches have been developed which do not fit neatly into this three-fold categorisation, and sometimes more than one is used by the same machine learning system. For example, topic modelling, meta-learning.[56]\\n\\nSelf-learning[edit]\\nSelf-learning, as a machine learning paradigm, was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA).[57][58] It gives a solution to the problem learning without any external reward, by introducing emotion as an internal reward. Emotion is used as a state evaluation of a self-learning agent. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.[59]\\nThe self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine: \\n\\nin situation s act a\\nreceive a consequence situation s\\'\\ncompute emotion of being in the consequence situation v(s\\')\\nupdate crossbar memory  w\\'(a,s) = w(a,s) + v(s\\')\\nIt is a system with only one input, situation, and only one output, action (or behaviour) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioural environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioural environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behaviour in an environment that contains both desirable and undesirable situations.[60]\\n\\nFeature learning[edit]\\nMain article: Feature learning\\nSeveral learning algorithms aim at discovering better representations of the inputs provided during training.[61] Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering, and allows a machine to both learn the features and use them to perform a specific task.\\nFeature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labelled input data. Examples include artificial neural networks, multilayer perceptrons, and supervised dictionary learning. In unsupervised feature learning, features are learned with unlabelled input data.  Examples include dictionary learning, independent component analysis, autoencoders, matrix factorisation[62] and various forms of clustering.[63][64][65]\\nManifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors.[66] Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine learns a representation that disentangles the underlying factors of variation that explain the observed data.[67]\\nFeature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data have not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.\\n\\nSparse dictionary learning[edit]\\nMain article: Sparse dictionary learning\\nSparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix. The method is strongly NP-hard and difficult to solve approximately.[68] A popular heuristic method for sparse dictionary learning is the k-SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image denoising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.[69]\\n\\nAnomaly detection[edit]\\nMain article: Anomaly detection\\nIn data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations that raise suspicions by differing significantly from the majority of the data.[70] Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers, novelties, noise, deviations and exceptions.[71]\\nIn particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.[72]\\nThree broad categories of anomaly detection techniques exist.[73] Unsupervised anomaly detection techniques detect anomalies in an unlabelled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labelled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behaviour from a given normal training data set and then test the likelihood of a test instance being generated by the model.\\n\\nRobot learning[edit]\\nRobot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,[74][75] and finally meta-learning (e.g. MAML).\\n\\nAssociation rules[edit]\\nMain article: Association rule learningSee also: Inductive logic programming\\nAssociation rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".[76]\\nRule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilisation of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[77] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.\\nBased on the concept of strong rules, Rakesh Agrawal, Tomasz Imieliński and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.[78] For example, the rule \\n\\n\\n\\n{\\n\\no\\nn\\ni\\no\\nn\\ns\\n,\\np\\no\\nt\\na\\nt\\no\\ne\\ns\\n\\n}\\n⇒\\n{\\n\\nb\\nu\\nr\\ng\\ne\\nr\\n\\n}\\n\\n\\n{\\\\displaystyle \\\\{\\\\mathrm {onions,potatoes} \\\\}\\\\Rightarrow \\\\{\\\\mathrm {burger} \\\\}}\\n\\n found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.\\nLearning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner to make predictions.[79]\\nInductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.\\nInductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.[80][81][82] Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.[83] The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.\\n\\nModels[edit]\\nA machine learning model is a type of mathematical model that, once \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model\\'s internal parameters to minimise errors in its predictions.[84] By extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.[85]\\nVarious types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection.\\n\\nArtificial neural networks[edit]\\nMain article: Artificial neural networkSee also: Deep learning\\nAn artificial neural network is an interconnected group of nodes, akin to the vast network of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another.\\nArtificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\\nAn ANN is a model based on a collection of connected units or nodes called \"artificial neurons\", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.\\nThe original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\\nDeep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[86]\\n\\nDecision trees[edit]\\nMain article: Decision tree learning\\nA decision tree showing survival probability of passengers on the Titanic\\nDecision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item\\'s target value (represented in the leaves). It is one of the predictive modelling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.\\n\\nRandom forest regression[edit]\\nRandom forest regression (RFR) falls under the umbrella of decision tree-based models. RFR is an ensemble learning method that builds multiple decision trees and averages their predictions to improve accuracy and to avoid overfitting. To build decision trees, RFR uses bootstrapped sampling; for instance, each decision tree is trained on random data from the training set. This random selection of RFR for training enables the model to reduce biased predictions and achieve a higher degree of accuracy. RFR generates independent decision trees, and it can work on single-output data as well as multiple regressor tasks. This makes RFR compatible to be use in various applications.[87][88]\\n\\nSupport-vector machines[edit]\\nMain article: Support-vector machine\\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.[89] An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\\n\\nRegression analysis[edit]\\nMain article: Regression analysis\\nIllustration of linear regression on a data set\\nRegression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularisation methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel[90]), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.\\nMultivariate linear regression extends the concept of linear regression to handle multiple dependent variables simultaneously. This approach estimates the relationships between a set of input variables and several output variables by fitting a multidimensional linear model. It is particularly useful in scenarios where outputs are interdependent or share underlying patterns, such as predicting multiple economic indicators or reconstructing images,[91] which are inherently multi-dimensional.\\n\\nBayesian networks[edit]\\nMain article: Bayesian network\\nA simple Bayesian network. Rain influences whether the sprinkler is activated, and both rain and the sprinkler influence whether the grass is wet.\\nA Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalisations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.\\n\\nGaussian processes[edit]\\nMain article: Gaussian processes\\nAn example of Gaussian Process Regression (prediction) compared with other regression models[92]\\nA Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations.\\nGiven a set of observed points, or input–output examples, the distribution of the (unobserved) output of a new point as a function of its input data can be directly computed by looking at the observed points and the covariances between those points and the new, unobserved point.\\nGaussian processes are popular surrogate models in Bayesian optimisation used to do hyperparameter optimisation.\\n\\nGenetic algorithms[edit]\\nMain article: Genetic algorithm\\nA genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.[93][94] Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.[95]\\n\\nBelief functions[edit]\\nMain article: Dempster–Shafer theory\\nThe theory of belief functions, also referred to as evidence theory or Dempster–Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and  imprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g.,  Dempster\\'s rule of combination), just like how in a pmf-based Bayesian approach would combine probabilities.[96] However, there are many caveats to these beliefs functions when compared to Bayesian approaches to incorporate ignorance and uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner\\'s decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.[97][6] However, the computational complexity of these algorithms is dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches.\\n\\nRule-based models[edit]\\nMain article: Rule-based machine learning\\nRule-based machine learning (RBML) is a branch of machine learning that automatically discovers and learns \\'rules\\' from data. It provides interpretable models, making it useful for decision-making in fields like healthcare, fraud detection, and cybersecurity. Key RBML techniques includes learning classifier systems,[98] association rule learning,[99] artificial immune systems,[100] and other similar models. These methods extract patterns from data and evolve rules over time.\\n\\nTraining models[edit]\\nTypically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and, notably, becoming integrated within machine learning engineering teams.\\n\\nFederated learning[edit]\\nMain article: Federated learning\\nFederated learning is an adapted form of distributed artificial intelligence to train machine learning models that decentralises the training process, allowing for users\\' privacy to be maintained by not needing to send their data to a centralised server. This also increases efficiency by decentralising the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users\\' mobile phones without having to send individual searches back to Google.[101]\\n\\nApplications[edit]\\nThere are many applications for machine learning, including:\\n\\n\\nAgriculture\\nAnatomy\\nAdaptive website\\nAffective computing\\nAstronomy\\nAutomated decision-making\\nBanking\\nBehaviorism\\nBioinformatics\\nBrain–machine interfaces\\nCheminformatics\\nCitizen Science\\nClimate Science\\nComputer networks\\nComputer vision\\nCredit-card fraud detection\\nData quality\\nDNA sequence classification\\nEconomics\\nFinancial data analysis[102]\\nGeneral game playing\\nHandwriting recognition\\nHealthcare\\nInformation retrieval\\nInsurance\\nInternet fraud detection\\nInvestment management[103]\\nKnowledge graph embedding\\nLinguistics\\nMachine learning control\\nMachine perception\\nMachine translation\\nMaterial Engineering\\nMarketing\\nMedical diagnosis\\nNatural language processing\\nNatural language understanding\\nOnline advertising\\nOptimisation\\nRecommender systems\\nRobot locomotion\\nSearch engines\\nSentiment analysis\\nSequence mining\\nSoftware engineering\\nSpeech recognition\\nStructural health monitoring\\nSyntactic pattern recognition\\nTelecommunications\\nTheorem proving\\nTime-series forecasting\\nTomographic reconstruction[104]\\nUser behaviour analytics\\n\\nIn 2006, the media-services provider Netflix held the first \"Netflix Prize\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million.[105] Shortly after the prize was awarded, Netflix realised that viewers\\' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly.[106] In 2010, an article in The Wall Street Journal noted the use of machine learning by Rebellion Research to predict the 2008 financial crisis.[107] In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.[108] In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognised influences among artists.[109] In 2019 Springer Nature published the first research book created using machine learning.[110] In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.[111] Machine learning was recently applied to predict the pro-environmental behaviour of travellers.[112] Recently, machine learning technology was also applied to optimise smartphone\\'s performance and thermal behaviour based on the user\\'s interaction with the phone.[113][114][115] When applied correctly, machine learning algorithms (MLAs) can utilise a wide range of company characteristics to predict stock returns without overfitting. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like OLS.[116]\\nRecent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.[117]\\nMachine Learning is becoming a useful tool to investigate and predict evacuation decision-making in large-scale and small-scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes.[118][119][120] Other applications have been focusing on pre evacuation decisions in building fires.[121][122]\\n\\nLimitations[edit]\\nAlthough machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.[123][124][125] Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.[126]\\nThe \"black box theory\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted from the data.[127] The House of Lords Select Committee, which claimed that such an \"intelligence system\" that could have a \"substantial impact on an individual\\'s life\" would not be considered acceptable unless it provided \"a full and satisfactory explanation for the decisions\" it makes.[127]\\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision.[128] Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.[129][130] Microsoft\\'s Bing Chat chatbot has been reported to produce hostile and offensive response against its users.[131]\\nMachine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research itself.[132]\\n\\nExplainability[edit]\\nMain article: Explainable artificial intelligence\\nExplainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI.[133] It contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision.[134] By refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation.\\n\\nOverfitting[edit]\\nMain article: Overfitting\\nThe blue line could be an example of overfitting a linear function due to random noise.\\nSettling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalising the theory in accordance with how complex the theory is.[135]\\n\\nOther limitations and vulnerabilities[edit]\\nLearners can also be disappointed by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.[136] A real-world example is that, unlike humans, current image classifiers often do not primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.[137][138]\\nAdversarial vulnerabilities can also result in nonlinear systems or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel.[139] Machine learning models are often vulnerable to manipulation or evasion via adversarial machine learning.[140]\\nResearchers have demonstrated how backdoors can be placed undetectably into classifying (e.g., for categories \"spam\" and \"not spam\" of posts) machine learning models that are often developed or trained by third parties. Parties can change the classification of any input, including in cases for which a type of data/software transparency is provided, possibly including white-box access.[141][142][143]\\n\\nModel assessments[edit]\\nClassification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data into a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.[144]\\nIn addition to overall accuracy, investigators frequently report sensitivity and specificity, meaning true positive rate (TPR) and true negative rate (TNR), respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. Receiver operating characteristic (ROC), along with the accompanying Area Under the ROC Curve (AUC), offer additional tools for classification model assessment. Higher AUC is associated with a better performing model.[145]\\n\\nEthics[edit]\\nThis section is an excerpt from Ethics of artificial intelligence.[edit]\\n\\nThe ethics of artificial intelligence covers a broad range of topics within AI that are considered to have particular ethical stakes.[146] This includes algorithmic biases, fairness, accountability, transparency, privacy, and regulation, particularly where systems influence or automate human decision-making. It also covers various emerging or potential future challenges such as machine ethics (how to make machines that behave ethically), lethal autonomous weapon systems, arms race dynamics, AI safety and alignment, technological unemployment, AI-enabled misinformation,[147] how to treat certain AI systems if they have a moral status (AI welfare and rights), artificial superintelligence and existential risks.[146]\\nSome application areas may also have particularly important ethical implications, like healthcare, education, criminal justice, or the military.\\n\\n\\nBias[edit]\\nMain article: Algorithmic bias\\nDifferent machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.[148]\\nSystems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitising cultural prejudices.[149] For example, in 1988, the UK\\'s Commission for Racial Equality found that St. George\\'s Medical School had been using a computer program trained from data of previous admissions staff and this program had denied nearly 60 candidates who were found to either be women or have non-European-sounding names.[148] Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants.[150][151] Another example includes predictive policing company Geolitica\\'s predictive algorithm that resulted in \"disproportionately high levels of over-policing in low-income and minority communities\" after being trained with historical crime data.[152]\\nWhile responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame the lack of participation and representation of minority populations in the field of AI for machine learning\\'s vulnerability to biases.[153] In fact, according to research carried out by the Computing Research Association in 2021, \"female faculty make up just 16.1%\" of all faculty members who focus on AI among several universities around the world.[154] Furthermore, among the group of \"new U.S. resident AI PhD graduates,\" 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.[154]\\nLanguage models learned from data have been shown to contain human-like biases.[155][156] Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.[157][158] In 2016, Microsoft tested Tay, a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.[159]\\nIn an experiment carried out by ProPublica, an investigative journalism organisation, a machine learning algorithm\\'s insight into the recidivism rates among prisoners falsely flagged \"black defendants high risk twice as often as white defendants\".[152] In 2015, Google Photos once tagged a couple of black people as gorillas, which caused controversy. The gorilla label was subsequently removed, and in 2023, it still cannot recognise gorillas.[160] Similar issues with recognising non-white people have been found in many other systems.[161]\\nBecause of such challenges, the effective use of machine learning may take longer to be adopted in other domains.[162] Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who said that \"[t]here\\'s nothing artificial about AI. It\\'s inspired by people, it\\'s created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"[163]\\n\\nFinancial incentives[edit]\\nThere are concerns among health care professionals that these systems might not be designed in the public\\'s interest but as income-generating machines. This is especially true in the United States, where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm\\'s proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals with an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.[164]\\n\\nHardware[edit]\\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units.[165] By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.[166] OpenAI estimated the hardware compute used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.[167][168]\\n\\nTensor Processing Units (TPUs)[edit]\\nTensor Processing Units (TPUs) are specialised hardware accelerators developed by Google specifically for machine learning workloads. Unlike general-purpose GPUs and FPGAs, TPUs are optimised for tensor computations, making them particularly efficient for deep learning tasks such as training and inference. They are widely used in Google Cloud AI services and large-scale machine learning models like Google\\'s DeepMind AlphaFold and large language models. TPUs leverage matrix multiplication units and high-bandwidth memory to accelerate computations while maintaining energy efficiency.[169] Since their introduction in 2016, TPUs have become a key component of AI infrastructure, especially in cloud-based environments.\\n\\nNeuromorphic computing[edit]\\nNeuromorphic computing refers to a class of computing systems designed to emulate the structure and functionality of biological neural networks. These systems may be implemented through software-based simulations on conventional hardware or through specialised hardware architectures.[170]\\n\\nPhysical neural networks[edit]\\nA physical neural network is a specific type of neuromorphic hardware that relies on electrically adjustable materials, such as memristors, to emulate the function of neural synapses. The term \"physical neural network\" highlights the use of physical hardware for computation, as opposed to software-based implementations. It broadly refers to artificial neural networks that use materials with adjustable resistance to replicate neural synapses.[171][172]\\n\\nEmbedded machine learning[edit]\\nEmbedded machine learning is a sub-field of machine learning where models are deployed on embedded systems with limited computing resources, such as wearable computers, edge devices and microcontrollers.[173][174][175][176] Running models directly on these devices eliminates the need to transfer and store data on cloud servers for further processing, thereby reducing the risk of data breaches, privacy leaks and theft of intellectual property, personal data and business secrets. Embedded machine learning can be achieved through various techniques, such as hardware acceleration,[177][178] approximate computing,[179] and model optimisation.[180][181] Common optimisation techniques include pruning, quantisation, knowledge distillation, low-rank factorisation, network architecture search, and parameter sharing.\\n\\nSoftware[edit]\\nSoftware suites containing a variety of machine learning algorithms include the following:\\n\\nFree and open-source software[edit]\\nSee also: Lists of open-source artificial intelligence software\\n\\nCaffe\\nDeeplearning4j\\nDeepSpeed\\nELKI\\nGoogle JAX\\nInfer.NET\\nJASP\\nJubatus\\nKeras\\nKubeflow\\nLightGBM\\nMahout\\nMallet\\nMicrosoft Cognitive Toolkit\\nML.NET\\nmlpack\\nMXNet\\nOpenNN\\nOrange\\npandas (software)\\nROOT (TMVA with ROOT)\\nscikit-learn\\nShogun\\nSpark MLlib\\nSystemML\\nTheano\\nTensorFlow\\nTorch / PyTorch\\nWeka / MOA\\nXGBoost\\nYooreeka\\n\\nProprietary software with free and open-source editions[edit]\\nKNIME\\nRapidMiner\\nProprietary software[edit]\\n\\nAmazon Machine Learning\\nAngoss KnowledgeSTUDIO\\nAzure Machine Learning\\nIBM Watson Studio\\nGoogle Cloud Vertex AI\\nGoogle Prediction API\\nIBM SPSS Modeller\\nKXEN Modeller\\nLIONsolver\\nMathematica\\nMATLAB\\nNeural Designer\\nNeuroSolutions\\nOracle Data Mining\\nOracle AI Platform Cloud Service\\nPolyAnalyst\\nRCASE\\nSAS Enterprise Miner\\nSequenceL\\nSplunk\\nSTATISTICA Data Miner\\n\\nJournals[edit]\\nJournal of Machine Learning Research\\nMachine Learning\\nNature Machine Intelligence\\nNeural Computation\\nIEEE Transactions on Pattern Analysis and Machine Intelligence\\nConferences[edit]\\nAAAI Conference on Artificial Intelligence\\nAssociation for Computational Linguistics (ACL)\\nEuropean Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)\\nInternational Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (CIBB)\\nInternational Conference on Machine Learning (ICML)\\nInternational Conference on Learning Representations (ICLR)\\nInternational Conference on Intelligent Robots and Systems (IROS)\\nConference on Knowledge Discovery and Data Mining (KDD)\\nConference on Neural Information Processing Systems (NeurIPS)\\nSee also[edit]\\nAutomated machine learning\\xa0– Process of automating the application of machine learning\\nBig data\\xa0– Extremely large or complex datasets\\nDeep learning — branch of ML concerned with artificial neural networks\\nDifferentiable programming\\xa0– Programming paradigm\\nList of datasets for machine-learning research\\nList of machine learning algorithms and List of algorithms for machine learning and statistical classification\\nM-theory (learning framework)\\xa0– Framework in machine learning\\nMachine unlearning\\xa0– Field of study in artificial intelligence\\nOutline of machine learning\\nSolomonoff\\'s theory of inductive inference\\xa0– Mathematical theory\\nReferences[edit]\\n\\n^ The definition \"without being explicitly programmed\" is often attributed to Arthur Samuel, who coined the term \"machine learning\" in 1959, but the phrase is not found verbatim in this publication, and may be a paraphrase that appeared later. Confer \"Paraphrasing Arthur Samuel (1959), the question is: How can computers learn to solve problems without being explicitly programmed?\" in Koza, John R.; Bennett, Forrest H.; Andre, David; Keane, Martin A. (1996). \"Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming\". Artificial Intelligence in Design \\'96. Artificial Intelligence in Design \\'96. Dordrecht, Netherlands: Springer Netherlands. pp.\\xa0151–170. doi:10.1007/978-94-009-0279-4_9. ISBN\\xa0978-94-010-6610-5.\\n\\n^ a b c Bishop, C. M. (2006), Pattern Recognition and Machine Learning, Springer, ISBN\\xa0978-0-387-31073-2\\n\\n^ Machine learning and pattern recognition \"can be viewed as two facets of the same field\".[2]:\\u200avii\\u200a\\n\\n^ a b Friedman, Jerome H. (1998). \"Data Mining and Statistics: What\\'s the connection?\". Computing Science and Statistics. 29 (1): 3–9.\\n\\n^ Samuel, Arthur (1959). \"Some Studies in Machine Learning Using the Game of Checkers\". IBM Journal of Research and Development. 3 (3): 210–229. CiteSeerX\\xa010.1.1.368.2254. doi:10.1147/rd.33.0210. S2CID\\xa02126705.\\n\\n^ a b R. Kohavi and F. Provost, \"Glossary of terms\", Machine Learning, vol. 30, no. 2–3, pp. 271–274, 1998.\\n\\n^ Gerovitch, Slava (9 April 2015). \"How the Computer Got Its Revenge on the Soviet Union\". Nautilus. Archived from the original on 22 September 2021. Retrieved 19 September 2021.\\n\\n^ Lindsay, Richard P. (1 September 1964). \"The Impact of Automation On Public Administration\". Western Political Quarterly. 17 (3): 78–81. doi:10.1177/106591296401700364. ISSN\\xa00043-4078. S2CID\\xa0154021253. Archived from the original on 6 October 2021. Retrieved 6 October 2021.\\n\\n^ a b c \"History and Evolution of Machine Learning: A Timeline\". WhatIs. Archived from the original on 8 December 2023. Retrieved 8 December 2023.\\n\\n^ Milner, Peter M. (1993). \"The Mind and Donald O. Hebb\". Scientific American. 268 (1): 124–129. Bibcode:1993SciAm.268a.124M. doi:10.1038/scientificamerican0193-124. ISSN\\xa00036-8733. JSTOR\\xa024941344. PMID\\xa08418480.\\n\\n^ \"Science: The Goof Button\", Time, 18 August 1961.\\n\\n^ Nilsson, Nils J. (1965). Learning Machines. McGraw-Hill.\\n\\n^ Duda, R., Hart P. Pattern Recognition and Scene Analysis, Wiley Interscience, 1973\\n\\n^ S. Bozinovski, \"Teaching space: A representation concept for adaptive pattern classification\" COINS Technical Report No. 81-28, Computer and Information Science Department, University of Massachusetts at Amherst, MA, 1981. https://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf Archived 25 February 2021 at the Wayback Machine\\n\\n^ a b Mitchell, T. (1997). Machine Learning. McGraw Hill. p.\\xa02. ISBN\\xa0978-0-07-042807-2.\\n\\n^ Harnad, Stevan (2008), \"The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence\", in Epstein, Robert; Peters, Grace (eds.), The Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer, Kluwer, pp.\\xa023–66, ISBN\\xa0978-1-4020-6708-2, archived from the original on 9 March 2012, retrieved 11 December 2012\\n\\n^ \"Machine Learning Algorithms\". GeeksforGeeks. 17 August 2023. Retrieved 3 September 2025.\\n\\n^ Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi (2014). Generative adversarial nets (PDF). Advances in Neural Information Processing Systems 27 (2014).\\n\\n^ Silver, David; Huang, Aja; Maddison, Christopher J. (2016). \"Mastering the game of Go with deep neural networks and tree search\". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. PMID\\xa026819042.\\n\\n^ Sindhu V, Nivedha S, Prakash M (February 2020). \"An Empirical Science Research on Bioinformatics in Machine Learning\". Journal of Mechanics of Continua and Mathematical Sciences (7). doi:10.26782/jmcms.spl.7/2020.02.00006.\\n\\n^ Sarle, Warren S. (1994). \"Neural Networks and statistical models\". SUGI 19: proceedings of the Nineteenth Annual SAS Users Group International Conference. SAS Institute. pp.\\xa01538–50. ISBN\\xa0978-1-55544-611-6. OCLC\\xa035546178.\\n\\n^ a b c d Russell, Stuart; Norvig, Peter (2003) [1995]. Artificial Intelligence: A Modern Approach (2nd\\xa0ed.). Prentice Hall. ISBN\\xa0978-0137903955.\\n\\n^ a b Langley, Pat (2011). \"The changing science of machine learning\". Machine Learning. 82 (3): 275–9. doi:10.1007/s10994-011-5242-y.\\n\\n^ Mahoney, Matt. \"Rationale for a Large Text Compression Benchmark\". Florida Institute of Technology. Archived from the original on 18 August 2006. Retrieved 5 March 2013.\\n\\n^ Shmilovici A.; Kahiri Y.; Ben-Gal I.; Hauser S. (2009). \"Measuring the Efficiency of the Intraday Forex Market with a Universal Data Compression Algorithm\" (PDF). Computational Economics. 33 (2): 131–154. CiteSeerX\\xa010.1.1.627.3751. doi:10.1007/s10614-008-9153-3. S2CID\\xa017234503. Archived (PDF) from the original on 9 July 2009.\\n\\n^ Ben-Gal, I. (2008). \"On the Use of Data Compression Measures to Analyze Robust Designs\" (PDF). IEEE Transactions on Reliability. 54 (3): 381–388. doi:10.1109/TR.2005.853280. S2CID\\xa09376086. Archived from the original (PDF) on 26 September 2020. Retrieved 6 April 2016.\\n\\n^ D. Scully; Carla E. Brodley (2006). \"Compression and Machine Learning: A New Perspective on Feature Space Vectors\". Data Compression Conference (DCC\\'06). p.\\xa0332. doi:10.1109/DCC.2006.13. ISBN\\xa00-7695-2545-8. S2CID\\xa012311412.\\n\\n^ Gary Adcock (5 January 2023). \"What Is AI Video Compression?\". massive.io. Retrieved 6 April 2023.\\n\\n^ Mentzer, Fabian; Toderici, George; Tschannen, Michael; Agustsson, Eirikur (2020). \"High-Fidelity Generative Image Compression\". arXiv:2006.09965 [eess.IV].\\n\\n^ \"What is Unsupervised Learning? | IBM\". www.ibm.com. 23 September 2021. Retrieved 5 February 2024.\\n\\n^ \"Differentially private clustering for large-scale datasets\". blog.research.google. 25 May 2023. Retrieved 16 March 2024.\\n\\n^ Edwards, Benj (28 September 2023). \"AI language models can exceed PNG and FLAC in lossless compression, says study\". Ars Technica. Retrieved 7 March 2024.\\n\\n^ Delétang, Grégoire; Ruoss, Anian; Duquenne, Paul-Ambroise; Catt, Elliot; Genewein, Tim; Mattern, Christopher; Grau-Moya, Jordi; Li Kevin Wenliang; Aitchison, Matthew; Orseau, Laurent; Hutter, Marcus; Veness, Joel (2023). \"Language Modeling is Compression\". arXiv:2309.10668 [cs.LG].\\n\\n^ Le Roux, Nicolas; Bengio, Yoshua; Fitzgibbon, Andrew (2012). \"Improving First and Second-Order Methods by Modeling Uncertainty\". In Sra, Suvrit; Nowozin, Sebastian; Wright, Stephen J. (eds.). Optimization for Machine Learning. MIT Press. p.\\xa0404. ISBN\\xa0978-0-262-01646-9. Archived from the original on 17 January 2023. Retrieved 12 November 2020.\\n\\n^ Bzdok, Danilo; Altman, Naomi; Krzywinski, Martin (2018). \"Statistics versus Machine Learning\". Nature Methods. 15 (4): 233–234. doi:10.1038/nmeth.4642. PMC\\xa06082636. PMID\\xa030100822.\\n\\n^ Hung et al. Algorithms to Measure Surgeon Performance and Anticipate Clinical Outcomes in Robotic Surgery. JAMA Surg. 2018\\n\\n^ Cornell University Library (August 2001). \"Breiman: Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)\". Statistical Science. 16 (3). doi:10.1214/ss/1009213726. S2CID\\xa062729017. Archived from the original on 26 June 2017. Retrieved 8 August 2015.\\n\\n^ Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). An Introduction to Statistical Learning. Springer. p.\\xa0vii. Archived from the original on 23 June 2019. Retrieved 25 October 2014.\\n\\n^ Ramezanpour, A.; Beam, A.L.; Chen, J.H.; Mashaghi, A. (17 November 2020). \"Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\". Diagnostics. 10 (11): 972. doi:10.3390/diagnostics10110972. PMC\\xa07699346. PMID\\xa033228143.\\n\\n^ Mashaghi, A.; Ramezanpour, A. (16 March 2018). \"Statistical physics of medical diagnostics: Study of a probabilistic model\". Physical Review E. 97 (3–1) 032118. arXiv:1803.10019. Bibcode:2018PhRvE..97c2118M. doi:10.1103/PhysRevE.97.032118. PMID\\xa029776109. S2CID\\xa04955393.\\n\\n^ Mohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). Foundations of Machine Learning. US, Massachusetts: MIT Press. ISBN\\xa09780262018258.\\n\\n^ Alpaydin, Ethem (2010). Introduction to Machine Learning. London: The MIT Press. ISBN\\xa0978-0-262-01243-0. Retrieved 4 February 2017.\\n\\n^ Jordan, M. I.; Mitchell, T. M. (17 July 2015). \"Machine learning: Trends, perspectives, and prospects\". Science. 349 (6245): 255–260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID\\xa026185243. S2CID\\xa0677218.\\n\\n^ El Naqa, Issam; Murphy, Martin J. (2015). \"What is Machine Learning?\". Machine Learning in Radiation Oncology. pp.\\xa03–11. doi:10.1007/978-3-319-18305-3_1. ISBN\\xa0978-3-319-18304-6. S2CID\\xa0178586107.\\n\\n^ Okolie, Jude A.; Savage, Shauna; Ogbaga, Chukwuma C.; Gunes, Burcu (June 2022). \"Assessing the potential of machine learning methods to study the removal of pharmaceuticals from wastewater using biochar or activated carbon\". Total Environment Research Themes. 1–2 100001. Bibcode:2022TERT....100001O. doi:10.1016/j.totert.2022.100001. S2CID\\xa0249022386.\\n\\n^ Russell, Stuart J.; Norvig, Peter (2010). Artificial Intelligence: A Modern Approach (Third\\xa0ed.). Prentice Hall. ISBN\\xa0978-0-13-604259-4.\\n\\n^ Mohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). Foundations of Machine Learning. The MIT Press. ISBN\\xa0978-0-262-01825-8.\\n\\n^ Alpaydin, Ethem (2010). Introduction to Machine Learning. MIT Press. p.\\xa09. ISBN\\xa0978-0-262-01243-0. Archived from the original on 17 January 2023. Retrieved 25 November 2018.\\n\\n^ De Sa, Christopher (Spring 2022). \"Lecture 2 Notes: Supervised Learning\". Cornell: Computer Science. Retrieved 1 July 2024.\\n\\n^ Jordan, Michael I.; Bishop, Christopher M. (2004). \"Neural Networks\". In Allen B. Tucker (ed.). Computer Science Handbook, Second Edition (Section VII: Intelligent Systems). Boca Raton, Florida: Chapman & Hall/CRC Press LLC. ISBN\\xa0978-1-58488-360-9.\\n\\n^ Misra, Ishan; Maaten, Laurens van der (2020). Self-Supervised Learning of Pretext-Invariant Representations. 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Seattle, WA, US: IEEE. pp.\\xa06707–6717. arXiv:1912.01991. doi:10.1109/CVPR42600.2020.00674.\\n\\n^ Jaiswal, Ashish; Babu, Ashwin Ramesh; Zadeh, Mohammad Zaki; Banerjee, Debapriya; Makedon, Fillia (March 2021). \"A Survey on Contrastive Self-Supervised Learning\". Technologies. 9 (1): 2. arXiv:2011.00362. doi:10.3390/technologies9010002. ISSN\\xa02227-7080.\\n\\n^ Roweis, Sam T.; Saul, Lawrence K. (22 December 2000). \"Nonlinear Dimensionality Reduction by Locally Linear Embedding\". Science. 290 (5500): 2323–2326. Bibcode:2000Sci...290.2323R. doi:10.1126/science.290.5500.2323. PMID\\xa011125150. S2CID\\xa05987139. Archived from the original on 15 August 2021. Retrieved 17 July 2023.\\n\\n^ Alex Ratner; Stephen Bach; Paroma Varma; Chris. \"Weak Supervision: The New Programming Paradigm for Machine Learning\". hazyresearch.github.io. referencing work by many other members of Hazy Research. Archived from the original on 6 June 2019. Retrieved 6 June 2019.\\n\\n^ van Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\". Reinforcement Learning. Adaptation, Learning, and Optimization. Vol.\\xa012. pp.\\xa03–42. doi:10.1007/978-3-642-27645-3_1. ISBN\\xa0978-3-642-27644-6.\\n\\n^ Pavel Brazdil; Christophe Giraud Carrier; Carlos Soares; Ricardo Vilalta (2009). Metalearning: Applications to Data Mining (Fourth\\xa0ed.). Springer Science+Business Media. pp.\\xa010–14, passim. ISBN\\xa0978-3-540-73262-4.\\n\\n^ Bozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397–402. ISBN\\xa0978-0-444-86488-8.\\n\\n^ Bozinovski, S. (1999) \"Crossbar Adaptive Array: The first connectionist network that solved the delayed reinforcement learning problem\" In A. Dobnikar, N. Steele, D. Pearson, R. Albert (eds.) Artificial Neural Networks and Genetic Algorithms, Springer Verlag, p. 320–325, ISBN 3-211-83364-1\\n\\n^ Bozinovski, Stevo (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255–263\\n\\n^ Bozinovski, S. (2001) \"Self-learning agents: A connectionist theory of emotion based on crossbar value judgment.\" Cybernetics and Systems 32(6) 637–667.\\n\\n^ Y. Bengio; A. Courville; P. Vincent (2013). \"Representation Learning: A Review and New Perspectives\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 35 (8): 1798–1828. arXiv:1206.5538. Bibcode:2013ITPAM..35.1798B. doi:10.1109/tpami.2013.50. PMID\\xa023787338. S2CID\\xa0393948.\\n\\n^ Nathan Srebro; Jason D. M. Rennie; Tommi S. Jaakkola (2004). Maximum-Margin Matrix Factorization. NIPS.\\n\\n^ Coates, Adam; Lee, Honglak; Ng, Andrew Y. (2011). An analysis of single-layer networks in unsupervised feature learning (PDF). Int\\'l Conf. on AI and Statistics (AISTATS). Archived from the original (PDF) on 13 August 2017. Retrieved 25 November 2018.\\n\\n^ Csurka, Gabriella; Dance, Christopher C.; Fan, Lixin; Willamowski, Jutta; Bray, Cédric (2004). Visual categorization with bags of keypoints (PDF). ECCV Workshop on Statistical Learning in Computer Vision. Archived (PDF) from the original on 13 July 2019. Retrieved 29 August 2019.\\n\\n^ Daniel Jurafsky; James H. Martin (2009). Speech and Language Processing. Pearson Education International. pp.\\xa0145–146.\\n\\n^ Lu, Haiping; Plataniotis, K.N.; Venetsanopoulos, A.N. (2011). \"A Survey of Multilinear Subspace Learning for Tensor Data\" (PDF). Pattern Recognition. 44 (7): 1540–1551. Bibcode:2011PatRe..44.1540L. doi:10.1016/j.patcog.2011.01.004. Archived (PDF) from the original on 10 July 2019. Retrieved 4 September 2015.\\n\\n^ Yoshua Bengio (2009). Learning Deep Architectures for AI. Now Publishers Inc. pp.\\xa01–3. ISBN\\xa0978-1-60198-294-0. Archived from the original on 17 January 2023. Retrieved 15 February 2016.\\n\\n^ Tillmann, A. M. (2015). \"On the Computational Intractability of Exact and Approximate Dictionary Learning\". IEEE Signal Processing Letters. 22 (1): 45–49. arXiv:1405.6664. Bibcode:2015ISPL...22...45T. doi:10.1109/LSP.2014.2345761. S2CID\\xa013342762.\\n\\n^ Aharon, M, M Elad, and A Bruckstein. 2006. \"K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation Archived 2018-11-23 at the Wayback Machine.\" Signal Processing, IEEE Transactions on 54 (11): 4311–4322\\n\\n^ Zimek, Arthur; Schubert, Erich (2017), \"Outlier Detection\", Encyclopedia of Database Systems, Springer New York, pp.\\xa01–5, doi:10.1007/978-1-4899-7993-3_80719-1, ISBN\\xa0978-1-4899-7993-3\\n\\n^ Hodge, V. J.; Austin, J. (2004). \"A Survey of Outlier Detection Methodologies\" (PDF). Artificial Intelligence Review. 22 (2): 85–126. CiteSeerX\\xa010.1.1.318.4023. doi:10.1007/s10462-004-4304-y. S2CID\\xa059941878. Archived (PDF) from the original on 22 June 2015. Retrieved 25 November 2018.\\n\\n^ Dokas, Paul; Ertoz, Levent; Kumar, Vipin; Lazarevic, Aleksandar; Srivastava, Jaideep; Tan, Pang-Ning (2002). \"Data mining for network intrusion detection\" (PDF). Proceedings NSF Workshop on Next Generation Data Mining. Archived (PDF) from the original on 23 September 2015. Retrieved 26 March 2023.\\n\\n^ Chandola, V.; Banerjee, A.; Kumar, V. (2009). \"Anomaly detection: A survey\". ACM Computing Surveys. 41 (3): 1–58. doi:10.1145/1541880.1541882. S2CID\\xa0207172599.\\n\\n^ Fleer, S.; Moringen, A.; Klatzky, R. L.; Ritter, H. (2020). \"Learning efficient haptic shape exploration with a rigid tactile sensor array, S. Fleer, A. Moringen, R. Klatzky, H. Ritter\". PLOS ONE. 15 (1) e0226880. arXiv:1902.07501. doi:10.1371/journal.pone.0226880. PMC\\xa06940144. PMID\\xa031896135.\\n\\n^ Moringen, Alexandra; Fleer, Sascha; Walck, Guillaume; Ritter, Helge (2020), Nisky, Ilana; Hartcher-O\\'Brien, Jess; Wiertlewski, Michaël; Smeets, Jeroen (eds.), \"Attention-Based Robot Learning of Haptic Interaction\", Haptics: Science, Technology, Applications, Lecture Notes in Computer Science, vol.\\xa012272, Cham: Springer International Publishing, pp.\\xa0462–470, doi:10.1007/978-3-030-58147-3_51, ISBN\\xa0978-3-030-58146-6, S2CID\\xa0220069113{{citation}}:  CS1 maint: work parameter with ISBN (link)\\n\\n^ Piatetsky-Shapiro, Gregory (1991), Discovery, analysis, and presentation of strong rules, in Piatetsky-Shapiro, Gregory; and Frawley, William J.; eds., Knowledge Discovery in Databases, AAAI/MIT Press, Cambridge, MA.\\n\\n^ Bassel, George W.; Glaab, Enrico; Marquez, Julietta; Holdsworth, Michael J.; Bacardit, Jaume (1 September 2011). \"Functional Network Construction in Arabidopsis Using Rule-Based Machine Learning on Large-Scale Data Sets\". The Plant Cell. 23 (9): 3101–3116. Bibcode:2011PlanC..23.3101B. doi:10.1105/tpc.111.088153. ISSN\\xa01532-298X. PMC\\xa03203449. PMID\\xa021896882.\\n\\n^ Agrawal, R.; Imieliński, T.; Swami, A. (1993). \"Mining association rules between sets of items in large databases\". Proceedings of the 1993 ACM SIGMOD international conference on Management of data - SIGMOD \\'93. p.\\xa0207. CiteSeerX\\xa010.1.1.40.6984. doi:10.1145/170035.170072. ISBN\\xa0978-0-89791-592-2. S2CID\\xa0490415.\\n\\n^ Urbanowicz, Ryan J.; Moore, Jason H. (22 September 2009). \"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\". Journal of Artificial Evolution and Applications. 2009: 1–25. doi:10.1155/2009/736398. ISSN\\xa01687-6229.\\n\\n^ Plotkin G.D. Automatic Methods of Inductive Inference Archived 22 December 2017 at the Wayback Machine, PhD thesis, University of Edinburgh, 1970.\\n\\n^ Shapiro, Ehud Y. Inductive inference of theories from facts Archived 21 August 2021 at the Wayback Machine, Research Report 192, Yale University, Department of Computer Science, 1981. Reprinted in J.-L. Lassez, G. Plotkin (Eds.), Computational Logic, The MIT Press, Cambridge, MA, 1991, pp. 199–254.\\n\\n^ Shapiro, Ehud Y. (1983). Algorithmic program debugging. Cambridge, Mass: MIT Press. ISBN\\xa00-262-19218-7\\n\\n^ Shapiro, Ehud Y. \"The model inference system Archived 2023-04-06 at the Wayback Machine.\" Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2. Morgan Kaufmann Publishers Inc., 1981.\\n\\n^ Burkov, Andriy (2019). The hundred-page machine learning book. Polen: Andriy Burkov. ISBN\\xa0978-1-9995795-0-0.\\n\\n^ Russell, Stuart J.; Norvig, Peter (2021). Artificial intelligence: a modern approach. Pearson series in artificial intelligence (Fourth\\xa0ed.). Hoboken: Pearson. ISBN\\xa0978-0-13-461099-3.\\n\\n^ Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng. \"Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations Archived 2017-10-18 at the Wayback Machine\" Proceedings of the 26th Annual International Conference on Machine Learning, 2009.\\n\\n^ \"RandomForestRegressor\". scikit-learn. Retrieved 12 February 2025.\\n\\n^ \"What Is Random Forest? | IBM\". www.ibm.com. 20 October 2021. Retrieved 12 February 2025.\\n\\n^ Cortes, Corinna; Vapnik, Vladimir N. (1995). \"Support-vector networks\". Machine Learning. 20 (3): 273–297. doi:10.1007/BF00994018.\\n\\n^ Stevenson, Christopher. \"Tutorial: Polynomial Regression in Excel\". facultystaff.richmond.edu. Archived from the original on 2 June 2013. Retrieved 22 January 2017.\\n\\n^ Wanta, Damian; Smolik, Aleksander; Smolik, Waldemar T.; Midura, Mateusz; Wróblewski, Przemysław (2025). \"Image reconstruction using machine-learned pseudoinverse in electrical capacitance tomography\". Engineering Applications of Artificial Intelligence. 142 109888. doi:10.1016/j.engappai.2024.109888.\\n\\n^ The documentation for scikit-learn also has similar examples Archived 2 November 2022 at the Wayback Machine.\\n\\n^ Goldberg, David E.; Holland, John H. (1988). \"Genetic algorithms and machine learning\" (PDF). Machine Learning. 3 (2): 95–99. doi:10.1007/bf00113892. S2CID\\xa035506513. Archived (PDF) from the original on 16 May 2011. Retrieved 3 September 2019.\\n\\n^ Michie, D.; Spiegelhalter, D. J.; Taylor, C. C. (1994). \"Machine Learning, Neural and Statistical Classification\". Ellis Horwood Series in Artificial Intelligence. Bibcode:1994mlns.book.....M.\\n\\n^ Zhang, Jun; Zhan, Zhi-hui; Lin, Ying; Chen, Ni; Gong, Yue-jiao; Zhong, Jing-hui; Chung, Henry S.H.; Li, Yun; Shi, Yu-hui (2011). \"Evolutionary Computation Meets Machine Learning: A Survey\". IEEE Computational Intelligence Magazine. 6 (4): 68–75. Bibcode:2011ICIM....6d..68Z. doi:10.1109/mci.2011.942584. S2CID\\xa06760276.\\n\\n^ Verbert, K.; Babuška, R.; De Schutter, B. (1 April 2017). \"Bayesian and Dempster–Shafer reasoning for knowledge-based fault diagnosis–A comparative study\". Engineering Applications of Artificial Intelligence. 60: 136–150. doi:10.1016/j.engappai.2017.01.011. ISSN\\xa00952-1976.\\n\\n^ Yoosefzadeh-Najafabadi, Mohsen; Hugh, Earl; Tulpan, Dan; Sulik, John; Eskandari, Milad (2021). \"Application of Machine Learning Algorithms in Plant Breeding: Predicting Yield From Hyperspectral Reflectance in Soybean?\". Front. Plant Sci. 11 624273. Bibcode:2021FrPS...1124273Y. doi:10.3389/fpls.2020.624273. PMC\\xa07835636. PMID\\xa033510761.\\n\\n^ Urbanowicz, Ryan J.; Moore, Jason H. (22 September 2009). \"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\". Journal of Artificial Evolution and Applications. 2009: 1–25. doi:10.1155/2009/736398. ISSN\\xa01687-6229.\\n\\n^ Zhang, C. and Zhang, S., 2002. Association rule mining: models and algorithms. Springer-Verlag.\\n\\n^ De Castro, Leandro Nunes, and Jonathan Timmis. Artificial immune systems: a new computational intelligence approach. Springer Science & Business Media, 2002.\\n\\n^ \"Federated Learning: Collaborative Machine Learning without Centralized Training Data\". Google AI Blog. 6 April 2017. Archived from the original on 7 June 2019. Retrieved 8 June 2019.\\n\\n^ Machine learning is included in the CFA Curriculum; see: [1] {{Webarchive|url=https://www.cfainstitute.org/\\n\\n^ Marcos M. López de Prado (2010). Machine Learning for Asset Managers. Cambridge University Press. ISBN\\xa09781108883658\\n\\n^ Ivanenko, Mikhail; Smolik, Waldemar T.; Wanta, Damian; Midura, Mateusz; Wróblewski, Przemysław; Hou, Xiaohan; Yan, Xiaoheng (2023). \"Image Reconstruction Using Supervised Learning in Wearable Electrical Impedance Tomography of the Thorax\". Sensors. 23 (18): 7774. Bibcode:2023Senso..23.7774I. doi:10.3390/s23187774. PMC\\xa010538128. PMID\\xa037765831.\\n\\n^ \"BelKor Home Page\" research.att.com\\n\\n^ \"The Netflix Tech Blog: Netflix Recommendations: Beyond the 5 stars (Part 1)\". 6 April 2012. Archived from the original on 31 May 2016. Retrieved 8 August 2015.\\n\\n^ Scott Patterson (13 July 2010). \"Letting the Machines Decide\". The Wall Street Journal. Archived from the original on 24 June 2018. Retrieved 24 June 2018.\\n\\n^ Vinod Khosla (10 January 2012). \"Do We Need Doctors or Algorithms?\". Tech Crunch. Archived from the original on 18 June 2018. Retrieved 20 October 2016.\\n\\n^ When A Machine Learning Algorithm Studied Fine Art Paintings, It Saw Things Art Historians Had Never Noticed Archived 4 June 2016 at the Wayback Machine, The Physics at ArXiv blog\\n\\n^ Vincent, James (10 April 2019). \"The first AI-generated textbook shows what robot writers are actually good at\". The Verge. Archived from the original on 5 May 2019. Retrieved 5 May 2019.\\n\\n^ Vaishya, Raju; Javaid, Mohd; Khan, Ibrahim Haleem; Haleem, Abid (1 July 2020). \"Artificial Intelligence (AI) applications for COVID-19 pandemic\". Diabetes & Metabolic Syndrome: Clinical Research & Reviews. 14 (4): 337–339. doi:10.1016/j.dsx.2020.04.012. PMC\\xa07195043. PMID\\xa032305024.\\n\\n^ Rezapouraghdam, Hamed; Akhshik, Arash; Ramkissoon, Haywantee (10 March 2021). \"Application of machine learning to predict visitors\\' green behavior in marine protected areas: evidence from Cyprus\". Journal of Sustainable Tourism. 31 (11): 2479–2505. doi:10.1080/09669582.2021.1887878. hdl:10037/24073.\\n\\n^ Dey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (15 June 2020). \"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE) (PDF). pp.\\xa01728–1733. doi:10.23919/DATE48585.2020.9116294. ISBN\\xa0978-3-9819263-4-7. S2CID\\xa0219858480. Archived from the original on 13 December 2021. Retrieved 20 January 2022.\\n\\n^ Quested, Tony. \"Smartphones get smarter with Essex innovation\". Business Weekly. Archived from the original on 24 June 2021. Retrieved 17 June 2021.\\n\\n^ Williams, Rhiannon (21 July 2020). \"Future smartphones \\'will prolong their own battery life by monitoring owners\\' behaviour\\'\". i. Archived from the original on 24 June 2021. Retrieved 17 June 2021.\\n\\n^ Rasekhschaffe, Keywan Christian; Jones, Robert C. (1 July 2019). \"Machine Learning for Stock Selection\". Financial Analysts Journal. 75 (3): 70–88. doi:10.1080/0015198X.2019.1596678. ISSN\\xa00015-198X. S2CID\\xa0108312507. Archived from the original on 26 November 2023. Retrieved 26 November 2023.\\n\\n^ Chung, Yunsie; Green, William H. (2024). \"Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates\". Chemical Science. 15 (7): 2410–2424. doi:10.1039/D3SC05353A. ISSN\\xa02041-6520. PMC\\xa010866337. PMID\\xa038362410.\\n\\n^ Sun, Yuran; Huang, Shih-Kai; Zhao, Xilei (1 February 2024). \"Predicting Hurricane Evacuation Decisions with Interpretable Machine Learning Methods\". International Journal of Disaster Risk Science. 15 (1): 134–148. arXiv:2303.06557. Bibcode:2024IJDRS..15..134S. doi:10.1007/s13753-024-00541-1. ISSN\\xa02192-6395.\\n\\n^ Sun, Yuran; Zhao, Xilei; Lovreglio, Ruggiero; Kuligowski, Erica (1 January 2024), Naser, M. Z. (ed.), \"8 - AI for large-scale evacuation modeling: promises and challenges\", Interpretable Machine Learning for the Analysis, Design, Assessment, and Informed Decision Making for Civil Infrastructure, Woodhead Publishing Series in Civil and Structural Engineering, Woodhead Publishing, pp.\\xa0185–204, ISBN\\xa0978-0-12-824073-1, archived from the original on 19 May 2024, retrieved 19 May 2024{{citation}}:  CS1 maint: work parameter with ISBN (link)\\n\\n^ Xu, Ningzhe; Lovreglio, Ruggiero; Kuligowski, Erica D.; Cova, Thomas J.; Nilsson, Daniel; Zhao, Xilei (1 March 2023). \"Predicting and Assessing Wildfire Evacuation Decision-Making Using Machine Learning: Findings from the 2019 Kincade Fire\". Fire Technology. 59 (2): 793–825. doi:10.1007/s10694-023-01363-1. ISSN\\xa01572-8099.\\n\\n^ Wang, Ke; Shi, Xiupeng; Goh, Algena Pei Xuan; Qian, Shunzhi (1 June 2019). \"A machine learning based study on pedestrian movement dynamics under emergency evacuation\". Fire Safety Journal. 106: 163–176. Bibcode:2019FirSJ.106..163W. doi:10.1016/j.firesaf.2019.04.008. hdl:10356/143390. ISSN\\xa00379-7112. Archived from the original on 19 May 2024. Retrieved 19 May 2024.\\n\\n^ Zhao, Xilei; Lovreglio, Ruggiero; Nilsson, Daniel (1 May 2020). \"Modelling and interpreting pre-evacuation decision-making using machine learning\". Automation in Construction. 113 103140. doi:10.1016/j.autcon.2020.103140. hdl:10179/17315. ISSN\\xa00926-5805. Archived from the original on 19 May 2024. Retrieved 19 May 2024.\\n\\n^ \"Why Machine Learning Models Often Fail to Learn: QuickTake Q&A\". Bloomberg.com. 10 November 2016. Archived from the original on 20 March 2017. Retrieved 10 April 2017.\\n\\n^ \"The First Wave of Corporate AI Is Doomed to Fail\". Harvard Business Review. 18 April 2017. Archived from the original on 21 August 2018. Retrieved 20 August 2018.\\n\\n^ \"Why the A.I. euphoria is doomed to fail\". VentureBeat. 18 September 2016. Archived from the original on 19 August 2018. Retrieved 20 August 2018.\\n\\n^ \"9 Reasons why your machine learning project will fail\". www.kdnuggets.com. Archived from the original on 21 August 2018. Retrieved 20 August 2018.\\n\\n^ a b Babuta, Alexander; Oswald, Marion; Rinik, Christine (2018). Transparency and Intelligibility (Report). Royal United Services Institute (RUSI). pp.\\xa017–22. Archived from the original on 9 December 2023. Retrieved 9 December 2023.\\n\\n^ \"Why Uber\\'s self-driving car killed a pedestrian\". The Economist. Archived from the original on 21 August 2018. Retrieved 20 August 2018.\\n\\n^ \"IBM\\'s Watson recommended \\'unsafe and incorrect\\' cancer treatments – STAT\". STAT. 25 July 2018. Archived from the original on 21 August 2018. Retrieved 21 August 2018.\\n\\n^ Hernandez, Daniela; Greenwald, Ted (11 August 2018). \"IBM Has a Watson Dilemma\". The Wall Street Journal. ISSN\\xa00099-9660. Archived from the original on 21 August 2018. Retrieved 21 August 2018.\\n\\n^ Allyn, Bobby (27 February 2023). \"How Microsoft\\'s experiment in artificial intelligence tech backfired\". National Public Radio. Archived from the original on 8 December 2023. Retrieved 8 December 2023.\\n\\n^ Reddy, Shivani M.; Patel, Sheila; Weyrich, Meghan; Fenton, Joshua; Viswanathan, Meera (2020). \"Comparison of a traditional systematic review approach with review-of-reviews and semi-automation as strategies to update the evidence\". Systematic Reviews. 9 (1): 243. doi:10.1186/s13643-020-01450-2. ISSN\\xa02046-4053. PMC\\xa07574591. PMID\\xa033076975.\\n\\n^ Rudin, Cynthia (2019). \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\". Nature Machine Intelligence. 1 (5): 206–215. doi:10.1038/s42256-019-0048-x. PMC\\xa09122117. PMID\\xa035603010.\\n\\n^ Hu, Tongxi; Zhang, Xuesong; Bohrer, Gil; Liu, Yanlan; Zhou, Yuyu; Martin, Jay; LI, Yang; Zhao, Kaiguang (2023). \"Crop yield prediction via explainable AI and interpretable machine learning: Dangers of black box models for evaluating climate change impacts on crop yield\". Agricultural and Forest Meteorology. 336 109458. Bibcode:2023AgFM..33609458H. doi:10.1016/j.agrformet.2023.109458. S2CID\\xa0258552400.\\n\\n^ Domingos 2015, Chapter 6, Chapter 7.\\n\\n^ Domingos 2015, p.\\xa0286.\\n\\n^ \"Single pixel change fools AI programs\". BBC News. 3 November 2017. Archived from the original on 22 March 2018. Retrieved 12 March 2018.\\n\\n^ \"AI Has a Hallucination Problem That\\'s Proving Tough to Fix\". WIRED. 2018. Archived from the original on 12 March 2018. Retrieved 12 March 2018.\\n\\n^ Madry, A.; Makelov, A.; Schmidt, L.; Tsipras, D.; Vladu, A. (4 September 2019). \"Towards deep learning models resistant to adversarial attacks\". arXiv:1706.06083 [stat.ML].\\n\\n^ \"Adversarial Machine Learning – CLTC UC Berkeley Center for Long-Term Cybersecurity\". CLTC. Archived from the original on 17 May 2022. Retrieved 25 May 2022.\\n\\n^ \"Machine-learning models vulnerable to undetectable backdoors\". The Register. Archived from the original on 13 May 2022. Retrieved 13 May 2022.\\n\\n^ \"Undetectable Backdoors Plantable In Any Machine-Learning Algorithm\". IEEE Spectrum. 10 May 2022. Archived from the original on 11 May 2022. Retrieved 13 May 2022.\\n\\n^ Goldwasser, Shafi; Kim, Michael P.; Vaikuntanathan, Vinod; Zamir, Or (14 April 2022). \"Planting Undetectable Backdoors in Machine Learning Models\". arXiv:2204.06974 [cs.LG].\\n\\n^ Kohavi, Ron (1995). \"A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection\" (PDF). International Joint Conference on Artificial Intelligence. Archived (PDF) from the original on 12 July 2018. Retrieved 26 March 2023.\\n\\n^ Catal, Cagatay (2012). \"Performance Evaluation Metrics for Software Fault Prediction Studies\" (PDF). Acta Polytechnica Hungarica. 9 (4). Retrieved 2 October 2016.\\n\\n^ a b Müller, Vincent C. (30 April 2020). \"Ethics of Artificial Intelligence and Robotics\". Stanford Encyclopedia of Philosophy. Archived from the original on 10 October 2020.\\n\\n^ \"Assessing potential future artificial intelligence risks, benefits and policy imperatives\". OECD. 14 November 2024. Retrieved 4 August 2025.\\n\\n^ a b Garcia, Megan (2016). \"Racist in the Machine\". World Policy Journal. 33 (4): 111–117. doi:10.1215/07402775-3813015. ISSN\\xa00740-2775. S2CID\\xa0151595343.\\n\\n^ Bostrom, Nick (2011). \"The Ethics of Artificial Intelligence\" (PDF). Archived from the original (PDF) on 4 March 2016. Retrieved 11 April 2016.\\n\\n^ Edionwe, Tolulope. \"The fight against racist algorithms\". The Outline. Archived from the original on 17 November 2017. Retrieved 17 November 2017.\\n\\n^ Jeffries, Adrianne. \"Machine learning is racist because the internet is racist\". The Outline. Archived from the original on 17 November 2017. Retrieved 17 November 2017.\\n\\n^ a b Silva, Selena; Kenney, Martin (2018). \"Algorithms, Platforms, and Ethnic Bias: An Integrative Essay\" (PDF). Phylon. 55 (1 & 2): 9–37. ISSN\\xa00031-8906. JSTOR\\xa026545017. Archived (PDF) from the original on 27 January 2024.\\n\\n^ Wong, Carissa (30 March 2023). \"AI \\'fairness\\' research held back by lack of diversity\". Nature. doi:10.1038/d41586-023-00935-z. PMID\\xa036997714. S2CID\\xa0257857012. Archived from the original on 12 April 2023. Retrieved 9 December 2023.\\n\\n^ a b Zhang, Jack Clark. \"Artificial Intelligence Index Report 2021\" (PDF). Stanford Institute for Human-Centered Artificial Intelligence. Archived from the original (PDF) on 19 May 2024. Retrieved 9 December 2023.\\n\\n^ Caliskan, Aylin; Bryson, Joanna J.; Narayanan, Arvind (14 April 2017). \"Semantics derived automatically from language corpora contain human-like biases\". Science. 356 (6334): 183–186. arXiv:1608.07187. Bibcode:2017Sci...356..183C. doi:10.1126/science.aal4230. ISSN\\xa00036-8075. PMID\\xa028408601. S2CID\\xa023163324.\\n\\n^ Wang, Xinan; Dasgupta, Sanjoy (2016), Lee, D. D.; Sugiyama, M.; Luxburg, U. V.; Guyon, I. (eds.), \"An algorithm for L1 nearest neighbor search via monotonic embedding\" (PDF), Advances in Neural Information Processing Systems 29, Curran Associates, Inc., pp.\\xa0983–991, archived (PDF) from the original on 7 April 2017, retrieved 20 August 2018\\n\\n^ M.O.R. Prates; P.H.C. Avelar; L.C. Lamb (11 March 2019). \"Assessing Gender Bias in Machine Translation – A Case Study with Google Translate\". arXiv:1809.02208 [cs.CY].\\n\\n^ Narayanan, Arvind (24 August 2016). \"Language necessarily contains human biases, and so will machines trained on language corpora\". Freedom to Tinker. Archived from the original on 25 June 2018. Retrieved 19 November 2016.\\n\\n^ Metz, Rachel (24 March 2016). \"Why Microsoft Accidentally Unleashed a Neo-Nazi Sexbot\". MIT Technology Review. Archived from the original on 9 November 2018. Retrieved 20 August 2018.\\n\\n^ Vincent, James (12 January 2018). \"Google \\'fixed\\' its racist algorithm by removing gorillas from its image-labeling tech\". The Verge. Archived from the original on 21 August 2018. Retrieved 20 August 2018.\\n\\n^ Crawford, Kate (25 June 2016). \"Opinion | Artificial Intelligence\\'s White Guy Problem\". New York Times. Archived from the original on 14 January 2021. Retrieved 20 August 2018.\\n\\n^ Simonite, Tom (30 March 2017). \"Microsoft: AI Isn\\'t Yet Adaptable Enough to Help Businesses\". MIT Technology Review. Archived from the original on 9 November 2018. Retrieved 20 August 2018.\\n\\n^ Hempel, Jessi (13 November 2018). \"Fei-Fei Li\\'s Quest to Make Machines Better for Humanity\". Wired. ISSN\\xa01059-1028. Archived from the original on 14 December 2020. Retrieved 17 February 2019.\\n\\n^ Char, D. S.; Shah, N. H.; Magnus, D. (2018). \"Implementing Machine Learning in Health Care—Addressing Ethical Challenges\". New England Journal of Medicine. 378 (11): 981–983. doi:10.1056/nejmp1714229. PMC\\xa05962261. PMID\\xa029539284.\\n\\n^ Research, AI (23 October 2015). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition\". airesearch.com. Archived from the original on 1 February 2016. Retrieved 23 October 2015.\\n\\n^ \"GPUs Continue to Dominate the AI Accelerator Market for Now\". InformationWeek. December 2019. Archived from the original on 10 June 2020. Retrieved 11 June 2020.\\n\\n^ Ray, Tiernan (2019). \"AI is changing the entire nature of compute\". ZDNet. Archived from the original on 25 May 2020. Retrieved 11 June 2020.\\n\\n^ \"AI and compute\". OpenAI. 16 May 2018. Archived from the original on 17 June 2020. Retrieved 11 June 2020.\\n\\n^ Jouppi, Norman P.; Young, Cliff; Patil, Nishant; Patterson, David; Agrawal, Gaurav; Bajwa, Raminder; Bates, Sarah; Bhatia, Suresh; Boden, Nan; Borchers, Al; Boyle, Rick; Cantin, Pierre-luc; Chao, Clifford; Clark, Chris; Coriell, Jeremy (24 June 2017). \"In-Datacenter Performance Analysis of a Tensor Processing Unit\". Proceedings of the 44th Annual International Symposium on Computer Architecture. ISCA \\'17. New York, NY, US: Association for Computing Machinery. pp.\\xa01–12. arXiv:1704.04760. doi:10.1145/3079856.3080246. ISBN\\xa0978-1-4503-4892-8.\\n\\n^ Best, Jo (8 December 2020). \"What is neuromorphic computing? Everything you need to know about how it is changing the future of computing\". ZDNET. Retrieved 21 November 2024.\\n\\n^ Hecate He (27 May 2021). Michael Sarazen; Chain Zhang (eds.). \"Cornell & NTT\\'s Physical Neural Networks: A \"Radical Alternative for Implementing Deep Neural Networks\" That Enables Arbitrary Physical Systems Training\". Synced. Archived from the original on 27 October 2021. Retrieved 12 October 2021.\\n\\n^ Clark, Lindsay (5 October 2021). \"Nano-spaghetti to solve neural network power consumption\". The Register. Archived from the original on 6 October 2021. Retrieved 12 October 2021.\\n\\n^ Fafoutis, Xenofon; Marchegiani, Letizia; Elsts, Atis; Pope, James; Piechocki, Robert; Craddock, Ian (7 May 2018). \"Extending the battery lifetime of wearable sensors with embedded machine learning\". 2018 IEEE 4th World Forum on Internet of Things (WF-IoT). pp.\\xa0269–274. doi:10.1109/WF-IoT.2018.8355116. hdl:1983/b8fdb58b-7114-45c6-82e4-4ab239c1327f. ISBN\\xa0978-1-4673-9944-9. S2CID\\xa019192912. Archived from the original on 18 January 2022. Retrieved 17 January 2022.\\n\\n^ \"A Beginner\\'s Guide To Machine learning For Embedded Systems\". Analytics India Magazine. 2 June 2021. Archived from the original on 18 January 2022. Retrieved 17 January 2022.\\n\\n^ Synced (12 January 2022). \"Google, Purdue & Harvard U\\'s Open-Source Framework for TinyML Achieves up to 75x Speedups on FPGAs | Synced\". syncedreview.com. Archived from the original on 18 January 2022. Retrieved 17 January 2022.\\n\\n^ AlSelek, Mohammad; Alcaraz-Calero, Jose M.; Wang, Qi (2024). \"Dynamic AI-IoT: Enabling Updatable AI Models in Ultralow-Power 5G IoT Devices\". IEEE Internet of Things Journal. 11 (8): 14192–14205. Bibcode:2024IITJ...1114192A. doi:10.1109/JIOT.2023.3340858.\\n\\n^ Giri, Davide; Chiu, Kuan-Lin; Di Guglielmo, Giuseppe; Mantovani, Paolo; Carloni, Luca P. (15 June 2020). \"ESP4ML: Platform-Based Design of Systems-on-Chip for Embedded Machine Learning\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE). pp.\\xa01049–1054. arXiv:2004.03640. doi:10.23919/DATE48585.2020.9116317. ISBN\\xa0978-3-9819263-4-7. S2CID\\xa0210928161. Archived from the original on 18 January 2022. Retrieved 17 January 2022.\\n\\n^ Louis, Marcia Sahaya; Azad, Zahra; Delshadtehrani, Leila; Gupta, Suyog; Warden, Pete; Reddi, Vijay Janapa; Joshi, Ajay (2019). \"Towards Deep Learning using TensorFlow Lite on RISC-V\". Harvard University. Archived from the original on 17 January 2022. Retrieved 17 January 2022.\\n\\n^ Ibrahim, Ali; Osta, Mario; Alameh, Mohamad; Saleh, Moustafa; Chible, Hussein; Valle, Maurizio (21 January 2019). \"Approximate Computing Methods for Embedded Machine Learning\". 2018 25th IEEE International Conference on Electronics, Circuits and Systems (ICECS). pp.\\xa0845–848. doi:10.1109/ICECS.2018.8617877. ISBN\\xa0978-1-5386-9562-3. S2CID\\xa058670712.\\n\\n^ \"dblp: TensorFlow Eager: A Multi-Stage, Python-Embedded DSL for Machine Learning\". dblp.org. Archived from the original on 18 January 2022. Retrieved 17 January 2022.\\n\\n^ Branco, Sérgio; Ferreira, André G.; Cabral, Jorge (5 November 2019). \"Machine Learning in Resource-Scarce Embedded Systems, FPGAs, and End-Devices: A Survey\". Electronics. 8 (11): 1289. doi:10.3390/electronics8111289. hdl:1822/62521. ISSN\\xa02079-9292.\\n\\n\\nSources[edit]\\nDomingos, Pedro (22 September 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN\\xa0978-0-465-06570-7.\\nNilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN\\xa0978-1-55860-467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\\nPoole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN\\xa0978-0-19-510270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\\nRussell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd\\xa0ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN\\xa00-13-790395-2.\\nFurther reading[edit]\\n\\nAlpaydin, Ethem (2020). Introduction to Machine Learning, (4th edition) MIT Press, ISBN\\xa09780262043793.\\nBishop, Christopher (1995). Neural Networks for Pattern Recognition, Oxford University Press. ISBN\\xa00-19-853864-2.\\nBishop, Christopher (2006) Pattern Recognition and Machine Learning, Springer. ISBN\\xa0978-0-387-31073-2\\nDomingos, Pedro (September 2015), The Master Algorithm, Basic Books, ISBN\\xa0978-0-465-06570-7\\nDuda, Richard O.; Hart, Peter E.; Stork, David G. (2001) Pattern classification (2nd edition), Wiley, New York, ISBN\\xa00-471-05669-3.\\nHastie, Trevor; Tibshirani, Robert & Friedman, Jerome H. (2009) The Elements of Statistical Learning, Springer. doi:10.1007/978-0-387-84858-7 ISBN\\xa00-387-95284-5.\\nMacKay, David J. C. Information Theory, Inference, and Learning Algorithms Cambridge: Cambridge University Press, 2003. ISBN\\xa00-521-64298-1\\nMurphy, Kevin P.  (2021). Probabilistic Machine Learning: An Introduction Archived 11 April 2021 at the Wayback Machine, MIT Press.\\nNilsson, Nils J. (2015) Introduction to Machine Learning Archived 16 August 2019 at the Wayback Machine.\\nRussell, Stuart &  Norvig, Peter (2020). Artificial Intelligence – A Modern Approach. (4th edition) Pearson, ISBN\\xa0978-0134610993.\\nSolomonoff, Ray, (1956) An Inductive Inference Machine Archived 26 April 2011 at the Wayback Machine A privately circulated report from the 1956 Dartmouth Summer Research Conference on AI.\\nWitten, Ian H. & Frank, Eibe (2011). Data Mining: Practical machine learning tools and techniques Morgan Kaufmann, 664pp., ISBN\\xa0978-0-12-374856-0.\\n\\nExternal links[edit]\\nInternational Machine Learning Society\\nmloss is an academic database of open-source machine learning software.\\nvteArtificial intelligence (AI)\\nHistory\\ntimeline\\nGlossary\\nCompanies\\nProjects\\nConcepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nPolicy gradient\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nUncanny valley\\nRLHF\\nSelf-supervised learning\\nReflection\\nRecursive self-improvement\\nHallucination\\nWord embedding\\nVibe coding\\nSafety (Alignment)\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge\\nNMT\\nReasoning\\nModel Context Protocol\\nIntelligent agent\\nArtificial human companion\\nHumanity\\'s Last Exam\\nLethal autonomous weapons (LAWs)\\nGenerative artificial intelligence (GenAI)\\n(Hypothetical: Artificial general intelligence (AGI))\\n(Hypothetical: Artificial superintelligence (ASI))\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nComputer vision\\nSpeech synthesis\\n15.ai\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nGPT Image\\nIdeogram\\nImagen\\nMidjourney\\nRecraft\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nRunway Gen\\nHailuo AI\\nKling\\nSora\\nVeo\\nMusic generation\\nRiffusion\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\n4.5\\n4.1\\no4-mini\\n5\\n5.1\\n5.2\\nClaude\\nGemini\\nGemini (language model)\\nGemma\\nGrok\\nLaMDA\\nBLOOM\\nDBRX\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDeepSeek\\nQwen\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nChristopher D. Manning\\nClaude Shannon\\nShun\\'ichi Amari\\nKunihiko Fukushima\\nTakeo Kanade\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nGeoffrey Hinton\\nJohn Hopfield\\nJürgen Schmidhuber\\nYann LeCun\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nJames Goodnight\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nOriol Vinyals\\nQuoc V. Le\\nIan Goodfellow\\nDemis Hassabis\\nDavid Silver\\nAndrej Karpathy\\nAshish Vaswani\\nNoam Shazeer\\nAidan Gomez\\nJohn Schulman\\nMustafa Suleyman\\nJan Leike\\nDaniel Kokotajlo\\nFrançois Chollet\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)\\nPolitical\\nRegulation of artificial intelligence\\nEthics of artificial intelligence\\nPrecautionary principle\\nAI alignment\\nEU Artificial Intelligence Act (AI Act)\\n\\n Category\\n\\nvteComputer scienceNote: This template roughly follows the 2012 ACM Computing Classification System.Hardware\\nPrinted circuit board\\nPeripheral\\nIntegrated circuit\\nVery-large-scale integration\\nSystem on a chip (SoC)\\nEnergy consumption (green computing)\\nElectronic design automation\\nHardware acceleration\\nProcessor\\nSize / Form\\nComputer systems organization\\nComputer architecture\\nComputational complexity\\nDependability\\nEmbedded system\\nReal-time computing\\nCyber-physical system\\nFault tolerance\\nWireless sensor network\\nNetworks\\nNetwork architecture\\nNetwork protocol\\nNetwork components\\nNetwork scheduler\\nNetwork performance evaluation\\nNetwork service\\nSoftware organization\\nInterpreter\\nMiddleware\\nVirtual machine\\nOperating system\\nSoftware quality\\nSoftware notations and tools\\nProgramming paradigm\\nProgramming language\\nCompiler\\nDomain-specific language\\nModeling language\\nSoftware framework\\nIntegrated development environment\\nSoftware configuration management\\nSoftware library\\nSoftware repository\\nSoftware development\\nControl flow\\nSoftware development process\\nRequirements analysis\\nSoftware design\\nSoftware construction\\nSoftware deployment\\nSoftware engineering\\nSoftware maintenance\\nProgramming team\\nOpen-source model\\nTheory of computation\\nModel of computation\\nStochastic\\nFormal language\\nAutomata theory\\nComputability theory\\nComputational complexity theory\\nLogic\\nSemantics\\nAlgorithms\\nAlgorithm design\\nAnalysis of algorithms\\nAlgorithmic efficiency\\nRandomized algorithm\\nComputational geometry\\nMathematics of computing\\nDiscrete mathematics\\nProbability\\nStatistics\\nMathematical software\\nInformation theory\\nMathematical analysis\\nNumerical analysis\\nTheoretical computer science\\nComputational problem\\nInformation systems\\nDatabase management system\\nInformation storage systems\\nEnterprise information system\\nSocial information systems\\nGeographic information system\\nDecision support system\\nProcess control system\\nMultimedia information system\\nData mining\\nDigital library\\nComputing platform\\nDigital marketing\\nWorld Wide Web\\nInformation retrieval\\nSecurity\\nCryptography\\nFormal methods\\nSecurity hacker\\nSecurity services\\nIntrusion detection system\\nHardware security\\nNetwork security\\nInformation security\\nApplication security\\nHuman-centered computing\\nInteraction design\\nAugmented reality\\nVirtual reality\\nSocial computing\\nUbiquitous computing\\nVisualization\\nAccessibility\\nHuman–computer interaction\\nMobile computing\\nConcurrency\\nConcurrent computing\\nParallel computing\\nDistributed computing\\nMultithreading\\nMultiprocessing\\nArtificial intelligence\\nNatural language processing\\nKnowledge representation and reasoning\\nComputer vision\\nAutomated planning and scheduling\\nSearch methodology\\nControl method\\nPhilosophy of artificial intelligence\\nDistributed artificial intelligence\\nMachine learning\\nSupervised learning\\nUnsupervised learning\\nReinforcement learning\\nMulti-task learning\\nCross-validation\\nGraphics\\nAnimation\\nRendering\\nPhotograph manipulation\\nGraphics processing unit\\nImage compression\\nSolid modeling\\nApplied computing\\nQuantum computing\\nE-commerce\\nEnterprise software\\nComputational mathematics\\nComputational physics\\nComputational chemistry\\nComputational biology\\nComputational social science\\nComputational engineering\\nDifferentiable computing\\nComputational healthcare\\nDigital art\\nElectronic publishing\\nCyberwarfare\\nElectronic voting\\nVideo games\\nWord processing\\nOperations research\\nEducational technology\\nDocument management\\nSpecialized Platform\\nDevelopment\\nThermodynamic computing\\n\\n Category\\n Outline\\n Glossaries\\n\\nPortals: Computer programming Mathematics Systems science TechnologyMachine learning at Wikipedia\\'s sister projects:Definitions from WiktionaryMedia from CommonsQuotations from WikiquoteTextbooks from WikibooksResources from WikiversityData from Wikidata\\nAuthority control databases InternationalGNDNationalUnited StatesJapanCzech RepublicIsraelOtherYale LUX\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Machine_learning&oldid=1332845049\"\\nCategories: Machine learningCyberneticsLearningDefinitionData scienceHidden categories: Webarchive template wayback linksCS1 maint: work parameter with ISBNArticles with short descriptionShort description is different from WikidataUse dmy dates from April 2025Use British English from October 2025All Wikipedia articles written in British EnglishArticles with excerptsAll articles with unsourced statementsArticles with unsourced statements from October 2025\\n\\n\\n\\n\\n\\n\\n This page was last edited on 14 January 2026, at 05:08\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nLegal & safety contacts\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nMachine learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n88 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'),\n",
       " Document(metadata={'source': 'https://en.wikipedia.org/wiki/Deep_learning', 'title': 'Deep learning - Wikipedia', 'language': 'en'}, page_content='\\n\\n\\n\\nDeep learning - Wikipedia\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nJump to content\\n\\n\\n\\n\\n\\n\\n\\nMain menu\\n\\n\\n\\n\\n\\nMain menu\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tNavigation\\n\\t\\n\\n\\nMain pageContentsCurrent eventsRandom articleAbout WikipediaContact us\\n\\n\\n\\n\\n\\n\\t\\tContribute\\n\\t\\n\\n\\nHelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDonate\\n\\nCreate account\\n\\nLog in\\n\\n\\n\\n\\n\\n\\n\\n\\nPersonal tools\\n\\n\\n\\n\\n\\nDonate Create account Log in\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nContents\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n(Top)\\n\\n\\n\\n\\n\\n1\\nOverview\\n\\n\\n\\n\\n\\n\\n\\n\\n2\\nInterpretations\\n\\n\\n\\n\\n\\n\\n\\n\\n3\\nHistory\\n\\n\\n\\n\\nToggle History subsection\\n\\n\\n\\n\\n\\n3.1\\nBefore 1980\\n\\n\\n\\n\\n\\n\\n\\n\\n3.2\\n1980s-2000s\\n\\n\\n\\n\\n\\n\\n\\n\\n3.3\\n2000s\\n\\n\\n\\n\\n\\n\\n\\n\\n3.4\\nDeep learning revolution\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n4\\nNeural networks\\n\\n\\n\\n\\nToggle Neural networks subsection\\n\\n\\n\\n\\n\\n4.1\\nDeep neural networks\\n\\n\\n\\n\\n\\n\\n4.1.1\\nChallenges\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n5\\nHardware\\n\\n\\n\\n\\n\\n\\n\\n\\n6\\nApplications\\n\\n\\n\\n\\nToggle Applications subsection\\n\\n\\n\\n\\n\\n6.1\\nAutomatic speech recognition\\n\\n\\n\\n\\n\\n\\n\\n\\n6.2\\nImage recognition\\n\\n\\n\\n\\n\\n\\n\\n\\n6.3\\nVisual art processing\\n\\n\\n\\n\\n\\n\\n\\n\\n6.4\\nNatural language processing\\n\\n\\n\\n\\n\\n\\n\\n\\n6.5\\nDrug discovery and toxicology\\n\\n\\n\\n\\n\\n\\n\\n\\n6.6\\nRecommendation systems\\n\\n\\n\\n\\n\\n\\n\\n\\n6.7\\nBioinformatics\\n\\n\\n\\n\\n\\n\\n\\n\\n6.8\\nDeep Neural Network Estimations\\n\\n\\n\\n\\n\\n\\n\\n\\n6.9\\nMedical image analysis\\n\\n\\n\\n\\n\\n\\n\\n\\n6.10\\nMobile advertising\\n\\n\\n\\n\\n\\n\\n\\n\\n6.11\\nImage restoration\\n\\n\\n\\n\\n\\n\\n\\n\\n6.12\\nFinancial fraud detection\\n\\n\\n\\n\\n\\n\\n\\n\\n6.13\\nMaterials science\\n\\n\\n\\n\\n\\n\\n\\n\\n6.14\\nMilitary\\n\\n\\n\\n\\n\\n\\n\\n\\n6.15\\nPartial differential equations\\n\\n\\n\\n\\n\\n\\n\\n\\n6.16\\nDeep backward stochastic differential equation method\\n\\n\\n\\n\\n\\n\\n\\n\\n6.17\\nImage reconstruction\\n\\n\\n\\n\\n\\n\\n\\n\\n6.18\\nWeather prediction\\n\\n\\n\\n\\n\\n\\n\\n\\n6.19\\nEpigenetic clock\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n7\\nRelation to human cognitive and brain development\\n\\n\\n\\n\\n\\n\\n\\n\\n8\\nCommercial activity\\n\\n\\n\\n\\n\\n\\n\\n\\n9\\nCriticism and comment\\n\\n\\n\\n\\nToggle Criticism and comment subsection\\n\\n\\n\\n\\n\\n9.1\\nTheory\\n\\n\\n\\n\\n\\n\\n\\n\\n9.2\\nErrors\\n\\n\\n\\n\\n\\n\\n\\n\\n9.3\\nCyber threat\\n\\n\\n\\n\\n\\n\\n\\n\\n9.4\\nData collection ethics\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n10\\nSee also\\n\\n\\n\\n\\n\\n\\n\\n\\n11\\nReferences\\n\\n\\n\\n\\n\\n\\n\\n\\n12\\nFurther reading\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nDeep learning\\n\\n\\n\\n64 languages\\n\\n\\n\\n\\nAfrikaansالعربيةAzərbaycancaবাংলা閩南語 / Bân-lâm-gíБългарскиBosanskiCatalàČeštinaDanskالدارجةDeutschEestiΕλληνικάEspañolEsperantoEuskaraفارسیFrançaisGaeilgeGalego한국어Հայերենहिन्दीHrvatskiIdoBahasa IndonesiaItalianoעבריתMagyarമലയാളംBahasa MelayuМонголNederlands日本語Norsk bokmålNorsk nynorskOccitanپښتوPolskiPortuguêsQaraqalpaqshaRomânăRuna SimiРусскийShqipසිංහලSimple EnglishSlovenščinaکوردیСрпски / srpskiSrpskohrvatski / српскохрватскиSuomiSvenskaதமிழ்ไทยТоҷикӣTürkçeУкраїнськаاردوTiếng Việt文言粵語中文\\n\\nEdit links\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nArticleTalk\\n\\n\\n\\n\\n\\nEnglish\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\n\\nTools\\n\\n\\n\\n\\n\\nTools\\nmove to sidebar\\nhide\\n\\n\\n\\n\\t\\tActions\\n\\t\\n\\n\\nReadEditView history\\n\\n\\n\\n\\n\\n\\t\\tGeneral\\n\\t\\n\\n\\nWhat links hereRelated changesUpload filePermanent linkPage informationCite this pageGet shortened URLDownload QR code\\n\\n\\n\\n\\n\\n\\t\\tPrint/export\\n\\t\\n\\n\\nDownload as PDFPrintable version\\n\\n\\n\\n\\n\\n\\t\\tIn other projects\\n\\t\\n\\n\\nWikimedia CommonsWikidata item\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAppearance\\nmove to sidebar\\nhide\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFrom Wikipedia, the free encyclopedia\\n\\n\\n\\nBranch of machine learning\\nFor the TV series episode, see Deep Learning (South Park).\\nRepresenting images on multiple layers of abstraction in deep learning[1]\\nPart of a series onArtificial intelligence (AI)\\nMajor goals\\nArtificial general intelligence\\nIntelligent agent\\nRecursive self-improvement\\nPlanning\\nComputer vision\\nGeneral game playing\\nKnowledge representation\\nNatural language processing\\nRobotics\\nAI safety\\n\\nApproaches\\nMachine learning\\nSymbolic\\nDeep learning\\nBayesian networks\\nEvolutionary algorithms\\nHybrid intelligent systems\\nSystems integration\\nOpen-source\\nAI data centers\\n\\nApplications\\nBioinformatics\\nDeepfake\\nEarth sciences\\n Finance \\nGenerative AI\\nArt\\nAudio\\nMusic\\nGovernment\\nHealthcare\\nMental health\\nIndustry\\nSoftware development\\nTranslation\\n Military \\nPhysics\\nProjects\\n\\nPhilosophy\\nAI alignment\\nArtificial consciousness\\nThe bitter lesson\\nChinese room\\nFriendly AI\\nEthics\\nExistential risk\\nTuring test\\nUncanny valley\\nHuman–AI interaction\\n\\nHistory\\nTimeline\\nProgress\\nAI winter\\nAI boom\\nAI bubble\\n\\nControversies\\nDeepfake pornography\\nTaylor Swift deepfake pornography controversy\\nGrok deepfake pornography controversy\\nGoogle Gemini image generation controversy\\nPause Giant AI Experiments\\nRemoval of Sam Altman from OpenAI\\nStatement on AI Risk\\nTay (chatbot)\\nThéâtre D\\'opéra Spatial\\nVoiceverse NFT plagiarism scandal\\n\\nGlossary\\nGlossary\\nvte\\nIn machine learning, deep learning focuses on utilizing multilayered neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and revolves around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be supervised, semi-supervised or unsupervised.[2]\\nSome common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.[3][4][5]\\nEarly forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.[6]\\n\\n\\nOverview[edit]\\nMost modern deep learning models are based on multi-layered neural networks such as convolutional neural networks and transformers, although they can also include propositional formulas or latent variables organized layer-wise in deep generative models such as the nodes in deep belief networks and deep Boltzmann machines.[7]\\nFundamentally, deep learning refers to a class of machine learning algorithms in which a hierarchy of layers is used to transform input data into a progressively more abstract and composite representation. For example, in an image recognition model, the raw input may be an image (represented as a tensor of pixels). The first representational layer may attempt to identify basic shapes such as lines and circles, the second layer may compose and encode arrangements of edges, the third layer may encode a nose and eyes, and the fourth layer may recognize that the image contains a face.\\nImportantly, a deep learning process can learn which features to optimally place at which level on its own. Prior to deep learning, machine learning techniques often involved hand-crafted feature engineering to transform the data into a more suitable representation for a classification algorithm to operate on. In the deep learning approach, features are not hand-crafted and the model discovers useful feature representations from the data automatically. This does not eliminate the need for hand-tuning; for example, varying numbers of layers and layer sizes can provide different degrees of abstraction.[8][2]\\nThe word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. More precisely, deep learning systems have a substantial credit assignment path (CAP) depth. The CAP is the chain of transformations from input to output. CAPs describe potentially causal connections between input and output. For a feedforward neural network, the depth of the CAPs is that of the network and is the number of hidden layers plus one (as the output layer is also parameterized). For recurrent neural networks, in which a signal may propagate through a layer more than once, the CAP depth is potentially unlimited.[9] No universally agreed-upon threshold of depth divides shallow learning from deep learning, but most researchers agree that deep learning involves CAP depth higher than two. CAP of depth two has been shown to be a universal approximator in the sense that it can emulate any function.[10] Beyond that, more layers do not add to the function approximator ability of the network. Deep models (CAP > two) are able to extract better features than shallow models and hence, extra layers help in learning the features effectively.\\nDeep learning architectures can be constructed with a greedy layer-by-layer method.[11] Deep learning helps to disentangle these abstractions and pick out which features improve performance.[8]\\nDeep learning algorithms can be applied to unsupervised learning tasks. This is an important benefit because unlabeled data is more abundant than the labeled data. Examples of deep structures that can be trained in an unsupervised manner are deep belief networks.[8][12]\\nThe term deep learning was introduced to the machine learning community by Rina Dechter in 1986,[13] and to artificial neural networks by Igor Aizenberg and colleagues in 2000, in the context of Boolean threshold neurons.[14][15] Although the history of its appearance is apparently more complicated.[16]\\n\\nInterpretations[edit]\\nDeep neural networks are generally interpreted in terms of the universal approximation theorem[17][18][19][20][21] or probabilistic inference.[22][23][8][9][24]\\nThe classic universal approximation theorem concerns the capacity of feedforward neural networks with a single hidden layer of finite size to approximate continuous functions.[17][18][19][20] In 1989, the first proof was published by George Cybenko for sigmoid activation functions[17] and was generalised to feed-forward multi-layer architectures in 1991 by Kurt Hornik.[18] Recent work also showed that universal approximation also holds for non-bounded activation functions such as Kunihiko Fukushima\\'s rectified linear unit.[25][26]\\nThe universal approximation theorem for deep neural networks concerns the capacity of networks with bounded width but the depth is allowed to grow. Lu et al.[21] proved that if the width of a deep neural network with ReLU activation is strictly larger than the input dimension, then the network can approximate any Lebesgue integrable function; if the width is smaller or equal to the input dimension, then a deep neural network is not a universal approximator.\\nThe probabilistic interpretation[24] derives from the field of machine learning. It features inference,[23][7][8][9][12][24] as well as the optimization concepts of training and testing, related to fitting and generalization, respectively. More specifically, the probabilistic interpretation considers the activation nonlinearity as a cumulative distribution function.[24] The probabilistic interpretation led to the introduction of dropout as regularizer in neural networks. The probabilistic interpretation was introduced by researchers including Hopfield, Widrow and Narendra and popularized in surveys such as the one by Bishop.[27]\\n\\nHistory[edit]\\nBefore 1980[edit]\\nThere are two types of artificial neural network (ANN): feedforward neural network (FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have cycles in their connectivity structure, FNNs don\\'t. In the 1920s, Wilhelm Lenz and Ernst Ising created the Ising model[28][29] which is essentially a non-learning RNN architecture consisting of neuron-like threshold elements. In 1972, Shun\\'ichi Amari made this architecture adaptive.[30][31] His learning RNN was republished by John Hopfield in 1982.[32] Other early recurrent neural networks were published by Kaoru Nakano in 1971.[33][34] Already in 1948, Alan Turing produced work on \"Intelligent Machinery\"  that was not published in his lifetime,[35] containing \"ideas related to artificial evolution and learning RNNs\".[31]\\nFrank Rosenblatt (1958)[36] proposed the perceptron, an MLP with 3 layers: an input layer, a hidden layer with randomized weights that did not learn, and an output layer. He later published a 1962 book that also introduced variants and computer experiments, including a version with four-layer perceptrons \"with adaptive preterminal networks\" where the last two layers have learned weights (here he credits H. D. Block and B. W. Knight).[37]:\\u200asection 16\\u200a The book cites an earlier network by R. D. Joseph (1960)[38] \"functionally equivalent to a variation of\" this four-layer system (the book mentions Joseph over 30 times). Should Joseph therefore be considered the originator of proper adaptive multilayer perceptrons with learning hidden units? Unfortunately, the learning algorithm was not a functional one, and fell into oblivion.\\nThe first working deep learning algorithm was the Group method of data handling, a method to train arbitrarily deep neural networks, published by Alexey Ivakhnenko and Lapa in 1965. They regarded it as a form of polynomial regression,[39] or a generalization of Rosenblatt\\'s perceptron to handle more complex, nonlinear, and hierarchical relationships.[40] A 1971 paper described a deep network with eight layers trained by this method,[41] which is based on layer by layer training through regression analysis. Superfluous hidden units are pruned using a separate validation set. Since the activation functions of the nodes are Kolmogorov-Gabor polynomials, these were also the first deep networks with multiplicative units or \"gates\".[31]\\nThe first deep learning multilayer perceptron trained by stochastic gradient descent[42] was published in 1967 by Shun\\'ichi Amari.[43] In computer experiments conducted by Amari\\'s student Saito, a five layer MLP with two modifiable layers learned  internal representations to classify non-linearily separable pattern classes.[31] Subsequent developments in hardware and hyperparameter tunings have made end-to-end stochastic gradient descent the currently dominant training technique.\\nIn 1969, Kunihiko Fukushima introduced the ReLU (rectified linear unit) activation function.[25][31] The rectifier has become the most popular activation function for deep learning.[44]\\nDeep learning architectures for convolutional neural networks (CNNs) with convolutional layers and downsampling layers began with the Neocognitron introduced by Kunihiko Fukushima in 1979, though not trained by backpropagation.[45][46]\\nBackpropagation is an efficient application of the chain rule derived by Gottfried Wilhelm Leibniz in 1673[47] to networks of differentiable nodes. The terminology \"back-propagating errors\" was actually introduced in 1962 by Rosenblatt,[37] but he did not know how to implement this, although Henry J. Kelley had a continuous precursor of backpropagation in 1960 in the context of control theory.[48] The modern form of backpropagation was first published in Seppo Linnainmaa\\'s master thesis (1970).[49][50][31] G.M. Ostrovski et al. republished it in 1971.[51][52] Paul Werbos applied backpropagation to neural networks in 1982[53] (his 1974 PhD thesis, reprinted in a 1994 book,[54] did not yet describe the algorithm[52]). In 1986, David E. Rumelhart et al. popularised backpropagation but did not cite the original work.[55][56]\\n\\n1980s-2000s[edit]\\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply CNN to phoneme recognition. It used convolutions, weight sharing, and backpropagation.[57][58]  In 1988, Wei Zhang applied a backpropagation-trained CNN to alphabet recognition.[59] \\nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP codes on mail. Training required 3 days.[60] In 1990, Wei Zhang implemented a CNN on optical computing hardware.[61] In 1991, a CNN was applied to medical image object segmentation[62] and breast cancer detection in mammograms.[63] LeNet-5 (1998), a 7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to recognize hand-written numbers on checks  digitized in 32x32 pixel images.[64]\\nRecurrent neural networks (RNN)[28][30] were further developed in the 1980s. Recurrence is used for sequence processing, and when a recurrent network is unrolled, it mathematically resembles a deep feedforward layer. Consequently, they have similar properties and issues, and their developments had mutual influences. In RNN, two early influential works were the Jordan network (1986)[65] and the Elman network (1990),[66] which applied RNN to study problems in cognitive psychology.\\nIn the 1980s, backpropagation did not work well for deep learning with long credit assignment paths. To overcome this problem, in 1991, Jürgen Schmidhuber proposed a hierarchy of RNNs pre-trained one level at a time by self-supervised learning where each RNN tries to predict its own next input, which is the next unexpected input of the RNN below.[67][68] This \"neural history compressor\" uses predictive coding  to learn internal representations at multiple self-organizing time scales. This can substantially facilitate downstream deep learning. The RNN hierarchy can be collapsed into a single RNN, by  distilling a higher level chunker network into a lower level automatizer network.[67][68][31] In 1993, a neural history compressor solved a \"Very Deep Learning\" task that required more than 1000 subsequent layers in an RNN unfolded in time.[69] The \"P\" in ChatGPT refers to such pre-training.\\nSepp Hochreiter\\'s diploma thesis (1991)[70] implemented the neural history compressor,[67] and identified and analyzed the vanishing gradient problem.[70][71]  Hochreiter proposed recurrent residual connections to solve the vanishing gradient problem. This led to the long short-term memory (LSTM), published in 1995.[72] LSTM can learn \"very deep learning\" tasks[9] with long credit assignment paths that require memories of events that happened thousands of discrete time steps before. That LSTM was not yet the modern architecture, which required a \"forget gate\", introduced in 1999,[73] which became the standard RNN architecture.\\nIn 1991, Jürgen Schmidhuber also published adversarial neural networks that contest with each other in the form of a zero-sum game, where one network\\'s gain is the other network\\'s loss.[74][75] The first network is a generative model that models a probability distribution over output patterns. The second network learns by gradient descent to predict the reactions of the environment to these patterns. This was called \"artificial curiosity\". In 2014, this principle was used in generative adversarial networks (GANs).[76]\\nDuring 1985–1995, inspired by statistical mechanics, several architectures and methods were developed by Terry Sejnowski, Peter Dayan, Geoffrey Hinton, etc., including the Boltzmann machine,[77] restricted Boltzmann machine,[78] Helmholtz machine,[79] and the wake-sleep algorithm.[80] These were designed for unsupervised learning of deep generative models. However, those were more computationally expensive compared to backpropagation. Boltzmann machine learning algorithm, published in 1985, was briefly popular before being eclipsed by the backpropagation algorithm in 1986. (p.\\xa0112 [81]). A 1988 network became state of the art in protein structure prediction, an early application of deep learning to bioinformatics.[82]\\nBoth shallow and deep learning (e.g., recurrent nets) of ANNs for speech recognition have been explored for many years.[83][84][85] These methods never outperformed non-uniform internal-handcrafting Gaussian mixture model/Hidden Markov model (GMM-HMM) technology based on generative models of speech trained discriminatively.[86] Key difficulties have been analyzed, including gradient diminishing[70] and weak temporal correlation structure in neural predictive models.[87][88] Additional difficulties were the lack of training data and limited computing power.\\nMost speech recognition researchers moved away from neural nets to pursue generative modeling. An exception was at SRI International in the late 1990s. Funded by the US government\\'s NSA and DARPA, SRI researched in speech and speaker recognition. The speaker recognition team led by Larry Heck reported significant success with deep neural networks in speech processing in the 1998 NIST Speaker Recognition benchmark.[89][90] It was deployed in the Nuance Verifier, representing the first major industrial application of deep learning.[91]\\nThe principle of elevating \"raw\" features over hand-crafted optimization was first explored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram or linear filter-bank features in the late 1990s,[90] showing its superiority over the Mel-Cepstral features that contain stages of fixed transformation from spectrograms. The raw features of speech, waveforms, later produced excellent larger-scale results.[92]\\n\\n2000s[edit]\\nNeural networks entered a lull, and simpler models that use task-specific handcrafted features such as Gabor filters and support vector machines (SVMs) became the preferred choices in the 1990s and 2000s, because of artificial neural networks\\' computational cost and a lack of understanding of how the brain wires its biological networks.[citation needed]\\nIn 2003, LSTM became competitive with traditional speech recognizers on certain tasks.[93] In 2006, Alex Graves, Santiago Fernández, Faustino Gomez, and Schmidhuber combined it with connectionist temporal classification (CTC)[94] in stacks of LSTMs.[95] In 2009, it became the first RNN to win a pattern recognition contest, in connected handwriting recognition.[96][9]\\nIn 2006, publications by Geoff Hinton, Ruslan Salakhutdinov, Osindero and Teh[97][98] deep belief networks were developed for generative modeling. They are trained by training one restricted Boltzmann machine, then freezing it and training another one on top of the first one, and so on, then optionally fine-tuned using supervised backpropagation.[99] They could model high-dimensional probability distributions, such as the distribution of MNIST images, but convergence was slow.[100][101][102]\\nThe impact of deep learning in industry began in the early 2000s, when CNNs already processed an estimated 10% to 20% of all the checks written in the US, according to Yann LeCun.[103] Industrial applications of deep learning to large-scale speech recognition started around 2010.\\nThe 2009 NIPS Workshop on Deep Learning for Speech Recognition was motivated by the limitations of deep generative models of speech, and the possibility that given more capable hardware and large-scale data sets that deep neural nets might become practical. It was believed that pre-training DNNs using generative models of deep belief nets (DBN) would overcome the main difficulties of neural nets. However, it was discovered that replacing pre-training with large amounts of training data for straightforward backpropagation when using DNNs with large, context-dependent output layers produced error rates dramatically lower than then-state-of-the-art Gaussian mixture model (GMM)/Hidden Markov Model (HMM) and also than more-advanced generative model-based systems.[104] The nature of the recognition errors produced by the two types of systems was characteristically different,[105] offering technical insights into how to integrate deep learning into the existing highly efficient, run-time speech decoding system deployed by all major speech recognition systems.[23][106][107] Analysis around 2009–2010, contrasting the GMM (and other generative speech models) vs. DNN models, stimulated early industrial investment in deep learning for speech recognition.[105]  That analysis was done with comparable performance (less than 1.5% in error rate) between discriminative DNNs and generative models.[104][105][108]\\nIn 2010, researchers extended deep learning from TIMIT to large vocabulary speech recognition, by adopting large output layers of the DNN based on context-dependent HMM states constructed by decision trees.[109][110][111][106]\\n\\nDeep learning revolution[edit]\\nHow deep learning is a subset of machine learning and how machine learning is a subset of artificial intelligence (AI)\\nThe deep learning revolution started around CNN- and GPU-based computer vision.\\nAlthough CNNs trained by backpropagation had been around for decades and GPU implementations of NNs for years,[112] including CNNs,[113] faster implementations of CNNs on GPUs were needed to progress on computer vision. Later, as deep learning becomes widespread, specialized hardware and algorithm optimizations were developed specifically for deep learning.[114]\\nA key advance for the deep learning revolution was hardware advances, especially GPU. Some early work dated back to 2004.[112][113] In 2009, Raina, Madhavan, and Andrew Ng reported a 100M deep belief network trained on 30 Nvidia GeForce GTX 280 GPUs, an early demonstration of GPU-based deep learning. They reported up to 70 times faster training.[115]\\nIn 2011, a CNN named DanNet[116][117] by Dan Ciresan, Ueli Meier, Jonathan Masci, Luca Maria Gambardella, and Jürgen Schmidhuber achieved for the first time superhuman performance in a visual pattern recognition contest, outperforming traditional methods by a factor of 3.[9] It then won more contests.[118][119] They also showed how max-pooling CNNs on GPU improved performance significantly.[3]\\nIn 2012, Andrew Ng and Jeff Dean created an FNN that learned to recognize higher-level concepts, such as cats, only from watching unlabeled images taken from YouTube videos.[120]\\nIn October 2012, AlexNet by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton[4] won the large-scale ImageNet competition by a significant margin over shallow machine learning methods. Further incremental improvements included the VGG-16 network by Karen Simonyan and Andrew Zisserman[121] and Google\\'s Inceptionv3.[122]\\nThe success in image classification was then extended to the more challenging task of generating descriptions (captions) for images, often as a combination of CNNs and LSTMs.[123][124][125]\\nIn 2014, the state of the art was training \"very deep neural network\" with 20 to 30 layers.[126] Stacking too many layers led to a steep reduction in training accuracy,[127] known as the \"degradation\" problem.[128] In 2015, two techniques were developed to train very deep networks: the highway network was published in May 2015, and the residual neural network (ResNet)[129] in Dec 2015. ResNet behaves like an open-gated Highway Net.\\nAround the same time, deep learning started impacting the field of art. Early examples included Google DeepDream (2015), and neural style transfer (2015),[130] both of which were based on pretrained image classification neural networks, such as VGG-19.\\nGenerative adversarial network (GAN) by (Ian Goodfellow et al., 2014)[131] (based on  Jürgen Schmidhuber\\'s principle of artificial curiosity[74][76])\\nbecame state of the art in generative modeling during 2014-2018 period. Excellent image quality is achieved by Nvidia\\'s StyleGAN (2018)[132] based on the Progressive GAN by Tero Karras et al.[133] Here the GAN generator is grown from small to large scale in a pyramidal fashion. Image generation by GAN reached popular success, and provoked discussions concerning deepfakes.[134] Diffusion models (2015)[135] eclipsed GANs in generative modeling since then, with systems such as DALL·E 2 (2022) and Stable Diffusion (2022).\\nIn 2015, Google\\'s speech recognition improved by 49% by an LSTM-based model, which they made available through Google Voice Search on smartphone.[136][137]\\nDeep learning is part of state-of-the-art systems in various disciplines, particularly computer vision and automatic speech recognition (ASR). Results on commonly used evaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range of large-vocabulary speech recognition tasks have steadily improved.[104][138] Convolutional neural networks were superseded for ASR by LSTM.[137][139][140][141] but are more successful in computer vision.\\nYoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the 2018 Turing Award for \"conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing\".[142]\\n\\nNeural networks[edit]\\nMain article: Artificial neural network\\nSimplified example of training a neural network in object detection: The network is trained by multiple images that are known to depict starfish and sea urchins, which are correlated with \"nodes\" that represent visual features. The starfish match with a ringed texture and a star outline, whereas most sea urchins match with a striped texture and oval shape. However, the instance of a ring textured sea urchin creates a weakly weighted association between them.Subsequent run of the network on an input image (left):[143] The network correctly detects the starfish. However, the weakly weighted association between ringed texture and sea urchin also confers a weak signal to the latter from one of two intermediate nodes. In addition, a shell that was not included in the training gives a weak signal for the oval shape, also resulting in a weak signal for the sea urchin output. These weak signals may result in a false positive result for sea urchin.In reality, textures and outlines would not be represented by single nodes, but rather by associated weight patterns of multiple nodes.\\nArtificial neural networks (ANNs) or connectionist systems are computing systems inspired by the biological neural networks that constitute animal brains. Such systems learn (progressively improve their ability) to do tasks by considering examples, generally without task-specific programming. For example, in image recognition, they might learn to identify images that contain cats by analyzing example images that have been manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats in other images. They have found most use in applications difficult to express with a traditional computer algorithm using rule-based programming.\\nAn ANN is based on a collection of connected units called artificial neurons, (analogous to biological neurons in a biological brain). Each connection (synapse) between neurons can transmit a signal to another neuron. The receiving (postsynaptic) neuron can process the signal(s) and then signal downstream neurons connected to it. Neurons may have state, generally represented by real numbers, typically between 0 and 1. Neurons and synapses may also have a weight that varies as learning proceeds, which can increase or decrease the strength of the signal that it sends downstream.\\nTypically, neurons are organized in layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first (input), to the last (output) layer, possibly after traversing the layers multiple times.\\nThe original goal of the neural network approach was to solve problems in the same way that a human brain would. Over time, attention focused on matching specific mental abilities, leading to deviations from biology such as backpropagation, or passing information in the reverse direction and adjusting the network to reflect that information.\\nNeural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\\nAs of 2017, neural networks typically have a few thousand to a few million units and millions of connections. Despite this number being several order of magnitude less than the number of neurons on a human brain, these networks can perform many tasks at a level beyond that of humans (e.g., recognizing faces, or playing \"Go\"[144]).\\n\\nDeep neural networks[edit]\\nA deep neural network (DNN) is an artificial neural network with multiple layers between the input and output layers.[7][9] There are different types of neural networks but they always consist of the same components: neurons, synapses, weights, biases, and functions.[145] These components as a whole function in a way that mimics functions of the human brain, and can be trained like any other ML algorithm.[citation needed]\\nFor example, a DNN that is trained to recognize dog breeds will go over the given image and calculate the probability that the dog in the image is a certain breed. The user can review the results and select which probabilities the network should display (above a certain threshold, etc.) and return the proposed label. Each mathematical manipulation as such is considered a layer,[146] and complex DNN have many layers, hence the name \"deep\" networks.\\nDNNs can model complex non-linear relationships. DNN architectures generate compositional models where the object is expressed as a layered composition of primitives.[147] The extra layers enable composition of features from lower layers, potentially modeling complex data with fewer units than a similarly performing shallow network.[7] For instance, it was proved that sparse multivariate polynomials are exponentially easier to approximate with DNNs than with shallow networks.[148]\\nDeep architectures include many variants of a few basic approaches. Each architecture has found success in specific domains. It is not always possible to compare the performance of multiple architectures, unless they have been evaluated on the same data sets.[146]\\nDNNs are typically feedforward networks in which data flows from the input layer to the output layer without looping back. At first, the DNN creates a map of virtual neurons and assigns random numerical values, or \"weights\", to connections between them. The weights and inputs are multiplied and return an output between 0 and 1. If the network did not accurately recognize a particular pattern, an algorithm would adjust the weights.[149] That way the algorithm can make certain parameters more influential, until it determines the correct mathematical manipulation to fully process the data.\\nRecurrent neural networks, in which data can flow in any direction, are used for applications such as language modeling.[150][151][152][153][154] Long short-term memory is particularly effective for this use.[155][156]\\nConvolutional neural networks (CNNs) are used in computer vision.[157] CNNs also have been applied to acoustic modeling for automatic speech recognition (ASR).[158]\\n\\nChallenges[edit]\\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues are overfitting and computation time.\\nDNNs are prone to overfitting because of the added layers of abstraction, which allow them to model rare dependencies in the training data. Regularization methods such as Ivakhnenko\\'s unit pruning[41] or weight decay (\\n\\n\\n\\n\\nℓ\\n\\n2\\n\\n\\n\\n\\n{\\\\displaystyle \\\\ell _{2}}\\n\\n-regularization) or sparsity (\\n\\n\\n\\n\\nℓ\\n\\n1\\n\\n\\n\\n\\n{\\\\displaystyle \\\\ell _{1}}\\n\\n-regularization) can be applied during training to combat overfitting.[159] Alternatively dropout regularization randomly omits units from the hidden layers during training. This helps to exclude rare dependencies.[160] Another interesting recent development is research into models of just enough complexity through an estimation of the intrinsic complexity of the task being modelled. This approach has been successfully applied for multivariate time series prediction tasks such as traffic prediction.[161] Finally, data can be augmented via methods such as cropping and rotating such that smaller training sets can be increased in size to reduce the chances of overfitting.[162]\\nDNNs must consider many training parameters, such as the size (number of layers and number of units per layer), the learning rate, and initial weights. Sweeping through the parameter space for optimal parameters may not be feasible due to the cost in time and computational resources. Various tricks, such as batching (computing the gradient on several training examples at once rather than individual examples)[163] speed up computation. Large processing capabilities of many-core architectures (such as GPUs or the Intel Xeon Phi) have produced significant speedups in training, because of the suitability of such processing architectures for the matrix and vector computations.[164][165]\\nAlternatively, engineers may look for other types of neural networks with more straightforward and convergent training algorithms. CMAC (cerebellar model articulation controller) is one such kind of neural network. It doesn\\'t require learning rates or randomized initial weights. The training process can be guaranteed to converge in one step with a new batch of data, and the computational complexity of the training algorithm is linear with respect to the number of neurons involved.[166][167]\\n\\nHardware[edit]\\nSince the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks that contain many layers of non-linear hidden units and a very large output layer.[168] By 2019, graphics processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method for training large-scale commercial cloud AI .[169] OpenAI estimated the hardware computation used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017) and found a 300,000-fold increase in the amount of computation required, with a doubling-time trendline of 3.4 months.[170][171]\\nSpecial electronic circuits called deep learning processors were designed to speed up deep learning algorithms. Deep learning processors include neural processing units (NPUs) in Huawei cellphones[172] and cloud computing servers such as tensor processing units (TPU) in the Google Cloud Platform.[173] Cerebras Systems has also built a dedicated system to handle large deep learning models, the CS-2, based on the largest processor in the industry, the second-generation Wafer Scale Engine (WSE-2).[174][175]\\nAtomically thin semiconductors are considered promising for energy-efficient deep learning hardware where the same basic device structure is used for both logic operations and data storage.\\nIn 2020, Marega et al. published experiments with a large-area active channel material for developing logic-in-memory devices and circuits based on floating-gate field-effect transistors (FGFETs).[176]\\nIn 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for parallel convolutional processing.[177] The authors identify two key advantages of integrated photonics over its electronic counterparts: (1) massively parallel data transfer through wavelength division multiplexing in conjunction with frequency combs, and (2) extremely high data modulation speeds.[177] Their system can execute trillions of multiply-accumulate operations per second, indicating the potential of integrated photonics in data-heavy AI applications.[177]\\n\\nApplications[edit]\\nAutomatic speech recognition[edit]\\nMain article: Speech recognition\\nLarge-scale automatic speech recognition is the first and most convincing successful case of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks[9] that involve multi-second intervals containing speech events separated by thousands of discrete time steps, where one time step corresponds to about 10 ms. LSTM with forget gates[156] is competitive with traditional speech recognizers on certain tasks.[93]\\nThe initial success in speech recognition was based on small-scale recognition tasks based on TIMIT. The data set contains 630 speakers from eight major dialects of American English, where each speaker reads 10 sentences.[178] Its small size lets many configurations be tried. More importantly, the TIMIT task concerns phone-sequence recognition, which, unlike word-sequence recognition, allows weak phone bigram language models. This lets the strength of the acoustic modeling aspects of speech recognition be more easily analyzed. The error rates listed below, including these early results and measured as percent phone error rates (PER), have been summarized since 1991.\\n\\n\\n\\nMethod\\nPercent phoneerror rate (PER) (%)\\n\\n\\nRandomly Initialized RNN[179]\\n26.1\\n\\n\\nBayesian Triphone GMM-HMM\\n25.6\\n\\n\\nHidden Trajectory (Generative) Model\\n24.8\\n\\n\\nMonophone Randomly Initialized DNN\\n23.4\\n\\n\\nMonophone DBN-DNN\\n22.4\\n\\n\\nTriphone GMM-HMM with BMMI Training\\n21.7\\n\\n\\nMonophone DBN-DNN on fbank\\n20.7\\n\\n\\nConvolutional DNN[180]\\n20.0\\n\\n\\nConvolutional DNN w. Heterogeneous Pooling\\n18.7\\n\\n\\nEnsemble DNN/CNN/RNN[181]\\n18.3\\n\\n\\nBidirectional LSTM\\n17.8\\n\\n\\nHierarchical Convolutional Deep Maxout Network[182]\\n16.5\\n\\nThe debut of DNNs for speaker recognition in the late 1990s and speech recognition around 2009-2011 and of LSTM around 2003–2007, accelerated progress in eight major areas:[23][108][106]\\n\\nScale-up/out and accelerated DNN training and decoding\\nSequence discriminative training\\nFeature processing by deep models with solid understanding of the underlying mechanisms\\nAdaptation of DNNs and related deep models\\nMulti-task and transfer learning by DNNs and related deep models\\nCNNs and how to design them to best exploit domain knowledge of speech\\nRNN and its rich LSTM variants\\nOther types of deep models including tensor-based models and integrated deep generative/discriminative models.\\nMore recent speech recognition models use Transformers or Temporal Convolution Networks with significant success and widespread applications.[183][184][185] All major commercial speech recognition systems (e.g., Microsoft Cortana, Xbox, Skype Translator, Amazon Alexa, Google Now, Apple Siri, Baidu and iFlyTek voice search, and a range of Nuance speech products, etc.) are based on deep learning.[23][186][187]\\n\\nImage recognition[edit]\\nMain article: Computer vision\\nRichard Green explains how deep learning is used with a remotely operated vehicle in mussel aquaculture.\\nA common evaluation set for image classification is the MNIST database data set. MNIST is composed of handwritten digits and includes 60,000 training examples and 10,000 test examples. As with TIMIT, its small size lets users test multiple configurations. A comprehensive list of results on this set is available.[188]\\nDeep learning-based image recognition has become \"superhuman\", producing more accurate results than human contestants. This first occurred in 2011 in recognition of traffic signs, and in 2014, with recognition of human faces.[189][190]\\nDeep learning-trained vehicles now interpret 360° camera views.[191] Another example is Facial Dysmorphology Novel Analysis (FDNA) used to analyze cases of human malformation connected to a large database of genetic syndromes.\\n\\nVisual art processing[edit]\\nVisual art processing of Jimmy Wales in France, with the style of Munch\\'s \"The Scream\" applied using neural style transfer\\nClosely related to the progress that has been made in image recognition is the increasing application of deep learning techniques to various visual art tasks. DNNs have proven themselves capable, for example, of\\n\\nidentifying the style period of a given painting[192][193]\\nNeural Style Transfer\\xa0–  capturing the style of a given artwork and applying it in a visually pleasing manner to an arbitrary photograph or video[192][193]\\ngenerating striking imagery based on random visual input fields.[192][193]\\nNatural language processing[edit]\\nMain article: Natural language processing\\nNeural networks have been used for implementing language models since the early 2000s.[150] LSTM helped to improve machine translation and language modeling.[151][152][153]\\nOther key techniques in this field are negative sampling[194] and word embedding. Word embedding, such as word2vec, can be thought of as a representational layer in a deep learning architecture that transforms an atomic word into a positional representation of the word relative to other words in the dataset; the position is represented as a point in a vector space. Using word embedding as an RNN input layer allows the network to parse sentences and phrases using an effective compositional vector grammar. A compositional vector grammar can be thought of as probabilistic context free grammar (PCFG) implemented by an RNN.[195] Recursive auto-encoders built atop word embeddings can assess sentence similarity and detect paraphrasing.[195] Deep neural architectures provide the best results for constituency parsing,[196] sentiment analysis,[197] information retrieval,[198][199] spoken language understanding,[200] machine translation,[151][201] contextual entity linking,[201] writing style recognition,[202] named-entity recognition (token classification),[203] text classification, and others.[204]\\nRecent developments generalize word embedding to sentence embedding.\\nGoogle Translate (GT) uses a large end-to-end long short-term memory (LSTM) network.[205][206][207][208] Google Neural Machine Translation (GNMT) uses an example-based machine translation method in which the system \"learns from millions of examples\".[206] It translates \"whole sentences at a time, rather than pieces\". Google Translate supports over one hundred languages.[206] The network encodes the \"semantics of the sentence rather than simply memorizing phrase-to-phrase translations\".[206][209] GT uses English as an intermediate between most language pairs.[209]\\n\\nDrug discovery and toxicology[edit]\\nFor more information, see Drug discovery and Toxicology.\\nA large percentage of candidate drugs fail to win regulatory approval. These failures are caused by insufficient efficacy (on-target effect), undesired interactions (off-target effects), or unanticipated toxic effects.[210][211] Research has explored use of deep learning to predict the biomolecular targets,[212][213] off-targets, and toxic effects of environmental chemicals in nutrients, household products and drugs.[214][215][216]\\nAtomNet is a deep learning system for structure-based rational drug design.[217] AtomNet was used to predict novel candidate biomolecules for disease targets such as the Ebola virus[218] and multiple sclerosis.[219][218]\\nIn 2017 graph neural networks were used for the first time to predict various properties of molecules in a large toxicology data set.[220] In 2019, generative neural networks were used to produce molecules that were validated experimentally all the way into mice.[221][222]\\n\\nRecommendation systems[edit]\\nMain article: Recommender system\\nRecommendation systems have used deep learning to extract meaningful features for a latent factor model for content-based music and journal recommendations.[223][224] Multi-view deep learning has been applied for learning user preferences from multiple domains.[225] The model uses a hybrid collaborative and content-based approach and enhances recommendations in multiple tasks.\\n\\nBioinformatics[edit]\\nMain article: Bioinformatics\\nAn autoencoder ANN was used in bioinformatics, to predict gene ontology annotations and gene-function relationships.[226]\\nIn medical informatics, deep learning was used to predict sleep quality based on data from wearables[227] and predictions of health complications from electronic health record data.[228]\\nDeep neural networks have shown unparalleled performance in predicting protein structure, according to the sequence of the amino acids that make it up. In 2020, AlphaFold, a deep-learning based system, achieved a level of accuracy significantly higher than all previous computational methods.[229][230]\\n\\nDeep Neural Network Estimations[edit]\\nDeep neural networks can be used to estimate the entropy of a stochastic process through an arrangement called a Neural Joint Entropy Estimator (NJEE).[231] Such an estimation provides insights on the effects of input random variables on an independent random variable. Practically, the DNN is trained as a classifier that maps an input vector or matrix X to an output probability distribution over the possible classes of random variable Y, given input X. For example, in image classification tasks, the NJEE maps a vector of pixels\\' color values to probabilities over possible image classes. In practice, the probability distribution of Y is obtained by a Softmax layer with number of nodes that is equal to the alphabet size of Y. NJEE uses continuously differentiable activation functions, such that the conditions for the universal approximation theorem holds. It is shown that this method provides a strongly consistent estimator and outperforms other methods in cases of large alphabet sizes.[231]\\n\\nMedical image analysis[edit]\\nDeep learning has been shown to produce competitive results in medical applications such as cancer cell classification, lesion detection, organ segmentation and image enhancement.[232][233] Modern deep learning tools demonstrate the high accuracy of detecting various diseases and the helpfulness of their use by specialists to improve the diagnosis efficiency.[234][235]\\n\\nMobile advertising[edit]\\nFinding the appropriate mobile audience for mobile advertising is always challenging, since many data points must be considered and analyzed before a target segment can be created and used in ad serving by any ad server.[236] Deep learning has been used to interpret large, many-dimensioned advertising datasets. Many data points are collected during the request/serve/click internet advertising cycle. This information can form the basis of machine learning to improve ad selection.\\n\\nImage restoration[edit]\\nDeep learning has been successfully applied to inverse problems such as denoising, super-resolution, inpainting, and film colorization.[237] These applications include learning methods such as \"Shrinkage Fields for Effective Image Restoration\"[238] which trains on an image dataset, and Deep Image Prior, which trains on the image that needs restoration.\\n\\nFinancial fraud detection[edit]\\nDeep learning is being successfully applied to financial fraud detection, tax evasion detection,[239] and anti-money laundering.[240]\\n\\nMaterials science[edit]\\nIn November 2023, researchers at Google DeepMind and Lawrence Berkeley National Laboratory announced that they had developed an AI system known as GNoME. This system has contributed to materials science by discovering over 2 million new materials within a relatively short timeframe. GNoME employs deep learning techniques to efficiently explore potential material structures, achieving a significant increase in the identification of stable inorganic crystal structures. The system\\'s predictions were validated through autonomous robotic experiments, demonstrating a noteworthy success rate of 71%. The data of newly discovered materials is publicly available through the Materials Project database, offering researchers the opportunity to identify materials with desired properties for various applications. This development has implications for the future of scientific discovery and the integration of AI in material science research, potentially expediting material innovation and reducing costs in product development. The use of AI and deep learning suggests the possibility of minimizing or eliminating manual lab experiments and allowing scientists to focus more on the design and analysis of unique compounds.[241][242][243]\\n\\nMilitary[edit]\\nThe United States Department of Defense applied deep learning to train robots in new tasks through observation.[244]\\n\\nPartial differential equations[edit]\\nPhysics informed neural networks have been used to solve partial differential equations in both forward and inverse problems in a data driven manner.[245] One example is the reconstructing fluid flow governed by the Navier-Stokes equations. Using physics informed neural networks does not require the often expensive mesh generation that conventional CFD methods rely on.[246][247] It is evident that geometric and physical constraints have a synergistic effect on neural PDE surrogates, thereby enhancing their efficacy in predicting stable and super long rollouts.[248]\\n\\nDeep backward stochastic differential equation method[edit]\\nDeep backward stochastic differential equation method is a numerical method that combines deep learning with Backward stochastic differential equation (BSDE). This method is particularly useful for solving high-dimensional problems in financial mathematics. By leveraging the powerful function approximation capabilities of deep neural networks, deep BSDE addresses the computational challenges faced by traditional numerical methods in high-dimensional settings. Specifically, traditional methods like finite difference methods or Monte Carlo simulations often struggle with the curse of dimensionality, where computational cost increases exponentially with the number of dimensions. Deep BSDE methods, however, employ deep neural networks to approximate solutions of high-dimensional partial differential equations (PDEs), effectively reducing the computational burden.[249]\\nIn addition, the integration of Physics-informed neural networks (PINNs) into the deep BSDE framework enhances its capability by embedding the underlying physical laws directly into the neural network architecture. This ensures that the solutions not only fit the data but also adhere to the governing stochastic differential equations. PINNs leverage the power of deep learning while respecting the constraints imposed by the physical models, resulting in more accurate and reliable solutions for financial mathematics problems.\\n\\nImage reconstruction[edit]\\nImage reconstruction is the reconstruction of the underlying images from the image-related measurements. Several works showed the better and superior performance of the deep learning methods compared to analytical methods for various applications, e.g., spectral imaging [250] and ultrasound imaging.[251]\\n\\nWeather prediction[edit]\\nTraditional weather prediction systems solve a very complex system of partial differential equations. GraphCast is a deep learning based model, trained on a long history of weather data to predict how weather patterns change over time. It is able to  predict weather conditions for up to 10 days globally, at a very detailed level, and in under a minute, with precision similar to state of the art systems.[252][253]\\n\\nEpigenetic clock[edit]\\nMain article: Epigenetic clock\\nAn epigenetic clock is a biochemical test that can be used to measure age. Galkin et al. used deep neural networks to train an epigenetic aging clock of unprecedented accuracy using >6,000 blood samples.[254] The clock uses information from 1000 CpG sites and predicts people with certain conditions older than healthy controls: IBD, frontotemporal dementia, ovarian cancer, obesity. The aging clock was planned to be released for public use in 2021 by an Insilico Medicine spinoff company Deep Longevity.\\n\\nRelation to human cognitive and brain development[edit]\\nDeep learning is closely related to a class of theories of brain development (specifically, neocortical development) proposed by cognitive neuroscientists in the early 1990s.[255][256][257][258] These developmental theories were instantiated in computational models, making them predecessors of deep learning systems. These developmental models share the property that various proposed learning dynamics in the brain (e.g., a wave of nerve growth factor) support the self-organization somewhat analogous to the neural networks utilized in deep learning models. Like the neocortex, neural networks employ a hierarchy of layered filters in which each layer considers information from a prior layer (or the operating environment), and then passes its output (and possibly the original input), to other layers. This process yields a self-organizing stack of transducers, well-tuned to their operating environment. A 1995 description stated, \"...the infant\\'s brain seems to organize itself under the influence of waves of so-called trophic-factors ... different regions of the brain become connected sequentially, with one layer of tissue maturing before another and so on until the whole brain is mature\".[259]\\nA variety of approaches have been used to investigate the plausibility of deep learning models from a neurobiological perspective. On the one hand, several variants of the backpropagation algorithm have been proposed in order to increase its processing realism.[260][261] Other researchers have argued that unsupervised forms of deep learning, such as those based on hierarchical generative models and deep belief networks, may be closer to biological reality.[262][263] In this respect, generative neural network models have been related to neurobiological evidence about sampling-based processing in the cerebral cortex.[264]\\nAlthough a systematic comparison between the human brain organization and the neuronal encoding in deep networks has not yet been established, several analogies have been reported. For example, the computations performed by deep learning units could be similar to those of actual neurons[265] and neural populations.[266] Similarly, the representations developed by deep learning models are similar to those measured in the primate visual system[267] both at the single-unit[268] and at the population[269] levels.\\n\\nCommercial activity[edit]\\nFacebook\\'s AI lab performs tasks such as automatically tagging uploaded pictures with the names of the people in them.[270]\\nGoogle\\'s DeepMind Technologies developed a system capable of learning how to play Atari video games using only pixels as data input. In 2015 they demonstrated their AlphaGo system, which learned the game of Go well enough to beat a professional Go player.[271][272][273] Google Translate uses a neural network to translate between more than 100 languages.\\nIn 2017, Covariant.ai was launched, which focuses on integrating deep learning into factories.[274]\\nAs of 2008,[275] researchers at The University of Texas at Austin (UT) developed a machine learning framework called Training an Agent Manually via Evaluative Reinforcement, or TAMER, which proposed new methods for robots or computer programs to learn how to perform tasks by interacting with a human instructor.[244] First developed as TAMER, a new algorithm called Deep TAMER was later introduced in 2018 during a collaboration between U.S. Army Research Laboratory (ARL) and UT researchers. Deep TAMER used deep learning to provide a robot with the ability to learn new tasks through observation.[244] Using Deep TAMER, a robot learned a task with a human trainer, watching video streams or observing a human perform a task in-person. The robot later practiced the task with the help of some coaching from the trainer, who provided feedback such as \"good job\" and \"bad job\".[276]\\n\\nCriticism and comment[edit]\\nDeep learning has attracted both criticism and comment, in some cases from outside the field of computer science.\\n\\nTheory[edit]\\nSee also: Explainable artificial intelligence\\nA main criticism concerns the lack of theory surrounding some methods.[277] Learning in the most common deep architectures is implemented using well-understood gradient descent. However, the theory surrounding other algorithms, such as contrastive divergence is less clear.[citation needed] (e.g., Does it converge? If so, how fast? What is it approximating?) Deep learning methods are often looked at as a black box, with most confirmations done empirically, rather than theoretically.[278]\\nIn further reference to the idea that artistic sensitivity might be inherent in relatively low levels of the cognitive hierarchy, a published series of graphic representations of the internal states of deep (20-30 layers) neural networks attempting to discern within essentially random data the images on which they were trained[279] demonstrate a visual appeal: the original research notice received well over 1,000 comments, and was the subject of what was for a time the most frequently accessed article on The Guardian\\'s[280] website.\\nWith the support of Innovation Diffusion Theory (IDT), a study analyzed the diffusion of Deep Learning[281] in BRICS and OECD countries using data from Google Trends.\\n\\nErrors[edit]\\nSome deep learning architectures display problematic behaviors,[282] such as confidently classifying unrecognizable images as belonging to a familiar category of ordinary images (2014)[283] and misclassifying minuscule perturbations of correctly classified images (2013).[284] Goertzel hypothesized that these behaviors are due to limitations in their internal representations and that these limitations would inhibit integration into heterogeneous multi-component artificial general intelligence (AGI) architectures.[282] These issues may possibly be addressed by deep learning architectures that internally form states homologous to image-grammar[285] decompositions of observed entities and events.[282] Learning a grammar (visual or linguistic) from training data would be equivalent to restricting the system to commonsense reasoning that operates on concepts in terms of grammatical production rules and is a basic goal of both human language acquisition[286] and artificial intelligence (AI).[287]\\n\\nCyber threat[edit]\\nAs deep learning moves from the lab into the world, research and experience show that artificial neural networks are vulnerable to hacks and deception.[288] By identifying patterns that these systems use to function, attackers can modify inputs to ANNs in such a way that the ANN finds a match that human observers would not recognize. For example, an attacker can make subtle changes to an image such that the ANN finds a match even though the image looks to a human nothing like the search target. Such manipulation is termed an \"adversarial attack\".[289]\\nIn 2016 researchers used one ANN to doctor images in trial and error fashion, identify another\\'s focal points, and thereby generate images that deceived it. The modified images looked no different to human eyes. Another group showed that printouts of doctored images then photographed successfully tricked an image classification system.[290] One defense is reverse image search, in which a possible fake image is submitted to a site such as TinEye that can then find other instances of it. A refinement is to search using only parts of the image, to identify images from which that piece may have been taken.[291]\\nAnother group showed that certain psychedelic spectacles could fool a facial recognition system into thinking ordinary people were celebrities, potentially allowing one person to impersonate another. In 2017 researchers added stickers to stop signs and caused an ANN to misclassify them.[290]\\nANNs can however be further trained to detect attempts at deception, potentially leading attackers and defenders into an arms race similar to the kind that already defines the malware defense industry. ANNs have been trained to defeat ANN-based anti-malware software by repeatedly attacking a defense with malware that was continually altered by a genetic algorithm until it tricked the anti-malware while retaining its ability to damage the target.[290]\\nIn 2016, another group demonstrated that certain sounds could make the Google Now voice command system open a particular web address, and hypothesized that this could \"serve as a stepping stone for further attacks (e.g., opening a web page hosting drive-by malware)\".[290]\\nIn \"data poisoning\", false data is continually smuggled into a machine learning system\\'s training set to prevent it from achieving mastery.[290]\\n\\nData collection ethics[edit]\\nThe deep learning systems that are trained using supervised learning often rely on data that is created or annotated by humans, or both.[292] It has been argued that not only low-paid clickwork (such as on Amazon Mechanical Turk) is regularly deployed for this purpose, but also implicit forms of human microwork that are often not recognized as such.[293] The philosopher Rainer Mühlhoff distinguishes five types of \"machinic capture\" of human microwork to generate training data: (1) gamification (the embedding of annotation or computation tasks in the flow of a game), (2) \"trapping and tracking\" (e.g. CAPTCHAs for image recognition or click-tracking on Google search results pages), (3) exploitation of social motivations (e.g. tagging faces on Facebook to obtain labeled facial images), (4) information mining (e.g. by leveraging quantified-self devices such as activity trackers) and (5) clickwork.[293]\\n\\nSee also[edit]\\nApplications of artificial intelligence\\nComparison of deep learning software\\nCompressed sensing\\nDifferentiable programming\\nEcho state network\\nList of artificial intelligence projects\\nLiquid state machine\\nList of datasets for machine-learning research\\nReservoir computing\\nScale space and deep learning\\nSparse coding\\nStochastic parrot\\nTopological deep learning\\nReferences[edit]\\n\\n^ Schulz, Hannes; Behnke, Sven (1 November 2012). \"Deep Learning\". KI - Künstliche Intelligenz. 26 (4): 357–363. doi:10.1007/s13218-012-0198-z. ISSN\\xa01610-1987. S2CID\\xa0220523562.\\n\\n^ a b LeCun, Yann; Bengio, Yoshua; Hinton, Geoffrey (2015). \"Deep Learning\" (PDF). Nature. 521 (7553): 436–444. Bibcode:2015Natur.521..436L. doi:10.1038/nature14539. PMID\\xa026017442. S2CID\\xa03074096.\\n\\n^ a b Ciresan, D.; Meier, U.; Schmidhuber, J. (2012). \"Multi-column deep neural networks for image classification\". 2012 IEEE Conference on Computer Vision and Pattern Recognition. pp.\\xa03642–3649. arXiv:1202.2745. doi:10.1109/cvpr.2012.6248110. ISBN\\xa0978-1-4673-1228-8. S2CID\\xa02161592.\\n\\n^ a b Krizhevsky, Alex; Sutskever, Ilya; Hinton, Geoffrey (2012). \"ImageNet Classification with Deep Convolutional Neural Networks\" (PDF). NIPS 2012: Neural Information Processing Systems, Lake Tahoe, Nevada. Archived (PDF) from the original on 2017-01-10. Retrieved 2017-05-24.\\n\\n^ \"Google\\'s AlphaGo AI wins three-match series against the world\\'s best Go player\". TechCrunch. 25 May 2017. Archived from the original on 17 June 2018. Retrieved 17 June 2018.\\n\\n^ \"Study urges caution when comparing neural networks to the brain\". MIT News | Massachusetts Institute of Technology. 2022-11-02. Retrieved 2023-12-06.\\n\\n^ a b c d Bengio, Yoshua (2009). \"Learning Deep Architectures for AI\" (PDF). Foundations and Trends in Machine Learning. 2 (1): 1–127. CiteSeerX\\xa010.1.1.701.9550. doi:10.1561/2200000006. S2CID\\xa0207178999. Archived from the original (PDF) on 4 March 2016. Retrieved 3 September 2015.\\n\\n^ a b c d e Bengio, Y.; Courville, A.; Vincent, P. (2013). \"Representation Learning: A Review and New Perspectives\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 35 (8): 1798–1828. arXiv:1206.5538. Bibcode:2013ITPAM..35.1798B. doi:10.1109/tpami.2013.50. PMID\\xa023787338. S2CID\\xa0393948.\\n\\n^ a b c d e f g h Schmidhuber, J. (2015). \"Deep Learning in Neural Networks: An Overview\". Neural Networks. 61: 85–117. arXiv:1404.7828. Bibcode:2015NN.....61...85S. doi:10.1016/j.neunet.2014.09.003. PMID\\xa025462637. S2CID\\xa011715509.\\n\\n^ Shigeki, Sugiyama (12 April 2019). Human Behavior and Another Kind in Consciousness: Emerging Research and Opportunities: Emerging Research and Opportunities. IGI Global. ISBN\\xa0978-1-5225-8218-2.\\n\\n^ Bengio, Yoshua; Lamblin, Pascal; Popovici, Dan; Larochelle, Hugo (2007). Greedy layer-wise training of deep networks (PDF). Advances in neural information processing systems. pp.\\xa0153–160. Archived (PDF) from the original on 2019-10-20. Retrieved 2019-10-06.\\n\\n^ a b Hinton, G.E. (2009). \"Deep belief networks\". Scholarpedia. 4 (5): 5947. Bibcode:2009SchpJ...4.5947H. doi:10.4249/scholarpedia.5947.\\n\\n^ Rina Dechter (1986). Learning while searching in constraint-satisfaction problems. University of California, Computer Science Department, Cognitive Systems Laboratory.Online Archived 2016-04-19 at the Wayback Machine\\n\\n^ Aizenberg, I.N.; Aizenberg, N.N.; Vandewalle, J. (2000). Multi-Valued and Universal Binary Neurons. Science & Business Media. doi:10.1007/978-1-4757-3115-6. ISBN\\xa0978-0-7923-7824-2. Retrieved 27 December 2023.\\n\\n^ Co-evolving recurrent neurons learn deep memory POMDPs. Proc. GECCO, Washington, D. C., pp. 1795–1802, ACM Press, New York, NY, USA, 2005.\\n\\n^ Fradkov, Alexander L. (2020-01-01). \"Early History of Machine Learning\". IFAC-PapersOnLine. 21st IFAC World Congress. 53 (2): 1385–1390. doi:10.1016/j.ifacol.2020.12.1888. ISSN\\xa02405-8963. S2CID\\xa0235081987.\\n\\n^ a b c Cybenko (1989). \"Approximations by superpositions of sigmoidal functions\" (PDF). Mathematics of Control, Signals, and Systems. 2 (4): 303–314. Bibcode:1989MCSS....2..303C. doi:10.1007/bf02551274. S2CID\\xa03958369. Archived from the original (PDF) on 10 October 2015.\\n\\n^ a b c Hornik, Kurt (1991). \"Approximation Capabilities of Multilayer Feedforward Networks\". Neural Networks. 4 (2): 251–257. Bibcode:1991NN......4..251H. doi:10.1016/0893-6080(91)90009-t. S2CID\\xa07343126.\\n\\n^ a b Haykin, Simon S. (1999). Neural Networks: A Comprehensive Foundation. Prentice Hall. ISBN\\xa0978-0-13-273350-2.\\n\\n^ a b Hassoun, Mohamad H. (1995). Fundamentals of Artificial Neural Networks. MIT Press. p.\\xa048. ISBN\\xa0978-0-262-08239-6.\\n\\n^ a b Lu, Z., Pu, H., Wang, F., Hu, Z., & Wang, L. (2017). The Expressive Power of Neural Networks: A View from the Width Archived 2019-02-13 at the Wayback Machine. Neural Information Processing Systems, 6231-6239.\\n\\n^ Orhan, A. E.; Ma, W. J. (2017). \"Efficient probabilistic inference in generic neural networks trained with non-probabilistic feedback\". Nature Communications. 8 (1): 138. Bibcode:2017NatCo...8..138O. doi:10.1038/s41467-017-00181-8. PMC\\xa05527101. PMID\\xa028743932.\\n\\n^ a b c d e Deng, L.; Yu, D. (2014). \"Deep Learning: Methods and Applications\" (PDF). Foundations and Trends in Signal Processing. 7 (3–4): 1–199. doi:10.1561/2000000039. Archived (PDF) from the original on 2016-03-14. Retrieved 2014-10-18.\\n\\n^ a b c d Murphy, Kevin P. (24 August 2012). Machine Learning: A Probabilistic Perspective. MIT Press. ISBN\\xa0978-0-262-01802-9.\\n\\n^ a b Fukushima, K. (1969). \"Visual feature extraction by a multilayered network of analog threshold elements\". IEEE Transactions on Systems Science and Cybernetics. 5 (4): 322–333. Bibcode:1969ITSSC...5..322F. doi:10.1109/TSSC.1969.300225.\\n\\n^ Sonoda, Sho; Murata, Noboru (2017). \"Neural network with unbounded activation functions is universal approximator\". Applied and Computational Harmonic Analysis. 43 (2): 233–268. arXiv:1505.03654. doi:10.1016/j.acha.2015.12.005. S2CID\\xa012149203.\\n\\n^ Bishop, Christopher M. (2006). Pattern Recognition and Machine Learning (PDF). Springer. ISBN\\xa0978-0-387-31073-2. Archived (PDF) from the original on 2017-01-11. Retrieved 2017-08-06.\\n\\n^ a b \"bibliotheca Augustana\". www.hs-augsburg.de.\\n\\n^ Brush, Stephen G. (1967). \"History of the Lenz-Ising Model\". Reviews of Modern Physics. 39 (4): 883–893. Bibcode:1967RvMP...39..883B. doi:10.1103/RevModPhys.39.883.\\n\\n^ a b Amari, Shun-Ichi (1972). \"Learning patterns and pattern sequences by self-organizing nets of threshold elements\". IEEE Transactions. C (21): 1197–1206.\\n\\n^ a b c d e f g Schmidhuber, Jürgen (2022). \"Annotated History of Modern AI and Deep Learning\". arXiv:2212.11279 [cs.NE].\\n\\n^ Hopfield, J. J. (1982). \"Neural networks and physical systems with emergent collective computational abilities\". Proceedings of the National Academy of Sciences. 79 (8): 2554–2558. Bibcode:1982PNAS...79.2554H. doi:10.1073/pnas.79.8.2554. PMC\\xa0346238. PMID\\xa06953413.\\n\\n^ Nakano, Kaoru (1971). \"Learning Process in a Model of Associative Memory\". Pattern Recognition and Machine Learning. pp.\\xa0172–186. doi:10.1007/978-1-4615-7566-5_15. ISBN\\xa0978-1-4615-7568-9.\\n\\n^ Nakano, Kaoru (1972). \"Associatron-A Model of Associative Memory\". IEEE Transactions on Systems, Man, and Cybernetics. SMC-2 (3): 380–388. Bibcode:1972ITSMC...2..380N. doi:10.1109/TSMC.1972.4309133.\\n\\n^ Turing, Alan (1992) [1948]. \"Intelligent Machinery\". In Ince, D.C. (ed.). Collected Works of AM Turing: Mechanical Intelligence. Vol.\\xa01. Elsevier Science Publishers. p.\\xa0107. ISBN\\xa00-444-88058-5.\\n\\n^ Rosenblatt, F. (1958). \"The perceptron: A probabilistic model for information storage and organization in the brain\". Psychological Review. 65 (6): 386–408. doi:10.1037/h0042519. ISSN\\xa01939-1471. PMID\\xa013602029.\\n\\n^ a b Rosenblatt, Frank (1962). Principles of Neurodynamics. Spartan, New York.\\n\\n^ Joseph, R. D. (1960). Contributions to Perceptron Theory, Cornell Aeronautical Laboratory Report No. VG-11 96--G-7, Buffalo.\\n\\n^ Ivakhnenko, A. G.; Lapa, V. G. (1967). Cybernetics and Forecasting Techniques. American Elsevier Publishing Co. ISBN\\xa0978-0-444-00020-0.\\n\\n^ Ivakhnenko, A.G. (March 1970). \"Heuristic self-organization in problems of engineering cybernetics\". Automatica. 6 (2): 207–219. Bibcode:1970Autom...6..207I. doi:10.1016/0005-1098(70)90092-0.\\n\\n^ a b Ivakhnenko, Alexey (1971). \"Polynomial theory of complex systems\" (PDF). IEEE Transactions on Systems, Man, and Cybernetics. SMC-1 (4): 364–378. Bibcode:1971ITSMC...1..364I. doi:10.1109/TSMC.1971.4308320. Archived (PDF) from the original on 2017-08-29. Retrieved 2019-11-05.\\n\\n^ Robbins, H.; Monro, S. (1951). \"A Stochastic Approximation Method\". The Annals of Mathematical Statistics. 22 (3): 400. doi:10.1214/aoms/1177729586.\\n\\n^ Amari, Shun\\'ichi (1967). \"A theory of adaptive pattern classifier\". IEEE Transactions. EC (16): 279–307.\\n\\n^ Ramachandran, Prajit; Barret, Zoph; Quoc, V. Le (October 16, 2017). \"Searching for Activation Functions\". arXiv:1710.05941 [cs.NE].\\n\\n^ Fukushima, K. (1979). \"Neural network model for a mechanism of pattern recognition unaffected by shift in position—Neocognitron\". Trans. IECE (In Japanese). J62-A (10): 658–665. doi:10.1007/bf00344251. PMID\\xa07370364. S2CID\\xa0206775608.\\n\\n^ Fukushima, K. (1980). \"Neocognitron: A self-organizing neural network model for a mechanism of pattern recognition unaffected by shift in position\". Biol. Cybern. 36 (4): 193–202. doi:10.1007/bf00344251. PMID\\xa07370364. S2CID\\xa0206775608.\\n\\n^ Leibniz, Gottfried Wilhelm Freiherr von (1920). The Early Mathematical Manuscripts of Leibniz: Translated from the Latin Texts Published by Carl Immanuel Gerhardt with Critical and Historical Notes (Leibniz published the chain rule in a 1676 memoir). Open court publishing Company. ISBN\\xa0978-0-598-81846-1. {{cite book}}: ISBN / Date incompatibility (help)\\n\\n^ Kelley, Henry J. (1960). \"Gradient theory of optimal flight paths\". ARS Journal. 30 (10): 947–954. doi:10.2514/8.5282.\\n\\n^ Linnainmaa, Seppo (1970). The representation of the cumulative rounding error of an algorithm as a Taylor expansion of the local rounding errors (Masters) (in Finnish). University of Helsinki. p.\\xa06–7.\\n\\n^ Linnainmaa, Seppo (1976). \"Taylor expansion of the accumulated rounding error\". BIT Numerical Mathematics. 16 (2): 146–160. doi:10.1007/bf01931367. S2CID\\xa0122357351.\\n\\n^ Ostrovski, G.M., Volin,Y.M., and Boris, W.W. (1971). On the computation of derivatives. Wiss. Z. Tech. Hochschule for Chemistry, 13:382–384.\\n\\n^ a b Schmidhuber, Juergen (25 Oct 2014). \"Who Invented Backpropagation?\". IDSIA, Switzerland. Archived from the original on 30 July 2024. Retrieved 14 Sep 2024.\\n\\n^ Werbos, Paul (1982). \"Applications of advances in nonlinear sensitivity analysis\" (PDF). System modeling and optimization. Springer. pp.\\xa0762–770. Archived (PDF) from the original on 14 April 2016. Retrieved 2 July 2017.\\n\\n^ Werbos, Paul J. (1994). The Roots of Backpropagation: From Ordered Derivatives to Neural Networks and Political Forecasting. New York: John Wiley & Sons. ISBN\\xa00-471-59897-6.\\n\\n^ Rumelhart, David E.; Hinton, Geoffrey E.; Williams, Ronald J. (October 1986). \"Learning representations by back-propagating errors\". Nature. 323 (6088): 533–536. Bibcode:1986Natur.323..533R. doi:10.1038/323533a0. ISSN\\xa01476-4687.\\n\\n^ Rumelhart, David E., Geoffrey E. Hinton, and R. J. Williams. \"Learning Internal Representations by Error Propagation Archived 2022-10-13 at the Wayback Machine\". David E. Rumelhart, James L. McClelland, and the PDP research group. (editors), Parallel distributed processing: Explorations in the microstructure of cognition, Volume 1: Foundation. MIT Press, 1986.\\n\\n^ Waibel, Alex (December 1987). Phoneme Recognition Using Time-Delay Neural Networks (PDF). Meeting of the Institute of Electrical, Information and Communication Engineers (IEICE). Tokyo, Japan.\\n\\n^ Alexander Waibel et al., Phoneme Recognition Using Time-Delay Neural Networks IEEE Transactions on Acoustics, Speech, and Signal Processing, Volume 37, No. 3, pp. 328. – 339 March 1989.\\n\\n^ Zhang, Wei (1988). \"Shift-invariant pattern recognition neural network and its optical architecture\". Proceedings of Annual Conference of the Japan Society of Applied Physics.\\n\\n^ LeCun et al., \"Backpropagation Applied to Handwritten Zip Code Recognition\", Neural Computation, 1, pp. 541–551, 1989.\\n\\n^ Zhang, Wei (1990). \"Parallel distributed processing model with local space-invariant interconnections and its optical architecture\". Applied Optics. 29 (32): 4790–7. Bibcode:1990ApOpt..29.4790Z. doi:10.1364/AO.29.004790. PMID\\xa020577468.\\n\\n^ Zhang, Wei (1991). \"Image processing of human corneal endothelium based on a learning network\". Applied Optics. 30 (29): 4211–7. Bibcode:1991ApOpt..30.4211Z. doi:10.1364/AO.30.004211. PMID\\xa020706526.\\n\\n^ Zhang, Wei (1994). \"Computerized detection of clustered microcalcifications in digital mammograms using a shift-invariant artificial neural network\". Medical Physics. 21 (4): 517–24. Bibcode:1994MedPh..21..517Z. doi:10.1118/1.597177. PMID\\xa08058017.\\n\\n^ LeCun, Yann; Léon Bottou; Yoshua Bengio; Patrick Haffner (1998). \"Gradient-based learning applied to document recognition\" (PDF). Proceedings of the IEEE. 86 (11): 2278–2324. Bibcode:1998IEEEP..86.2278L. CiteSeerX\\xa010.1.1.32.9552. doi:10.1109/5.726791. S2CID\\xa014542261. Retrieved October 7, 2016.\\n\\n^ Jordan, Michael I. (1986). \"Attractor dynamics and parallelism in a connectionist sequential machine\". Proceedings of the Annual Meeting of the Cognitive Science Society. 8.\\n\\n^ Elman, Jeffrey L. (March 1990). \"Finding Structure in Time\". Cognitive Science. 14 (2): 179–211. doi:10.1207/s15516709cog1402_1. ISSN\\xa00364-0213.\\n\\n^ a b c Schmidhuber, Jürgen (April 1991). \"Neural Sequence Chunkers\" (PDF). TR FKI-148, TU Munich.\\n\\n^ a b Schmidhuber, Jürgen (1992). \"Learning complex, extended sequences using the principle of history compression (based on TR FKI-148, 1991)\" (PDF). Neural Computation. 4 (2): 234–242. doi:10.1162/neco.1992.4.2.234. S2CID\\xa018271205.\\n\\n^ Schmidhuber, Jürgen (1993). Habilitation thesis: System modeling and optimization (PDF). Archived from the original (PDF) on May 16, 2022. Page 150 ff demonstrates credit assignment across the equivalent of 1,200 layers in an unfolded RNN.\\n\\n^ a b c S. Hochreiter., \"Untersuchungen zu dynamischen neuronalen Netzen\". Archived 2015-03-06 at the Wayback Machine. Diploma thesis. Institut f. Informatik, Technische Univ. Munich. Advisor: J. Schmidhuber, 1991.\\n\\n^ Hochreiter, S.; et\\xa0al. (15 January 2001). \"Gradient flow in recurrent nets: the difficulty of learning long-term dependencies\". In Kolen, John F.; Kremer, Stefan C. (eds.). A Field Guide to Dynamical Recurrent Networks. John Wiley & Sons. ISBN\\xa0978-0-7803-5369-5.\\n\\n^ Sepp Hochreiter; Jürgen Schmidhuber (21 August 1995), Long Short Term Memory, Wikidata\\xa0Q98967430\\n\\n^ Gers, Felix; Schmidhuber, Jürgen; Cummins, Fred (1999). \"Learning to forget: Continual prediction with LSTM\". 9th International Conference on Artificial Neural Networks: ICANN \\'99. Vol.\\xa01999. pp.\\xa0850–855. doi:10.1049/cp:19991218. ISBN\\xa00-85296-721-7.\\n\\n^ a b Schmidhuber, Jürgen (1991). \"A possibility for implementing curiosity and boredom in model-building neural controllers\". Proc. SAB\\'1991. MIT Press/Bradford Books. pp.\\xa0222–227.\\n\\n^ Schmidhuber, Jürgen (2010). \"Formal Theory of Creativity, Fun, and Intrinsic Motivation (1990-2010)\". IEEE Transactions on Autonomous Mental Development. 2 (3): 230–247. Bibcode:2010ITAMD...2..230S. doi:10.1109/TAMD.2010.2056368. S2CID\\xa0234198.\\n\\n^ a b Schmidhuber, Jürgen (2020). \"Generative Adversarial Networks are Special Cases of Artificial Curiosity (1990) and also Closely Related to Predictability Minimization (1991)\". Neural Networks. 127: 58–66. arXiv:1906.04493. doi:10.1016/j.neunet.2020.04.008. PMID\\xa032334341. S2CID\\xa0216056336.\\n\\n^ Ackley, David H.; Hinton, Geoffrey E.; Sejnowski, Terrence J. (1985-01-01). \"A learning algorithm for boltzmann machines\". Cognitive Science. 9 (1): 147–169. doi:10.1016/S0364-0213(85)80012-4. ISSN\\xa00364-0213.\\n\\n^ Smolensky, Paul (1986). \"Chapter 6: Information Processing in Dynamical Systems: Foundations of Harmony Theory\" (PDF). In Rumelhart, David E.; McLelland, James L. (eds.). Parallel Distributed Processing: Explorations in the Microstructure of Cognition, Volume 1: Foundations. MIT Press. pp.\\xa0194–281. ISBN\\xa00-262-68053-X.\\n\\n^ Peter, Dayan; Hinton, Geoffrey E.; Neal, Radford M.; Zemel, Richard S. (1995). \"The Helmholtz machine\". Neural Computation. 7 (5): 889–904. doi:10.1162/neco.1995.7.5.889. hdl:21.11116/0000-0002-D6D3-E. PMID\\xa07584891. S2CID\\xa01890561. \\n\\n^ Hinton, Geoffrey E.; Dayan, Peter; Frey, Brendan J.; Neal, Radford (1995-05-26). \"The wake-sleep algorithm for unsupervised neural networks\". Science. 268 (5214): 1158–1161. Bibcode:1995Sci...268.1158H. doi:10.1126/science.7761831. PMID\\xa07761831. S2CID\\xa0871473.\\n\\n^ Sejnowski, Terrence J. (2018). The Deep Learning Revolution. Cambridge, Massachusetts: The MIT Press. ISBN\\xa0978-0-262-03803-4.\\n\\n^ Qian, Ning; Sejnowski, Terrence J. (1988-08-20). \"Predicting the secondary structure of globular proteins using neural network models\". Journal of Molecular Biology. 202 (4): 865–884. Bibcode:1988JMBio.202..865Q. doi:10.1016/0022-2836(88)90564-5. ISSN\\xa00022-2836. PMID\\xa03172241.\\n\\n^ Morgan, Nelson; Bourlard, Hervé; Renals, Steve; Cohen, Michael; Franco, Horacio (1 August 1993). \"Hybrid neural network/hidden markov model systems for continuous speech recognition\". International Journal of Pattern Recognition and Artificial Intelligence. 07 (4): 899–916. doi:10.1142/s0218001493000455. ISSN\\xa00218-0014.\\n\\n^ Robinson, T. (1992). \"A real-time recurrent error propagation network word recognition system\". ICASSP. Icassp\\'92: 617–620. ISBN\\xa0978-0-7803-0532-8. Archived from the original on 2021-05-09. Retrieved 2017-06-12.\\n\\n^ Waibel, A.; Hanazawa, T.; Hinton, G.; Shikano, K.; Lang, K. J. (March 1989). \"Phoneme recognition using time-delay neural networks\" (PDF). IEEE Transactions on Acoustics, Speech, and Signal Processing. 37 (3): 328–339. Bibcode:1989ITASS..37..328W. doi:10.1109/29.21701. hdl:10338.dmlcz/135496. ISSN\\xa00096-3518. S2CID\\xa09563026. Archived (PDF) from the original on 2021-04-27. Retrieved 2019-09-24.\\n\\n^ Baker, J.; Deng, Li; Glass, Jim; Khudanpur, S.; Lee, C.-H.; Morgan, N.; O\\'Shaughnessy, D. (2009). \"Research Developments and Directions in Speech Recognition and Understanding, Part 1\". IEEE Signal Processing Magazine. 26 (3): 75–80. Bibcode:2009ISPM...26...75B. doi:10.1109/msp.2009.932166. hdl:1721.1/51891. S2CID\\xa0357467.\\n\\n^ Bengio, Y. (1991). \"Artificial Neural Networks and their Application to Speech/Sequence Recognition\". McGill University Ph.D. thesis. Archived from the original on 2021-05-09. Retrieved 2017-06-12.\\n\\n^ Deng, L.; Hassanein, K.; Elmasry, M. (1994). \"Analysis of correlation structure for a neural predictive model with applications to speech recognition\". Neural Networks. 7 (2): 331–339. doi:10.1016/0893-6080(94)90027-2.\\n\\n^ Doddington, G.; Przybocki, M.; Martin, A.; Reynolds, D. (2000). \"The NIST speaker recognition evaluation ± Overview, methodology, systems, results, perspective\". Speech Communication. 31 (2): 225–254. doi:10.1016/S0167-6393(99)00080-1.\\n\\n^ a b Heck, L.; Konig, Y.; Sonmez, M.; Weintraub, M. (2000). \"Robustness to Telephone Handset Distortion in Speaker Recognition by Discriminative Feature Design\". Speech Communication. 31 (2): 181–192. doi:10.1016/s0167-6393(99)00077-1.\\n\\n^ L.P Heck and R. Teunen. \"Secure and Convenient Transactions with Nuance Verifier\". Nuance Users Conference, April 1998.\\n\\n^ \"Acoustic Modeling with Deep Neural Networks Using Raw Time Signal for LVCSR (PDF Download Available)\". ResearchGate. Archived from the original on 9 May 2021. Retrieved 14 June 2017.\\n\\n^ a b Graves, Alex; Eck, Douglas; Beringer, Nicole; Schmidhuber, Jürgen (2003). \"Biologically Plausible Speech Recognition with LSTM Neural Nets\" (PDF). 1st Intl. Workshop on Biologically Inspired Approaches to Advanced Information Technology, Bio-ADIT 2004, Lausanne, Switzerland. pp.\\xa0175–184. Archived from the original (PDF) on 2017-07-06. Retrieved 2016-04-09.\\n\\n^ Graves, Alex; Fernández, Santiago; Gomez, Faustino; Schmidhuber, Jürgen (2006). \"Connectionist temporal classification: Labelling unsegmented sequence data with recurrent neural networks\". Proceedings of the International Conference on Machine Learning, ICML 2006: 369–376. CiteSeerX\\xa010.1.1.75.6306.\\n\\n^ Santiago Fernandez, Alex Graves, and Jürgen Schmidhuber (2007). An application of recurrent neural networks to discriminative keyword spotting Archived 2018-11-18 at the Wayback Machine. Proceedings of ICANN (2), pp. 220–229.\\n\\n^ Graves, Alex; and Schmidhuber, Jürgen; Offline Handwriting Recognition with Multidimensional Recurrent Neural Networks, in Bengio, Yoshua; Schuurmans, Dale; Lafferty, John; Williams, Chris K. I.; and Culotta, Aron (eds.), Advances in Neural Information Processing Systems 22 (NIPS\\'22), December 7th–10th, 2009, Vancouver, BC, Neural Information Processing Systems (NIPS) Foundation, 2009, pp. 545–552\\n\\n^ Hinton, Geoffrey E. (1 October 2007). \"Learning multiple layers of representation\". Trends in Cognitive Sciences. 11 (10): 428–434. doi:10.1016/j.tics.2007.09.004. ISSN\\xa01364-6613. PMID\\xa017921042. S2CID\\xa015066318. Archived from the original on 11 October 2013. Retrieved 12 June 2017.\\n\\n^ Hinton, G. E.; Osindero, S.; Teh, Y. W. (2006). \"A Fast Learning Algorithm for Deep Belief Nets\" (PDF). Neural Computation. 18 (7): 1527–1554. doi:10.1162/neco.2006.18.7.1527. PMID\\xa016764513. S2CID\\xa02309950. Archived (PDF) from the original on 2015-12-23. Retrieved 2011-07-20.\\n\\n^ G. E. Hinton., \"Learning multiple layers of representation\". Archived 2018-05-22 at the Wayback Machine. Trends in Cognitive Sciences, 11, pp. 428–434, 2007.\\n\\n^ Hinton, Geoffrey E. (October 2007). \"Learning multiple layers of representation\". Trends in Cognitive Sciences. 11 (10): 428–434. doi:10.1016/j.tics.2007.09.004. PMID\\xa017921042.\\n\\n^ Hinton, Geoffrey E.; Osindero, Simon; Teh, Yee-Whye (July 2006). \"A Fast Learning Algorithm for Deep Belief Nets\". Neural Computation. 18 (7): 1527–1554. doi:10.1162/neco.2006.18.7.1527. ISSN\\xa00899-7667. PMID\\xa016764513.\\n\\n^ Hinton, Geoffrey E. (2009-05-31). \"Deep belief networks\". Scholarpedia. 4 (5): 5947. Bibcode:2009SchpJ...4.5947H. doi:10.4249/scholarpedia.5947. ISSN\\xa01941-6016.\\n\\n^ Yann LeCun (2016). Slides on Deep Learning Online Archived 2016-04-23 at the Wayback Machine\\n\\n^ a b c Hinton, G.; Deng, L.; Yu, D.; Dahl, G.; Mohamed, A.; Jaitly, N.; Senior, A.; Vanhoucke, V.; Nguyen, P.; Sainath, T.; Kingsbury, B. (2012). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups\". IEEE Signal Processing Magazine. 29 (6): 82–97. Bibcode:2012ISPM...29...82H. doi:10.1109/msp.2012.2205597. S2CID\\xa0206485943.\\n\\n^ a b c Deng, L.; Hinton, G.; Kingsbury, B. (May 2013). \"New types of deep neural network learning for speech recognition and related applications: An overview (ICASSP)\" (PDF). Microsoft. Archived (PDF) from the original on 2017-09-26. Retrieved 27 December 2023.\\n\\n^ a b c Yu, D.; Deng, L. (2014). Automatic Speech Recognition: A Deep Learning Approach (Publisher: Springer). Springer. ISBN\\xa0978-1-4471-5779-3.\\n\\n^ \"Deng receives prestigious IEEE Technical Achievement Award - Microsoft Research\". Microsoft Research. 3 December 2015. Archived from the original on 16 March 2018. Retrieved 16 March 2018.\\n\\n^ a b Li, Deng (September 2014). \"Keynote talk: \\'Achievements and Challenges of Deep Learning - From Speech Analysis and Recognition To Language and Multimodal Processing\\'\". Interspeech. Archived from the original on 2017-09-26. Retrieved 2017-06-12.\\n\\n^ Yu, D.; Deng, L. (2010). \"Roles of Pre-Training and Fine-Tuning in Context-Dependent DBN-HMMs for Real-World Speech Recognition\". NIPS Workshop on Deep Learning and Unsupervised Feature Learning. Archived from the original on 2017-10-12. Retrieved 2017-06-14.\\n\\n^ Seide, F.; Li, G.; Yu, D. (2011). \"Conversational speech transcription using context-dependent deep neural networks\". Interspeech 2011. pp.\\xa0437–440. doi:10.21437/Interspeech.2011-169. S2CID\\xa0398770. Archived from the original on 2017-10-12. Retrieved 2017-06-14.\\n\\n^ Deng, Li; Li, Jinyu; Huang, Jui-Ting; Yao, Kaisheng; Yu, Dong; Seide, Frank; Seltzer, Mike; Zweig, Geoff; He, Xiaodong (1 May 2013). \"Recent Advances in Deep Learning for Speech Research at Microsoft\". Microsoft Research. Archived from the original on 12 October 2017. Retrieved 14 June 2017.\\n\\n^ a b Oh, K.-S.; Jung, K. (2004). \"GPU implementation of neural networks\". Pattern Recognition. 37 (6): 1311–1314. Bibcode:2004PatRe..37.1311O. doi:10.1016/j.patcog.2004.01.013.\\n\\n^ a b Chellapilla, Kumar; Puri, Sidd; Simard, Patrice (2006), High performance convolutional neural networks for document processing, archived from the original on 2020-05-18, retrieved 2021-02-14\\n\\n^ Sze, Vivienne; Chen, Yu-Hsin; Yang, Tien-Ju; Emer, Joel (2017). \"Efficient Processing of Deep Neural Networks: A Tutorial and Survey\". arXiv:1703.09039 [cs.CV].\\n\\n^ Raina, Rajat; Madhavan, Anand; Ng, Andrew Y. (2009-06-14). \"Large-scale deep unsupervised learning using graphics processors\". Proceedings of the 26th Annual International Conference on Machine Learning. ICML \\'09. New York, NY, USA: Association for Computing Machinery. pp.\\xa0873–880. doi:10.1145/1553374.1553486. ISBN\\xa0978-1-60558-516-1.\\n\\n^ Cireşan, Dan Claudiu; Meier, Ueli; Gambardella, Luca Maria; Schmidhuber, Jürgen (21 September 2010). \"Deep, Big, Simple Neural Nets for Handwritten Digit Recognition\". Neural Computation. 22 (12): 3207–3220. arXiv:1003.0358. Bibcode:2010NeCom..22.3207C. doi:10.1162/neco_a_00052. ISSN\\xa00899-7667. PMID\\xa020858131. S2CID\\xa01918673.\\n\\n^ Ciresan, D. C.; Meier, U.; Masci, J.; Gambardella, L.M.; Schmidhuber, J. (2011). \"Flexible, High Performance Convolutional Neural Networks for Image Classification\" (PDF). International Joint Conference on Artificial Intelligence. doi:10.5591/978-1-57735-516-8/ijcai11-210. Archived (PDF) from the original on 2014-09-29. Retrieved 2017-06-13.\\n\\n^ Ciresan, Dan; Giusti, Alessandro; Gambardella, Luca M.; Schmidhuber, Jürgen (2012). Pereira, F.; Burges, C. J. C.; Bottou, L.; Weinberger, K. Q. (eds.). Advances in Neural Information Processing Systems 25 (PDF). Curran Associates, Inc. pp.\\xa02843–2851. Archived (PDF) from the original on 2017-08-09. Retrieved 2017-06-13.\\n\\n^ Ciresan, D.; Giusti, A.; Gambardella, L.M.; Schmidhuber, J. (2013). \"Mitosis Detection in Breast Cancer Histology Images with Deep Neural Networks\". Medical Image Computing and Computer-Assisted Intervention – MICCAI 2013. Lecture Notes in Computer Science. Vol.\\xa07908. pp.\\xa0411–418. doi:10.1007/978-3-642-40763-5_51. ISBN\\xa0978-3-642-38708-1. PMID\\xa024579167.\\n\\n^ Ng, Andrew; Dean, Jeff (2012). \"Building High-level Features Using Large Scale Unsupervised Learning\". arXiv:1112.6209 [cs.LG].\\n\\n^ Simonyan, Karen; Andrew, Zisserman (2014). \"Very Deep Convolution Networks for Large Scale Image Recognition\". arXiv:1409.1556 [cs.CV].\\n\\n^ Szegedy, Christian (2015). \"Going deeper with convolutions\" (PDF). Cvpr2015. arXiv:1409.4842.\\n\\n^ Vinyals, Oriol; Toshev, Alexander; Bengio, Samy; Erhan, Dumitru (2014). \"Show and Tell: A Neural Image Caption Generator\". arXiv:1411.4555 [cs.CV]..\\n\\n^ Fang, Hao; Gupta, Saurabh; Iandola, Forrest; Srivastava, Rupesh; Deng, Li; Dollár, Piotr; Gao, Jianfeng; He, Xiaodong; Mitchell, Margaret; Platt, John C; Lawrence Zitnick, C; Zweig, Geoffrey (2014). \"From Captions to Visual Concepts and Back\". arXiv:1411.4952 [cs.CV]..\\n\\n^ Kiros, Ryan; Salakhutdinov, Ruslan; Zemel, Richard S (2014). \"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\". arXiv:1411.2539 [cs.LG]..\\n\\n^ Simonyan, Karen; Zisserman, Andrew (2015-04-10), Very Deep Convolutional Networks for Large-Scale Image Recognition, arXiv:1409.1556\\n\\n^ He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (2016). \"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\". arXiv:1502.01852 [cs.CV].\\n\\n^ He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (10 Dec 2015). Deep Residual Learning for Image Recognition. arXiv:1512.03385.\\n\\n^ He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (2016). \"Deep Residual Learning for Image Recognition\". 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Las Vegas, NV, USA: IEEE. pp.\\xa0770–778. arXiv:1512.03385. doi:10.1109/CVPR.2016.90. ISBN\\xa0978-1-4673-8851-1.\\n\\n^ Gatys, Leon A.; Ecker, Alexander S.; Bethge, Matthias (26 August 2015). \"A Neural Algorithm of Artistic Style\". arXiv:1508.06576 [cs.CV].\\n\\n^ Goodfellow, Ian; Pouget-Abadie, Jean; Mirza, Mehdi; Xu, Bing; Warde-Farley, David; Ozair, Sherjil; Courville, Aaron; Bengio, Yoshua (2014). Generative Adversarial Networks (PDF). Proceedings of the International Conference on Neural Information Processing Systems (NIPS 2014). pp.\\xa02672–2680. Archived (PDF) from the original on 22 November 2019. Retrieved 20 August 2019.\\n\\n^ \"GAN 2.0: NVIDIA\\'s Hyperrealistic Face Generator\". SyncedReview.com. December 14, 2018. Retrieved October 3, 2019.\\n\\n^ Karras, T.; Aila, T.; Laine, S.; Lehtinen, J. (26 February 2018). \"Progressive Growing of GANs for Improved Quality, Stability, and Variation\". arXiv:1710.10196 [cs.NE].\\n\\n^ \"Prepare, Don\\'t Panic: Synthetic Media and Deepfakes\". witness.org. Archived from the original on 2 December 2020. Retrieved 25 November 2020.\\n\\n^ Sohl-Dickstein, Jascha; Weiss, Eric; Maheswaranathan, Niru; Ganguli, Surya (2015-06-01). \"Deep Unsupervised Learning using Nonequilibrium Thermodynamics\" (PDF). Proceedings of the 32nd International Conference on Machine Learning. 37. PMLR: 2256–2265. arXiv:1503.03585.\\n\\n^ Google Research Blog. The neural networks behind Google Voice transcription. August 11, 2015. By Françoise Beaufays http://googleresearch.blogspot.co.at/2015/08/the-neural-networks-behind-google-voice.html\\n\\n^ a b Sak, Haşim; Senior, Andrew; Rao, Kanishka; Beaufays, Françoise; Schalkwyk, Johan (September 2015). \"Google voice search: faster and more accurate\". Archived from the original on 2016-03-09. Retrieved 2016-04-09.\\n\\n^ Singh, Premjeet; Saha, Goutam; Sahidullah, Md (2021). \"Non-linear frequency warping using constant-Q transformation for speech emotion recognition\". 2021 International Conference on Computer Communication and Informatics (ICCCI). pp.\\xa01–4. arXiv:2102.04029. doi:10.1109/ICCCI50826.2021.9402569. ISBN\\xa0978-1-7281-5875-4. S2CID\\xa0231846518.\\n\\n^ Sak, Hasim; Senior, Andrew; Beaufays, Francoise (2014). \"Long Short-Term Memory recurrent neural network architectures for large scale acoustic modeling\" (PDF). Archived from the original (PDF) on 24 April 2018.\\n\\n^ Li, Xiangang; Wu, Xihong (2014). \"Constructing Long Short-Term Memory based Deep Recurrent Neural Networks for Large Vocabulary Speech Recognition\". arXiv:1410.4281 [cs.CL].\\n\\n^ Zen, Heiga; Sak, Hasim (2015). \"Unidirectional Long Short-Term Memory Recurrent Neural Network with Recurrent Output Layer for Low-Latency Speech Synthesis\" (PDF). Google.com. ICASSP. pp.\\xa04470–4474. Archived (PDF) from the original on 2021-05-09. Retrieved 2017-06-13.\\n\\n^ \"2018 ACM A.M. Turing Award Laureates\". awards.acm.org. Retrieved 2024-08-07.\\n\\n^ Ferrie, C., & Kaiser, S. (2019). Neural Networks for Babies. Sourcebooks. ISBN\\xa0978-1-4926-7120-6.{{cite book}}:  CS1 maint: multiple names: authors list (link)\\n\\n^ Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda (January 2016). \"Mastering the game of Go with deep neural networks and tree search\". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. ISSN\\xa01476-4687. PMID\\xa026819042. S2CID\\xa0515925.\\n\\n^ A Guide to Deep Learning and Neural Networks, archived from the original on 2020-11-02, retrieved 2020-11-16\\n\\n^ a b Kumar, Nishant; Raubal, Martin (2021). \"Applications of deep learning in congestion detection, prediction and alleviation: A survey\". Transportation Research Part C: Emerging Technologies. 133 103432. arXiv:2102.09759. Bibcode:2021TRPC..13303432K. doi:10.1016/j.trc.2021.103432. hdl:10230/42143. S2CID\\xa0240420107.\\n\\n^ Szegedy, Christian; Toshev, Alexander; Erhan, Dumitru (2013). \"Deep neural networks for object detection\". Advances in Neural Information Processing Systems: 2553–2561. Archived from the original on 2017-06-29. Retrieved 2017-06-13.\\n\\n^ Rolnick, David; Tegmark, Max (2018). \"The power of deeper networks for expressing natural functions\". International Conference on Learning Representations. ICLR 2018. Archived from the original on 2021-01-07. Retrieved 2021-01-05.\\n\\n^ Hof, Robert D. \"Is Artificial Intelligence Finally Coming into Its Own?\". MIT Technology Review. Archived from the original on 31 March 2019. Retrieved 10 July 2018.\\n\\n^ a b Gers, Felix A.; Schmidhuber, Jürgen (2001). \"LSTM Recurrent Networks Learn Simple Context Free and Context Sensitive Languages\". IEEE Transactions on Neural Networks. 12 (6): 1333–1340. Bibcode:2001ITNN...12.1333G. doi:10.1109/72.963769. PMID\\xa018249962. S2CID\\xa010192330. Archived from the original on 2020-01-26. Retrieved 2020-02-25.\\n\\n^ a b c Sutskever, L.; Vinyals, O.; Le, Q. (2014). \"Sequence to Sequence Learning with Neural Networks\" (PDF). Proc. NIPS. arXiv:1409.3215. Bibcode:2014arXiv1409.3215S. Archived (PDF) from the original on 2021-05-09. Retrieved 2017-06-13.\\n\\n^ a b Jozefowicz, Rafal; Vinyals, Oriol; Schuster, Mike; Shazeer, Noam; Wu, Yonghui (2016). \"Exploring the Limits of Language Modeling\". arXiv:1602.02410 [cs.CL].\\n\\n^ a b Gillick, Dan; Brunk, Cliff; Vinyals, Oriol; Subramanya, Amarnag (2015). \"Multilingual Language Processing from Bytes\". arXiv:1512.00103 [cs.CL].\\n\\n^ Mikolov, T.; et\\xa0al. (2010). \"Recurrent neural network based language model\" (PDF). Interspeech: 1045–1048. doi:10.21437/Interspeech.2010-343. S2CID\\xa017048224. Archived (PDF) from the original on 2017-05-16. Retrieved 2017-06-13.\\n\\n^ Hochreiter, Sepp; Schmidhuber, Jürgen (1 November 1997). \"Long Short-Term Memory\". Neural Computation. 9 (8): 1735–1780. doi:10.1162/neco.1997.9.8.1735. ISSN\\xa00899-7667. PMID\\xa09377276. S2CID\\xa01915014.\\n\\n^ a b \"Learning Precise Timing with LSTM Recurrent Networks (PDF Download Available)\". ResearchGate. Archived from the original on 9 May 2021. Retrieved 13 June 2017.\\n\\n^ LeCun, Y.; et\\xa0al. (1998). \"Gradient-based learning applied to document recognition\". Proceedings of the IEEE. 86 (11): 2278–2324. Bibcode:1998IEEEP..86.2278L. doi:10.1109/5.726791. S2CID\\xa014542261.\\n\\n^ Sainath, Tara N.; Mohamed, Abdel-Rahman; Kingsbury, Brian; Ramabhadran, Bhuvana (2013). \"Deep convolutional neural networks for LVCSR\". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. pp.\\xa08614–8618. doi:10.1109/icassp.2013.6639347. ISBN\\xa0978-1-4799-0356-6. S2CID\\xa013816461.\\n\\n^ Bengio, Yoshua; Boulanger-Lewandowski, Nicolas; Pascanu, Razvan (2013). \"Advances in optimizing recurrent networks\". 2013 IEEE International Conference on Acoustics, Speech and Signal Processing. pp.\\xa08624–8628. arXiv:1212.0901. CiteSeerX\\xa010.1.1.752.9151. doi:10.1109/icassp.2013.6639349. ISBN\\xa0978-1-4799-0356-6. S2CID\\xa012485056.\\n\\n^ Dahl, G.; et\\xa0al. (2013). \"Improving DNNs for LVCSR using rectified linear units and dropout\" (PDF). ICASSP. Archived (PDF) from the original on 2017-08-12. Retrieved 2017-06-13.\\n\\n^ Kumar, Nishant; Martin, Henry; Raubal, Martin (2024). \"Enhancing Deep Learning-Based City-Wide Traffic Prediction Pipelines Through Complexity Analysis\". Data Science for Transportation. 6 (3) 24. doi:10.1007/s42421-024-00109-x. hdl:20.500.11850/695425.\\n\\n^ \"Data Augmentation - deeplearning.ai | Coursera\". Coursera. Archived from the original on 1 December 2017. Retrieved 30 November 2017.\\n\\n^ Hinton, G. E. (2010). \"A Practical Guide to Training Restricted Boltzmann Machines\". Tech. Rep. UTML TR 2010-003. Archived from the original on 2021-05-09. Retrieved 2017-06-13.\\n\\n^ You, Yang; Buluç, Aydın; Demmel, James (November 2017). \"Scaling deep learning on GPU and knights landing clusters\". Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis on - SC \\'17. SC \\'17, ACM. pp.\\xa01–12. arXiv:1708.02983. doi:10.1145/3126908.3126912. ISBN\\xa0978-1-4503-5114-0. S2CID\\xa08869270. Archived from the original on 29 July 2020. Retrieved 5 March 2018.\\n\\n^ Viebke, André; Memeti, Suejb; Pllana, Sabri; Abraham, Ajith (2019). \"CHAOS: a parallelization scheme for training convolutional neural networks on Intel Xeon Phi\". The Journal of Supercomputing. 75: 197–227. arXiv:1702.07908. Bibcode:2017arXiv170207908V. doi:10.1007/s11227-017-1994-x. S2CID\\xa014135321.\\n\\n^ Ting Qin, et al. \"A learning algorithm of CMAC based on RLS\". Neural Processing Letters 19.1 (2004): 49-61.\\n\\n^ Ting Qin, et al. \"Continuous CMAC-QRLS and its systolic array\". Archived 2018-11-18 at the Wayback Machine. Neural Processing Letters 22.1 (2005): 1-16.\\n\\n^ Research, AI (23 October 2015). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition\". airesearch.com. Archived from the original on 1 February 2016. Retrieved 23 October 2015.\\n\\n^ \"GPUs Continue to Dominate the AI Accelerator Market for Now\". InformationWeek. December 2019. Archived from the original on 10 June 2020. Retrieved 11 June 2020.\\n\\n^ Ray, Tiernan (2019). \"AI is changing the entire nature of computation\". ZDNet. Archived from the original on 25 May 2020. Retrieved 11 June 2020.\\n\\n^ \"AI and Compute\". OpenAI. 16 May 2018. Archived from the original on 17 June 2020. Retrieved 11 June 2020.\\n\\n^ \"HUAWEI Reveals the Future of Mobile AI at IFA 2017 | HUAWEI Latest News | HUAWEI Global\". consumer.huawei.com.\\n\\n^ P, JouppiNorman; YoungCliff; PatilNishant; PattersonDavid; AgrawalGaurav; BajwaRaminder; BatesSarah; BhatiaSuresh; BodenNan; BorchersAl; BoyleRick (2017-06-24). \"In-Datacenter Performance Analysis of a Tensor Processing Unit\". ACM SIGARCH Computer Architecture News. 45 (2): 1–12. arXiv:1704.04760. doi:10.1145/3140659.3080246.\\n\\n^ Woodie, Alex (2021-11-01). \"Cerebras Hits the Accelerator for Deep Learning Workloads\". Datanami. Retrieved 2022-08-03.\\n\\n^ \"Cerebras launches new AI supercomputing processor with 2.6 trillion transistors\". VentureBeat. 2021-04-20. Retrieved 2022-08-03.\\n\\n^ Marega, Guilherme Migliato; Zhao, Yanfei; Avsar, Ahmet; Wang, Zhenyu; Tripati, Mukesh; Radenovic, Aleksandra; Kis, Anras (2020). \"Logic-in-memory based on an atomically thin semiconductor\". Nature. 587 (2): 72–77. Bibcode:2020Natur.587...72M. doi:10.1038/s41586-020-2861-0. PMC\\xa07116757. PMID\\xa033149289.\\n\\n^ a b c Feldmann, J.; Youngblood, N.; Karpov, M.; et\\xa0al. (2021). \"Parallel convolutional processing using an integrated photonic tensor\". Nature. 589 (2): 52–58. arXiv:2002.00281. doi:10.1038/s41586-020-03070-1. PMID\\xa033408373. S2CID\\xa0211010976.\\n\\n^ Garofolo, J.S.; Lamel, L.F.; Fisher, W.M.; Fiscus, J.G.; Pallett, D.S.; Dahlgren, N.L.; Zue, V. (1993). TIMIT Acoustic-Phonetic Continuous Speech Corpus. Linguistic Data Consortium. doi:10.35111/17gk-bn40. ISBN\\xa01-58563-019-5. Retrieved 27 December 2023.\\n\\n^ Robinson, Tony (30 September 1991). \"Several Improvements to a Recurrent Error Propagation Network Phone Recognition System\". Cambridge University Engineering Department Technical Report. CUED/F-INFENG/TR82. doi:10.13140/RG.2.2.15418.90567.\\n\\n^ Abdel-Hamid, O.; et\\xa0al. (2014). \"Convolutional Neural Networks for Speech Recognition\". IEEE/ACM Transactions on Audio, Speech, and Language Processing. 22 (10): 1533–1545. Bibcode:2014ITASL..22.1533A. doi:10.1109/taslp.2014.2339736. S2CID\\xa0206602362. Archived from the original on 2020-09-22. Retrieved 2018-04-20.\\n\\n^ Deng, L.; Platt, J. (2014). \"Ensemble Deep Learning for Speech Recognition\". Proc. Interspeech: 1915–1919. doi:10.21437/Interspeech.2014-433. S2CID\\xa015641618.\\n\\n^ Tóth, Laszló (2015). \"Phone Recognition with Hierarchical Convolutional Deep Maxout Networks\" (PDF). EURASIP Journal on Audio, Speech, and Music Processing. 2015 25. doi:10.1186/s13636-015-0068-3. S2CID\\xa0217950236. Archived (PDF) from the original on 2020-09-24. Retrieved 2019-04-01.\\n\\n^ Aaron van den Oord; Dieleman, Sander; Zen, Heiga; Simonyan, Karen; Vinyals, Oriol; Graves, Alex; Kalchbrenner, Nal; Senior, Andrew; Kavukcuoglu, Koray (2016). \"WaveNet: A Generative Model for Raw Audio\". arXiv:1609.03499 [cs.SD].\\n\\n^ \"WaveNet: A generative model for raw audio\". Google DeepMind. 2016-09-08. Retrieved 2025-07-31.\\n\\n^ Latif, Siddique; Zaidi, Aun; Cuayahuitl, Heriberto; Shamshad, Fahad; Shoukat, Moazzam; Usama, Muhammad; Qadir, Junaid (2023). \"Transformers in Speech Processing: A Survey\". arXiv:2303.11607 [cs.CL].\\n\\n^ McMillan, Robert (17 December 2014). \"How Skype Used AI to Build Its Amazing New Language Translator | WIRED\". Wired. Archived from the original on 8 June 2017. Retrieved 14 June 2017.\\n\\n^ Hannun, Awni; Case, Carl; Casper, Jared; Catanzaro, Bryan; Diamos, Greg; Elsen, Erich; Prenger, Ryan; Satheesh, Sanjeev; Sengupta, Shubho; Coates, Adam; Ng, Andrew Y (2014). \"Deep Speech: Scaling up end-to-end speech recognition\". arXiv:1412.5567 [cs.CL].\\n\\n^ \"MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges\". yann.lecun.com. Archived from the original on 2014-01-13. Retrieved 2014-01-28.\\n\\n^ Cireşan, Dan; Meier, Ueli; Masci, Jonathan; Schmidhuber, Jürgen (August 2012). \"Multi-column deep neural network for traffic sign classification\". Neural Networks. Selected Papers from IJCNN 2011. 32: 333–338. CiteSeerX\\xa010.1.1.226.8219. doi:10.1016/j.neunet.2012.02.023. PMID\\xa022386783.\\n\\n^ Chaochao Lu; Xiaoou Tang (2014). \"Surpassing Human Level Face Recognition\". arXiv:1404.3840 [cs.CV].\\n\\n^ Nvidia Demos a Car Computer Trained with \"Deep Learning\" (6 January 2015), David Talbot, MIT Technology Review\\n\\n^ a b c G. W. Smith; Frederic Fol Leymarie (10 April 2017). \"The Machine as Artist: An Introduction\". Arts. 6 (4): 5. doi:10.3390/arts6020005.\\n\\n^ a b c Blaise Agüera y Arcas (29 September 2017). \"Art in the Age of Machine Intelligence\". Arts. 6 (4): 18. doi:10.3390/arts6040018.\\n\\n^ Goldberg, Yoav; Levy, Omar (2014). \"word2vec Explained: Deriving Mikolov et al.\\'s Negative-Sampling Word-Embedding Method\". arXiv:1402.3722 [cs.CL].\\n\\n^ a b Socher, Richard; Manning, Christopher. \"Deep Learning for NLP\" (PDF). Archived (PDF) from the original on 6 July 2014. Retrieved 26 October 2014.\\n\\n^ Socher, Richard; Bauer, John; Manning, Christopher; Ng, Andrew (2013). \"Parsing With Compositional Vector Grammars\" (PDF). Proceedings of the ACL 2013 Conference. Archived (PDF) from the original on 2014-11-27. Retrieved 2014-09-03.\\n\\n^ Socher, R.; Perelygin, A.; Wu, J.; Chuang, J.; Manning, C.D.; Ng, A.; Potts, C. (October 2013). \"Recursive Deep Models for Semantic Compositionality over a Sentiment Treebank\" (PDF). Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics. pp.\\xa01631–1642. doi:10.18653/v1/D13-1170. Archived (PDF) from the original on 28 December 2016. Retrieved 21 December 2023.\\n\\n^ Shen, Yelong; He, Xiaodong; Gao, Jianfeng; Deng, Li; Mesnil, Gregoire (1 November 2014). \"A Latent Semantic Model with Convolutional-Pooling Structure for Information Retrieval\". Microsoft Research. Archived from the original on 27 October 2017. Retrieved 14 June 2017.\\n\\n^ Huang, Po-Sen; He, Xiaodong; Gao, Jianfeng; Deng, Li; Acero, Alex; Heck, Larry (1 October 2013). \"Learning Deep Structured Semantic Models for Web Search using Clickthrough Data\". Microsoft Research. Archived from the original on 27 October 2017. Retrieved 14 June 2017.\\n\\n^ Mesnil, G.; Dauphin, Y.; Yao, K.; Bengio, Y.; Deng, L.; Hakkani-Tur, D.; He, X.; Heck, L.; Tur, G.; Yu, D.; Zweig, G. (2015). \"Using recurrent neural networks for slot filling in spoken language understanding\". IEEE Transactions on Audio, Speech, and Language Processing. 23 (3): 530–539. Bibcode:2015ITASL..23..530M. doi:10.1109/taslp.2014.2383614. S2CID\\xa01317136.\\n\\n^ a b Gao, Jianfeng; He, Xiaodong; Yih, Scott Wen-tau; Deng, Li (1 June 2014). \"Learning Continuous Phrase Representations for Translation Modeling\". Microsoft Research. Archived from the original on 27 October 2017. Retrieved 14 June 2017.\\n\\n^ Brocardo, Marcelo Luiz; Traore, Issa; Woungang, Isaac; Obaidat, Mohammad S. (2017). \"Authorship verification using deep belief network systems\". International Journal of Communication Systems. 30 (12) e3259. doi:10.1002/dac.3259. S2CID\\xa040745740.\\n\\n^ Kariampuzha, William; Alyea, Gioconda; Qu, Sue; Sanjak, Jaleal; Mathé, Ewy; Sid, Eric; Chatelaine, Haley; Yadaw, Arjun; Xu, Yanji; Zhu, Qian (2023). \"Precision information extraction for rare disease epidemiology at scale\". Journal of Translational Medicine. 21 (1): 157. doi:10.1186/s12967-023-04011-y. PMC\\xa09972634. PMID\\xa036855134.\\n\\n^ \"Deep Learning for Natural Language Processing: Theory and Practice (CIKM2014 Tutorial) - Microsoft Research\". Microsoft Research. Archived from the original on 13 March 2017. Retrieved 14 June 2017.\\n\\n^ Turovsky, Barak (15 November 2016). \"Found in translation: More accurate, fluent sentences in Google Translate\". The Keyword Google Blog. Archived from the original on 7 April 2017. Retrieved 23 March 2017.\\n\\n^ a b c d Schuster, Mike; Johnson, Melvin; Thorat, Nikhil (22 November 2016). \"Zero-Shot Translation with Google\\'s Multilingual Neural Machine Translation System\". Google Research Blog. Archived from the original on 10 July 2017. Retrieved 23 March 2017.\\n\\n^ Wu, Yonghui; Schuster, Mike; Chen, Zhifeng; Le, Quoc V; Norouzi, Mohammad; Macherey, Wolfgang; Krikun, Maxim; Cao, Yuan; Gao, Qin; Macherey, Klaus; Klingner, Jeff; Shah, Apurva; Johnson, Melvin; Liu, Xiaobing; Kaiser, Łukasz; Gouws, Stephan; Kato, Yoshikiyo; Kudo, Taku; Kazawa, Hideto; Stevens, Keith; Kurian, George; Patil, Nishant; Wang, Wei; Young, Cliff; Smith, Jason; Riesa, Jason; Rudnick, Alex; Vinyals, Oriol; Corrado, Greg; et\\xa0al. (2016). \"Google\\'s Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\". arXiv:1609.08144 [cs.CL].\\n\\n^ Metz, Cade (27 September 2016). \"An Infusion of AI Makes Google Translate More Powerful Than Ever\". Wired. Archived from the original on 8 November 2020. Retrieved 12 October 2017.\\n\\n^ a b Boitet, Christian; Blanchon, Hervé; Seligman, Mark; Bellynck, Valérie (2010). \"MT on and for the Web\" (PDF). Archived from the original (PDF) on 29 March 2017. Retrieved 1 December 2016.\\n\\n^ Arrowsmith, J; Miller, P (2013). \"Trial watch: Phase II and phase III attrition rates 2011-2012\". Nature Reviews Drug Discovery. 12 (8): 569. doi:10.1038/nrd4090. PMID\\xa023903212. S2CID\\xa020246434.\\n\\n^ Verbist, B; Klambauer, G; Vervoort, L; Talloen, W; The Qstar, Consortium; Shkedy, Z; Thas, O; Bender, A; Göhlmann, H. W.; Hochreiter, S (2015). \"Using transcriptomics to guide lead optimization in drug discovery projects: Lessons learned from the QSTAR project\". Drug Discovery Today. 20 (5): 505–513. doi:10.1016/j.drudis.2014.12.014. hdl:1942/18723. PMID\\xa025582842.\\n\\n^ \"Merck Molecular Activity Challenge\". kaggle.com. Archived from the original on 2020-07-16. Retrieved 2020-07-16.\\n\\n^ \"Multi-task Neural Networks for QSAR Predictions | Data Science Association\". www.datascienceassn.org. Archived from the original on 30 April 2017. Retrieved 14 June 2017.\\n\\n^ \"Toxicology in the 21st century Data Challenge\"\\n\\n^ \"NCATS Announces Tox21 Data Challenge Winners\". Archived from the original on 2015-09-08. Retrieved 2015-03-05.\\n\\n^ \"NCATS Announces Tox21 Data Challenge Winners\". Archived from the original on 28 February 2015. Retrieved 5 March 2015.\\n\\n^ Wallach, Izhar; Dzamba, Michael; Heifets, Abraham (9 October 2015). \"AtomNet: A Deep Convolutional Neural Network for Bioactivity Prediction in Structure-based Drug Discovery\". arXiv:1510.02855 [cs.LG].\\n\\n^ a b \"Toronto startup has a faster way to discover effective medicines\". The Globe and Mail. Archived from the original on 20 October 2015. Retrieved 9 November 2015.\\n\\n^ \"Startup Harnesses Supercomputers to Seek Cures\". KQED Future of You. 27 May 2015. Archived from the original on 24 December 2015. Retrieved 9 November 2015.\\n\\n^ Gilmer, Justin; Schoenholz, Samuel S.; Riley, Patrick F.; Vinyals, Oriol; Dahl, George E. (2017-06-12). \"Neural Message Passing for Quantum Chemistry\". arXiv:1704.01212 [cs.LG].\\n\\n^ Zhavoronkov, Alex (2019). \"Deep learning enables rapid identification of potent DDR1 kinase inhibitors\". Nature Biotechnology. 37 (9): 1038–1040. doi:10.1038/s41587-019-0224-x. PMID\\xa031477924. S2CID\\xa0201716327.\\n\\n^ Gregory, Barber. \"A Molecule Designed By AI Exhibits \\'Druglike\\' Qualities\". Wired. Archived from the original on 2020-04-30. Retrieved 2019-09-05.\\n\\n^ van den Oord, Aaron; Dieleman, Sander; Schrauwen, Benjamin (2013). Burges, C. J. C.; Bottou, L.; Welling, M.; Ghahramani, Z.; Weinberger, K. Q. (eds.). Advances in Neural Information Processing Systems 26 (PDF). Curran Associates, Inc. pp.\\xa02643–2651. Archived (PDF) from the original on 2017-05-16. Retrieved 2017-06-14.\\n\\n^ Feng, X.Y.; Zhang, H.; Ren, Y.J.; Shang, P.H.; Zhu, Y.; Liang, Y.C.; Guan, R.C.; Xu, D. (2019). \"The Deep Learning–Based Recommender System \"Pubmender\" for Choosing a Biomedical Publication Venue: Development and Validation Study\". Journal of Medical Internet Research. 21 (5) e12957. doi:10.2196/12957. PMC\\xa06555124. PMID\\xa031127715.\\n\\n^ Elkahky, Ali Mamdouh; Song, Yang; He, Xiaodong (1 May 2015). \"A Multi-View Deep Learning Approach for Cross Domain User Modeling in Recommendation Systems\". Microsoft Research. Archived from the original on 25 January 2018. Retrieved 14 June 2017.\\n\\n^ Chicco, Davide; Sadowski, Peter; Baldi, Pierre (1 January 2014). \"Deep autoencoder neural networks for gene ontology annotation predictions\". Proceedings of the 5th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics. ACM. pp.\\xa0533–540. doi:10.1145/2649387.2649442. hdl:11311/964622. ISBN\\xa0978-1-4503-2894-4. S2CID\\xa0207217210. Archived from the original on 9 May 2021. Retrieved 23 November 2015.\\n\\n^ Sathyanarayana, Aarti (1 January 2016). \"Sleep Quality Prediction From Wearable Data Using Deep Learning\". JMIR mHealth and uHealth. 4 (4): e125. doi:10.2196/mhealth.6562. PMC\\xa05116102. PMID\\xa027815231. S2CID\\xa03821594.\\n\\n^ Choi, Edward; Schuetz, Andy; Stewart, Walter F.; Sun, Jimeng (13 August 2016). \"Using recurrent neural network models for early detection of heart failure onset\". Journal of the American Medical Informatics Association. 24 (2): 361–370. doi:10.1093/jamia/ocw112. ISSN\\xa01067-5027. PMC\\xa05391725. PMID\\xa027521897.\\n\\n^ \"DeepMind\\'s protein-folding AI has solved a 50-year-old grand challenge of biology\". MIT Technology Review. Retrieved 2024-05-10.\\n\\n^ Shead, Sam (2020-11-30). \"DeepMind solves 50-year-old \\'grand challenge\\' with protein folding A.I.\" CNBC. Retrieved 2024-05-10.\\n\\n^ a b Shalev, Y.; Painsky, A.; Ben-Gal, I. (2022). \"Neural Joint Entropy Estimation\" (PDF). IEEE Transactions on Neural Networks and Learning Systems. PP (4): 5488–5500. arXiv:2012.11197. doi:10.1109/TNNLS.2022.3204919. PMID\\xa036155469. S2CID\\xa0229339809.\\n\\n^ Litjens, Geert; Kooi, Thijs; Bejnordi, Babak Ehteshami; Setio, Arnaud Arindra Adiyoso; Ciompi, Francesco; Ghafoorian, Mohsen; van der Laak, Jeroen A.W.M.; van Ginneken, Bram; Sánchez, Clara I. (December 2017). \"A survey on deep learning in medical image analysis\". Medical Image Analysis. 42: 60–88. arXiv:1702.05747. Bibcode:2017arXiv170205747L. doi:10.1016/j.media.2017.07.005. PMID\\xa028778026. S2CID\\xa02088679.\\n\\n^ Forslid, Gustav; Wieslander, Hakan; Bengtsson, Ewert; Wahlby, Carolina; Hirsch, Jan-Michael; Stark, Christina Runow; Sadanandan, Sajith Kecheril (2017). \"Deep Convolutional Neural Networks for Detecting Cellular Changes Due to Malignancy\". 2017 IEEE International Conference on Computer Vision Workshops (ICCVW). pp.\\xa082–89. doi:10.1109/ICCVW.2017.18. ISBN\\xa0978-1-5386-1034-3. S2CID\\xa04728736. Archived from the original on 2021-05-09. Retrieved 2019-11-12.\\n\\n^ Dong, Xin; Zhou, Yizhao; Wang, Lantian; Peng, Jingfeng; Lou, Yanbo; Fan, Yiqun (2020). \"Liver Cancer Detection Using Hybridized Fully Convolutional Neural Network Based on Deep Learning Framework\". IEEE Access. 8: 129889–129898. Bibcode:2020IEEEA...8l9889D. doi:10.1109/ACCESS.2020.3006362. ISSN\\xa02169-3536. S2CID\\xa0220733699.\\n\\n^ Lyakhov, Pavel Alekseevich; Lyakhova, Ulyana Alekseevna; Nagornov, Nikolay Nikolaevich (2022-04-03). \"System for the Recognizing of Pigmented Skin Lesions with Fusion and Analysis of Heterogeneous Data Based on a Multimodal Neural Network\". Cancers. 14 (7): 1819. doi:10.3390/cancers14071819. ISSN\\xa02072-6694. PMC\\xa08997449. PMID\\xa035406591.\\n\\n^ De, Shaunak; Maity, Abhishek; Goel, Vritti; Shitole, Sanjay; Bhattacharya, Avik (2017). \"Predicting the popularity of instagram posts for a lifestyle magazine using deep learning\". 2017 2nd International Conference on Communication Systems, Computing and IT Applications (CSCITA). pp.\\xa0174–177. doi:10.1109/CSCITA.2017.8066548. ISBN\\xa0978-1-5090-4381-1. S2CID\\xa035350962.\\n\\n^ \"Colorizing and Restoring Old Images with Deep Learning\". FloydHub Blog. 13 November 2018. Archived from the original on 11 October 2019. Retrieved 11 October 2019.\\n\\n^ Schmidt, Uwe; Roth, Stefan. Shrinkage Fields for Effective Image Restoration (PDF). Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. Archived (PDF) from the original on 2018-01-02. Retrieved 2018-01-01.\\n\\n^ Kleanthous, Christos; Chatzis, Sotirios (2020). \"Gated Mixture Variational Autoencoders for Value Added Tax audit case selection\". Knowledge-Based Systems. 188 105048. doi:10.1016/j.knosys.2019.105048. S2CID\\xa0204092079.\\n\\n^ Czech, Tomasz (28 June 2018). \"Deep learning: the next frontier for money laundering detection\". Global Banking and Finance Review. Archived from the original on 2018-11-16. Retrieved 2018-07-15.\\n\\n^ Nuñez, Michael (2023-11-29). \"Google DeepMind\\'s materials AI has already discovered 2.2 million new crystals\". VentureBeat. Retrieved 2023-12-19.\\n\\n^ Merchant, Amil; Batzner, Simon; Schoenholz, Samuel S.; Aykol, Muratahan; Cheon, Gowoon; Cubuk, Ekin Dogus (December 2023). \"Scaling deep learning for materials discovery\". Nature. 624 (7990): 80–85. Bibcode:2023Natur.624...80M. doi:10.1038/s41586-023-06735-9. ISSN\\xa01476-4687. PMC\\xa010700131. PMID\\xa038030720.\\n\\n^ Peplow, Mark (2023-11-29). \"Google AI and robots join forces to build new materials\". Nature. doi:10.1038/d41586-023-03745-5. PMID\\xa038030771. S2CID\\xa0265503872.\\n\\n^ a b c \"Army researchers develop new algorithms to train robots\". EurekAlert!. Archived from the original on 28 August 2018. Retrieved 29 August 2018.\\n\\n^ Raissi, M.; Perdikaris, P.; Karniadakis, G. E. (2019-02-01). \"Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations\". Journal of Computational Physics. 378: 686–707. Bibcode:2019JCoPh.378..686R. doi:10.1016/j.jcp.2018.10.045. ISSN\\xa00021-9991. OSTI\\xa01595805. S2CID\\xa057379996.\\n\\n^ Mao, Zhiping; Jagtap, Ameya D.; Karniadakis, George Em (2020-03-01). \"Physics-informed neural networks for high-speed flows\". Computer Methods in Applied Mechanics and Engineering. 360 112789. Bibcode:2020CMAME.360k2789M. doi:10.1016/j.cma.2019.112789. ISSN\\xa00045-7825. S2CID\\xa0212755458.\\n\\n^ Raissi, Maziar; Yazdani, Alireza; Karniadakis, George Em (2020-02-28). \"Hidden fluid mechanics: Learning velocity and pressure fields from flow visualizations\". Science. 367 (6481): 1026–1030. Bibcode:2020Sci...367.1026R. doi:10.1126/science.aaw4741. PMC\\xa07219083. PMID\\xa032001523.\\n\\n^ Huang, Yunfei and Greenberg, David S. \"Geometric and Physical Constraints Synergistically Enhance Neural PDE Surrogates.\" Proceedings of the 42th international conference on Machine learning. ACM, 2025.\\n\\n^ Han, J.; Jentzen, A.; E, W. (2018). \"Solving high-dimensional partial differential equations using deep learning\". Proceedings of the National Academy of Sciences. 115 (34): 8505–8510. arXiv:1707.02568. Bibcode:2018PNAS..115.8505H. doi:10.1073/pnas.1718942115. PMC\\xa06112690. PMID\\xa030082389.\\n\\n^ Oktem, Figen S.; Kar, Oğuzhan Fatih; Bezek, Can Deniz; Kamalabadi, Farzad (2021). \"High-Resolution Multi-Spectral Imaging With Diffractive Lenses and Learned Reconstruction\". IEEE Transactions on Computational Imaging. 7: 489–504. arXiv:2008.11625. Bibcode:2021ITCI....7..489O. doi:10.1109/TCI.2021.3075349. ISSN\\xa02333-9403. S2CID\\xa0235340737.\\n\\n^ Bernhardt, Melanie; Vishnevskiy, Valery; Rau, Richard; Goksel, Orcun (December 2020). \"Training Variational Networks With Multidomain Simulations: Speed-of-Sound Image Reconstruction\". IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control. 67 (12): 2584–2594. arXiv:2006.14395. Bibcode:2020ITUFF..67.2584B. doi:10.1109/TUFFC.2020.3010186. ISSN\\xa01525-8955. PMID\\xa032746211. S2CID\\xa0220055785.\\n\\n^ Lam, Remi; Sanchez-Gonzalez, Alvaro; Willson, Matthew; Wirnsberger, Peter; Fortunato, Meire; Alet, Ferran; Ravuri, Suman; Ewalds, Timo; Eaton-Rosen, Zach; Hu, Weihua; Merose, Alexander; Hoyer, Stephan; Holland, George; Vinyals, Oriol; Stott, Jacklynn (2023-12-22). \"Learning skillful medium-range global weather forecasting\". Science. 382 (6677): 1416–1421. arXiv:2212.12794. Bibcode:2023Sci...382.1416L. doi:10.1126/science.adi2336. ISSN\\xa00036-8075. PMID\\xa037962497.\\n\\n^ Sivakumar, Ramakrishnan (2023-11-27). \"GraphCast: A breakthrough in Weather Forecasting\". Medium. Retrieved 2024-05-19.\\n\\n^ Galkin, F.; Mamoshina, P.; Kochetov, K.; Sidorenko, D.; Zhavoronkov, A. (2020). \"DeepMAge: A Methylation Aging Clock Developed with Deep Learning\". Aging and Disease. doi:10.14336/AD.\\n\\n^ Utgoff, P. E.; Stracuzzi, D. J. (2002). \"Many-layered learning\". Neural Computation. 14 (10): 2497–2529. doi:10.1162/08997660260293319. PMID\\xa012396572. S2CID\\xa01119517.\\n\\n^ Elman, Jeffrey L. (1998). Rethinking Innateness: A Connectionist Perspective on Development. MIT Press. ISBN\\xa0978-0-262-55030-7.\\n\\n^ Shrager, J.; Johnson, MH (1996). \"Dynamic plasticity influences the emergence of function in a simple cortical array\". Neural Networks. 9 (7): 1119–1129. doi:10.1016/0893-6080(96)00033-0. PMID\\xa012662587.\\n\\n^ Quartz, SR; Sejnowski, TJ (1997). \"The neural basis of cognitive development: A constructivist manifesto\". Behavioral and Brain Sciences. 20 (4): 537–556. CiteSeerX\\xa010.1.1.41.7854. doi:10.1017/s0140525x97001581. PMID\\xa010097006. S2CID\\xa05818342.\\n\\n^ S. Blakeslee, \"In brain\\'s early growth, timetable may be critical\", The New York Times, Science Section, pp. B5–B6, 1995.\\n\\n^ Mazzoni, P.; Andersen, R. A.; Jordan, M. I. (15 May 1991). \"A more biologically plausible learning rule for neural networks\". Proceedings of the National Academy of Sciences. 88 (10): 4433–4437. Bibcode:1991PNAS...88.4433M. doi:10.1073/pnas.88.10.4433. ISSN\\xa00027-8424. PMC\\xa051674. PMID\\xa01903542.\\n\\n^ O\\'Reilly, Randall C. (1 July 1996). \"Biologically Plausible Error-Driven Learning Using Local Activation Differences: The Generalized Recirculation Algorithm\". Neural Computation. 8 (5): 895–938. doi:10.1162/neco.1996.8.5.895. ISSN\\xa00899-7667. S2CID\\xa02376781.\\n\\n^ Testolin, Alberto; Zorzi, Marco (2016). \"Probabilistic Models and Generative Neural Networks: Towards an Unified Framework for Modeling Normal and Impaired Neurocognitive Functions\". Frontiers in Computational Neuroscience. 10: 73. doi:10.3389/fncom.2016.00073. ISSN\\xa01662-5188. PMC\\xa04943066. PMID\\xa027468262. S2CID\\xa09868901.\\n\\n^ Testolin, Alberto; Stoianov, Ivilin; Zorzi, Marco (September 2017). \"Letter perception emerges from unsupervised deep learning and recycling of natural image features\". Nature Human Behaviour. 1 (9): 657–664. doi:10.1038/s41562-017-0186-2. ISSN\\xa02397-3374. PMID\\xa031024135. S2CID\\xa024504018.\\n\\n^ Buesing, Lars; Bill, Johannes; Nessler, Bernhard; Maass, Wolfgang (3 November 2011). \"Neural Dynamics as Sampling: A Model for Stochastic Computation in Recurrent Networks of Spiking Neurons\". PLOS Computational Biology. 7 (11) e1002211. Bibcode:2011PLSCB...7E2211B. doi:10.1371/journal.pcbi.1002211. ISSN\\xa01553-7358. PMC\\xa03207943. PMID\\xa022096452. S2CID\\xa07504633.\\n\\n^ Cash, S.; Yuste, R. (February 1999). \"Linear summation of excitatory inputs by CA1 pyramidal neurons\". Neuron. 22 (2): 383–394. doi:10.1016/s0896-6273(00)81098-3. ISSN\\xa00896-6273. PMID\\xa010069343. S2CID\\xa014663106.\\n\\n^ Olshausen, B; Field, D (1 August 2004). \"Sparse coding of sensory inputs\". Current Opinion in Neurobiology. 14 (4): 481–487. doi:10.1016/j.conb.2004.07.007. ISSN\\xa00959-4388. PMID\\xa015321069. S2CID\\xa016560320.\\n\\n^ Yamins, Daniel L K; DiCarlo, James J (March 2016). \"Using goal-driven deep learning models to understand sensory cortex\". Nature Neuroscience. 19 (3): 356–365. doi:10.1038/nn.4244. ISSN\\xa01546-1726. PMID\\xa026906502. S2CID\\xa016970545.\\n\\n^ Zorzi, Marco; Testolin, Alberto (19 February 2018). \"An emergentist perspective on the origin of number sense\". Phil. Trans. R. Soc. B. 373 (1740) 20170043. doi:10.1098/rstb.2017.0043. ISSN\\xa00962-8436. PMC\\xa05784047. PMID\\xa029292348. S2CID\\xa039281431.\\n\\n^ Güçlü, Umut; van Gerven, Marcel A. J. (8 July 2015). \"Deep Neural Networks Reveal a Gradient in the Complexity of Neural Representations across the Ventral Stream\". Journal of Neuroscience. 35 (27): 10005–10014. arXiv:1411.6422. doi:10.1523/jneurosci.5023-14.2015. PMC\\xa06605414. PMID\\xa026157000.\\n\\n^ Metz, C. (12 December 2013). \"Facebook\\'s \\'Deep Learning\\' Guru Reveals the Future of AI\". Wired. Archived from the original on 28 March 2014. Retrieved 26 August 2017.\\n\\n^ Gibney, Elizabeth (2016). \"Google AI algorithm masters ancient game of Go\". Nature. 529 (7587): 445–446. Bibcode:2016Natur.529..445G. doi:10.1038/529445a. PMID\\xa026819021. S2CID\\xa04460235.\\n\\n^ Silver, David; Huang, Aja; Maddison, Chris J.; Guez, Arthur; Sifre, Laurent; Driessche, George van den; Schrittwieser, Julian; Antonoglou, Ioannis; Panneershelvam, Veda; Lanctot, Marc; Dieleman, Sander; Grewe, Dominik; Nham, John; Kalchbrenner, Nal; Sutskever, Ilya; Lillicrap, Timothy; Leach, Madeleine; Kavukcuoglu, Koray; Graepel, Thore; Hassabis, Demis (28 January 2016). \"Mastering the game of Go with deep neural networks and tree search\". Nature. 529 (7587): 484–489. Bibcode:2016Natur.529..484S. doi:10.1038/nature16961. ISSN\\xa00028-0836. PMID\\xa026819042. S2CID\\xa0515925.\\n\\n^ \"A Google DeepMind Algorithm Uses Deep Learning and More to Master the Game of Go | MIT Technology Review\". MIT Technology Review. Archived from the original on 1 February 2016. Retrieved 30 January 2016.\\n\\n^ Metz, Cade (6 November 2017). \"A.I. Researchers Leave Elon Musk Lab to Begin Robotics Start-Up\". The New York Times. Archived from the original on 7 July 2019. Retrieved 5 July 2019.\\n\\n^ Bradley Knox, W.; Stone, Peter (2008). \"TAMER: Training an Agent Manually via Evaluative Reinforcement\". 2008 7th IEEE International Conference on Development and Learning. pp.\\xa0292–297. doi:10.1109/devlrn.2008.4640845. ISBN\\xa0978-1-4244-2661-4. S2CID\\xa05613334.\\n\\n^ \"Talk to the Algorithms: AI Becomes a Faster Learner\". governmentciomedia.com. 16 May 2018. Archived from the original on 28 August 2018. Retrieved 29 August 2018.\\n\\n^ Marcus, Gary (14 January 2018). \"In defense of skepticism about deep learning\". Gary Marcus. Archived from the original on 12 October 2018. Retrieved 11 October 2018.\\n\\n^ Knight, Will (14 March 2017). \"DARPA is funding projects that will try to open up AI\\'s black boxes\". MIT Technology Review. Archived from the original on 4 November 2019. Retrieved 2 November 2017.\\n\\n^ Alexander Mordvintsev; Christopher Olah; Mike Tyka (17 June 2015). \"Inceptionism: Going Deeper into Neural Networks\". Google Research Blog. Archived from the original on 3 July 2015. Retrieved 20 June 2015.\\n\\n^ Alex Hern (18 June 2015). \"Yes, androids do dream of electric sheep\". The Guardian. Archived from the original on 19 June 2015. Retrieved 20 June 2015.\\n\\n^ Takahashi, Carlos Kazunari; Figueiredo, Júlio César Bastos de; Favaretto, José Eduardo Ricciardi (2023-03-24). \"Deep learning diffusion by search trend: a country-level analysis\". Future Studies Research Journal: Trends and Strategies. 15 (1): e0695. doi:10.24023/FutureJournal/2175-5825/2023.v15i1.695. ISSN\\xa02175-5825.\\n\\n^ a b c Goertzel, Ben (2015). \"Are there Deep Reasons Underlying the Pathologies of Today\\'s Deep Learning Algorithms?\" (PDF). Archived (PDF) from the original on 2015-05-13. Retrieved 2015-05-10.\\n\\n^ Nguyen, Anh; Yosinski, Jason; Clune, Jeff (2014). \"Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images\". arXiv:1412.1897 [cs.CV].\\n\\n^ Szegedy, Christian; Zaremba, Wojciech; Sutskever, Ilya; Bruna, Joan; Erhan, Dumitru; Goodfellow, Ian; Fergus, Rob (2013). \"Intriguing properties of neural networks\". arXiv:1312.6199 [cs.CV].\\n\\n^ Zhu, S.C.; Mumford, D. (2006). \"A stochastic grammar of images\". Found. Trends Comput. Graph. Vis. 2 (4): 259–362. CiteSeerX\\xa010.1.1.681.2190. doi:10.1561/0600000018.\\n\\n^ Miller, G. A., and N. Chomsky. \"Pattern conception\". Paper for Conference on pattern detection, University of Michigan. 1957.\\n\\n^ Eisner, Jason. \"Deep Learning of Recursive Structure: Grammar Induction\". Archived from the original on 2017-12-30. Retrieved 2015-05-10.\\n\\n^ \"Hackers Have Already Started to Weaponize Artificial Intelligence\". Gizmodo. 11 September 2017. Archived from the original on 11 October 2019. Retrieved 11 October 2019.\\n\\n^ \"How hackers can force AI to make dumb mistakes\". The Daily Dot. 18 June 2018. Archived from the original on 11 October 2019. Retrieved 11 October 2019.\\n\\n^ a b c d e \"AI Is Easy to Fool—Why That Needs to Change\". Singularity Hub. 10 October 2017. Archived from the original on 11 October 2017. Retrieved 11 October 2017.\\n\\n^ Gibney, Elizabeth (2017). \"The scientist who spots fake videos\". Nature. doi:10.1038/nature.2017.22784. Archived from the original on 2017-10-10. Retrieved 2017-10-11.\\n\\n^ Tubaro, Paola (2020). \"Whose intelligence is artificial intelligence?\". Global Dialogue: 38–39.\\n\\n^ a b Mühlhoff, Rainer (6 November 2019). \"Human-aided artificial intelligence: Or, how to run large computations in human brains? Toward a media sociology of machine learning\". New Media & Society. 22 (10): 1868–1884. doi:10.1177/1461444819885334. ISSN\\xa01461-4448. S2CID\\xa0209363848.\\n\\n\\nFurther reading[edit]\\n\\nBishop, Christopher M.; Bishop, Hugh (2024). Deep learning: foundations and concepts. Springer. ISBN\\xa0978-3-031-45467-7.\\nPrince, Simon J. D. (2023). Understanding deep learning. The MIT Press. ISBN\\xa0978-0-262-04864-4.\\nGoodfellow, Ian; Bengio, Yoshua; Courville, Aaron (2016). Deep Learning. MIT Press. ISBN\\xa0978-0-26203561-3. Archived from the original on 2016-04-16. Retrieved 2021-05-09, introductory textbook.{{cite book}}:  CS1 maint: postscript (link)\\n\\nvteGenerative AIConcepts\\nAutoencoder\\nDeep learning\\nFine-tuning\\nFoundation model\\nGenerative adversarial network\\nGenerative pre-trained transformer\\nLarge language model\\nModel Context Protocol\\nNeural network\\nPrompt engineering\\nReinforcement learning from human feedback\\nRetrieval-augmented generation\\nSelf-supervised learning\\nStochastic parrot\\nSynthetic data\\nTop-p sampling\\nTransformer\\nVariational autoencoder\\nVibe coding\\nVision transformer\\nWord embedding\\nChatbots\\nCharacter.ai\\nChatGPT\\nCopilot\\nDeepSeek\\nErnie\\nGemini\\nGrok\\nPerplexity.ai\\nModelsText\\nClaude\\nGemini\\nGemma\\nGPT\\n1\\n2\\n3\\nJ\\n4\\n4o\\n4.5\\n4.1\\nOSS\\n5\\n5.1\\n5.2\\nLlama\\no1\\no3\\no4-mini\\nQwen\\nVelvet\\nCoding\\nClaude Code\\nCursor\\nDevstral\\nGitHub Copilot\\nKimi\\nQwen3-Coder\\nReplit\\nImage\\nAurora\\nFirefly\\nDALL-E\\nFlux\\nGPT Image\\nIdeogram\\nImagen\\nNano Banana\\nMidjourney\\nQwen-Image\\nRecraft\\nSeedream\\nStable Diffusion\\nVideo\\nDream Machine\\nHailuo AI\\nKling\\nRunway Gen\\nSeedance\\nLTX-2\\nSora\\nVeo\\nWan\\nSpeech\\n15.ai\\nEleven\\nMiniMax Speech 2.5\\nWaveNet\\nMusic\\nEleven Music\\nEndel\\nLyria\\nRiffusion\\nSuno\\nUdio\\nControversies\\nGenerative AI pornography\\nDeepfake pornography\\nTaylor Swift\\'s\\nGoogle Gemini image generation\\nPause Giant AI Experiments\\nRemoval of Sam Altman from OpenAI\\nStatement on AI Risk\\nTay (chatbot)\\nThéâtre D\\'opéra Spatial\\nVoiceverse NFT plagiarism\\nAgents\\nAgentforce\\nAutoGLM\\nAutoGPT\\nChatGPT Agent\\nDevin AI\\nManus\\nOpenAI Codex\\nOperator\\nReplit Agent\\nCompanies\\nAleph Alpha\\nAnthropic\\nAnysphere\\nCognition AI\\nCohere\\nContextual AI\\nDeepSeek\\nEleutherAI\\nElevenLabs\\nGoogle DeepMind\\nHeyGen\\nHugging Face\\nInflection AI\\nKrikey AI\\nKuaishou\\nLightricks\\nLuma Labs\\nMeta AI\\nMiniMax\\nMistral AI\\nMoonshot AI\\nOpenAI\\nPerplexity AI\\nRunway\\nSafe Superintelligence\\nSalesforce\\nScale AI\\nSoundHound\\nStability AI\\nStepFun\\nSynthesia\\nThinking Machines Lab\\nUpstage\\nxAI\\nZ.ai\\n\\n Category\\n\\nvteArtificial intelligence (AI)\\nHistory\\ntimeline\\nGlossary\\nCompanies\\nProjects\\nConcepts\\nParameter\\nHyperparameter\\nLoss functions\\nRegression\\nBias–variance tradeoff\\nDouble descent\\nOverfitting\\nClustering\\nGradient descent\\nSGD\\nQuasi-Newton method\\nConjugate gradient method\\nBackpropagation\\nAttention\\nConvolution\\nNormalization\\nBatchnorm\\nActivation\\nSoftmax\\nSigmoid\\nRectifier\\nGating\\nWeight initialization\\nRegularization\\nDatasets\\nAugmentation\\nPrompt engineering\\nReinforcement learning\\nQ-learning\\nSARSA\\nImitation\\nPolicy gradient\\nDiffusion\\nLatent diffusion model\\nAutoregression\\nAdversary\\nRAG\\nUncanny valley\\nRLHF\\nSelf-supervised learning\\nReflection\\nRecursive self-improvement\\nHallucination\\nWord embedding\\nVibe coding\\nSafety (Alignment)\\nApplications\\nMachine learning\\nIn-context learning\\nArtificial neural network\\nDeep learning\\nLanguage model\\nLarge\\nNMT\\nReasoning\\nModel Context Protocol\\nIntelligent agent\\nArtificial human companion\\nHumanity\\'s Last Exam\\nLethal autonomous weapons (LAWs)\\nGenerative artificial intelligence (GenAI)\\n(Hypothetical: Artificial general intelligence (AGI))\\n(Hypothetical: Artificial superintelligence (ASI))\\nImplementationsAudio–visual\\nAlexNet\\nWaveNet\\nHuman image synthesis\\nHWR\\nOCR\\nComputer vision\\nSpeech synthesis\\n15.ai\\nElevenLabs\\nSpeech recognition\\nWhisper\\nFacial recognition\\nAlphaFold\\nText-to-image models\\nAurora\\nDALL-E\\nFirefly\\nFlux\\nGPT Image\\nIdeogram\\nImagen\\nMidjourney\\nRecraft\\nStable Diffusion\\nText-to-video models\\nDream Machine\\nRunway Gen\\nHailuo AI\\nKling\\nSora\\nVeo\\nMusic generation\\nRiffusion\\nSuno AI\\nUdio\\nText\\nWord2vec\\nSeq2seq\\nGloVe\\nBERT\\nT5\\nLlama\\nChinchilla AI\\nPaLM\\nGPT\\n1\\n2\\n3\\nJ\\nChatGPT\\n4\\n4o\\no1\\no3\\n4.5\\n4.1\\no4-mini\\n5\\n5.1\\n5.2\\nClaude\\nGemini\\nGemini (language model)\\nGemma\\nGrok\\nLaMDA\\nBLOOM\\nDBRX\\nProject Debater\\nIBM Watson\\nIBM Watsonx\\nGranite\\nPanGu-Σ\\nDeepSeek\\nQwen\\nDecisional\\nAlphaGo\\nAlphaZero\\nOpenAI Five\\nSelf-driving car\\nMuZero\\nAction selection\\nAutoGPT\\nRobot control\\nPeople\\nAlan Turing\\nWarren Sturgis McCulloch\\nWalter Pitts\\nJohn von Neumann\\nChristopher D. Manning\\nClaude Shannon\\nShun\\'ichi Amari\\nKunihiko Fukushima\\nTakeo Kanade\\nMarvin Minsky\\nJohn McCarthy\\nNathaniel Rochester\\nAllen Newell\\nCliff Shaw\\nHerbert A. Simon\\nOliver Selfridge\\nFrank Rosenblatt\\nBernard Widrow\\nJoseph Weizenbaum\\nSeymour Papert\\nSeppo Linnainmaa\\nPaul Werbos\\nGeoffrey Hinton\\nJohn Hopfield\\nJürgen Schmidhuber\\nYann LeCun\\nYoshua Bengio\\nLotfi A. Zadeh\\nStephen Grossberg\\nAlex Graves\\nJames Goodnight\\nAndrew Ng\\nFei-Fei Li\\nAlex Krizhevsky\\nIlya Sutskever\\nOriol Vinyals\\nQuoc V. Le\\nIan Goodfellow\\nDemis Hassabis\\nDavid Silver\\nAndrej Karpathy\\nAshish Vaswani\\nNoam Shazeer\\nAidan Gomez\\nJohn Schulman\\nMustafa Suleyman\\nJan Leike\\nDaniel Kokotajlo\\nFrançois Chollet\\nArchitectures\\nNeural Turing machine\\nDifferentiable neural computer\\nTransformer\\nVision transformer (ViT)\\nRecurrent neural network (RNN)\\nLong short-term memory (LSTM)\\nGated recurrent unit (GRU)\\nEcho state network\\nMultilayer perceptron (MLP)\\nConvolutional neural network (CNN)\\nResidual neural network (RNN)\\nHighway network\\nMamba\\nAutoencoder\\nVariational autoencoder (VAE)\\nGenerative adversarial network (GAN)\\nGraph neural network (GNN)\\nPolitical\\nRegulation of artificial intelligence\\nEthics of artificial intelligence\\nPrecautionary principle\\nAI alignment\\nEU Artificial Intelligence Act (AI Act)\\n\\n Category\\n\\n\\n\\n\\n\\nRetrieved from \"https://en.wikipedia.org/w/index.php?title=Deep_learning&oldid=1331430863\"\\nCategory: Deep learningHidden categories: Webarchive template wayback linksCS1: long volume valueCS1 errors: ISBN dateCS1 Finnish-language sources (fi)CS1 maint: multiple names: authors listArticles with short descriptionShort description matches WikidataAll articles with unsourced statementsArticles with unsourced statements from August 2024Pages using multiple image with auto scaled imagesArticles with unsourced statements from November 2020Articles with unsourced statements from July 2016CS1 maint: postscriptArticles prone to spam from June 2015\\n\\n\\n\\n\\n\\n\\n This page was last edited on 6 January 2026, at 07:20\\xa0(UTC).\\nText is available under the Creative Commons Attribution-ShareAlike 4.0 License;\\nadditional terms may apply. By using this site, you agree to the Terms of Use and Privacy Policy. Wikipedia® is a registered trademark of the Wikimedia Foundation, Inc., a non-profit organization.\\n\\n\\nPrivacy policy\\nAbout Wikipedia\\nDisclaimers\\nContact Wikipedia\\nLegal & safety contacts\\nCode of Conduct\\nDevelopers\\nStatistics\\nCookie statement\\nMobile view\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nToggle the table of contents\\n\\n\\n\\n\\n\\n\\n\\nDeep learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n64 languages\\n\\n\\nAdd topic\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [\n",
    "    \"https://en.wikipedia.org/wiki/Machine_learning\",\n",
    "    \"https://en.wikipedia.org/wiki/Deep_learning\",\n",
    "]\n",
    "loader = WebBaseLoader(urls)\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3193b9",
   "metadata": {},
   "source": [
    "**CUSTOM WEB DATA EXTRACTION USING BEAUTIFULSOUP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0241fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://www.ibm.com/think/topics/deep-learning#763338456', 'title': 'Caret right'}, page_content='\\n\\nMachine learning\\n\\n\\n\\nWelcome\\n\\n\\n\\n\\n\\nCaret right\\n\\nIntroduction\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nMachine learning types\\n\\n\\n\\n\\nMachine learning algorithms\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nData science for machine learning\\n\\n\\n\\n\\nStatistical machine learning\\n\\n\\n\\n\\nLinear algebra for machine learning\\n\\n\\n\\n\\nUncertainty quantification\\n\\n\\n\\n\\nBias variance tradeoff\\n\\n\\n\\n\\nBayesian Statistics\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nFeature Engineering\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nFeature selection\\n\\n\\n\\n\\nFeature extraction\\n\\n\\n\\n\\nVector embedding\\n\\n\\n\\n\\nLatent space\\n\\n\\n\\n\\n\\nCaret right\\n\\nDimensionality reduction\\n\\n\\n\\n\\nPrincipal component analysis\\n\\n\\n\\n\\nLinear discriminant analysis\\n\\n\\n\\n\\n\\n\\nUpsampling\\n\\n\\n\\n\\nDownsampling\\n\\n\\n\\n\\nSynthetic data\\n\\n\\n\\n\\nData leakage\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nSupervised learning\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nRegression\\n\\n\\n\\n\\nLinear regression\\n\\n\\n\\n\\nLasso regression\\n\\n\\n\\n\\nRidge regression\\n\\n\\n\\n\\nState space model\\n\\n\\n\\n\\nTime series\\n\\n\\n\\n\\nAutoregressive model\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nClassification\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nDecision trees\\n\\n\\n\\n\\nK-nearest neighbors (KNNs)\\n\\n\\n\\n\\nNaive bayes\\n\\n\\n\\n\\nRandom forest\\n\\n\\n\\n\\nSupport vector machine\\n\\n\\n\\n\\nLogistic regression\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nEnsemble learning\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nBoosting\\n\\n\\n\\n\\nBagging\\n\\n\\n\\n\\nGradient boosting\\n\\n\\n\\n\\nGradient boosting classifier\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nSelf-supervised learning\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nTransfer learning\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nUnsupervised learning\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nClustering\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nK means clustering\\n\\n\\n\\n\\nHierarchical clustering\\n\\n\\n\\n\\n\\n\\nA priori algorithm\\n\\n\\n\\n\\nGaussian mixture model\\n\\n\\n\\n\\nAnomaly detection\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nSemi-supervised learning\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nRecommendation engine\\n\\n\\n\\n\\nCollaborative filtering\\n\\n\\n\\n\\nContent based filtering\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nReinforcement learning\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nReinforcement learning human feedback\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nDeep Learning\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\n\\nCaret right\\n\\nNeural networks\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nBackpropagation\\n\\n\\n\\n\\nEncoder-decoder model\\n\\n\\n\\n\\n\\n\\nRecurrent neural networks\\n\\n\\n\\n\\nLong short-term memory (LSTM)\\n\\n\\n\\n\\nConvolutional neural networks\\n\\n\\n\\n\\n\\nCaret right\\n\\nTransformer models\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nAttention mechanism\\n\\n\\n\\n\\nGrouped query attention\\n\\n\\n\\n\\nPositional encoding\\n\\n\\n\\n\\n\\n\\nAutoencoder\\n\\n\\n\\n\\nMamba model\\n\\n\\n\\n\\nGraph neural network\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nGenerative AI\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nGenerative model\\n\\n\\n\\n\\nGenerative AI vs. predictive AI\\n\\n\\n\\n\\n\\nCaret right\\n\\nLarge language models (LLMs)\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nReasoning models\\n\\n\\n\\n\\nSmall language models\\n\\n\\n\\n\\nInstruction tuning\\n\\n\\n\\n\\nLLM parameters\\n\\n\\n\\n\\nLLM temperature\\n\\n\\n\\n\\nLLM benchmarks\\n\\n\\n\\n\\nLLM customization\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nAI image generation\\n\\n\\n\\n\\nDiffusion models\\n\\n\\n\\n\\nVariational autoencoder (VAE)\\n\\n\\n\\n\\nGenerative adversarial networks (GANs)\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nMultimodal AI\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nVision language models\\n\\n\\n\\n\\nTutorial: Build an AI stylist\\n\\n\\n\\n\\nTutorial: Multimodal AI queries using Llama\\n\\n\\n\\n\\nTutorial: Multimodal AI queries using Pixtral\\n\\n\\n\\n\\nTutorial: Automatic podcast transcription with Granite\\n\\n\\n\\n\\nTutorial: PPT AI image analysis answering system\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nRetrieval augmented generation (RAG)\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nGraphRAG\\n\\n\\n\\n\\nTutorial: Build a multimodal RAG system with Docling and Granite\\n\\n\\n\\n\\nTutorial: Evaluate RAG pipline using Ragas\\n\\n\\n\\n\\nTutorial: RAG chunking strategies\\n\\n\\n\\n\\nTutorial: Graph RAG using knowledge graphs\\n\\n\\n\\n\\nTutorial: Inference scaling to improve multimodal RAG\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nAI code generation\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nVibe coding\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nAI agents\\n\\n\\n\\n\\nVisit the 2025 Guide to AI Agents\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nModel training\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nLoss function\\n\\n\\n\\n\\nTraining data\\n\\n\\n\\n\\nModel parameters\\n\\n\\n\\n\\n\\nCaret right\\n\\nOptimization algorithm\\n\\n\\n\\n\\nGradient descent\\n\\n\\n\\n\\nStochastic gradient descent\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nModel hyperparameters\\n\\n\\n\\n\\nHyperparameter tuning\\n\\n\\n\\n\\nLearning rate\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nFine tuning\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nParameter efficient fine tuning (PEFT)\\n\\n\\n\\n\\nLoRA\\n\\n\\n\\n\\nTutorial: Fine tuning Granite model with LoRA\\n\\n\\n\\n\\n\\n\\nRegularization\\n\\n\\n\\n\\nFoundation models\\n\\n\\n\\n\\nOverfitting\\n\\n\\n\\n\\nUnderfitting\\n\\n\\n\\n\\n\\nCaret right\\n\\nN-shot learning\\n\\n\\n\\n\\nFew shot learning\\n\\n\\n\\n\\nZero shot learning\\n\\n\\n\\n\\n\\n\\nKnowledge distillation \\n\\n\\n\\n\\nMeta learning\\n\\n\\n\\n\\nData augmentation\\n\\n\\n\\n\\n\\nCaret right\\n\\nContinual learning\\n\\n\\n\\n\\nCatastrophic forgetting\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nMachine learning libraries\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nScikit-learn\\n\\n\\n\\n\\nXGboost\\n\\n\\n\\n\\nPyTorch\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nMLOps\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nAI lifecyle\\n\\n\\n\\n\\nAI inference\\n\\n\\n\\n\\nModel deployment\\n\\n\\n\\n\\nMachine learning pipeline\\n\\n\\n\\n\\nData labeling\\n\\n\\n\\n\\n\\nCaret right\\n\\nModel governance\\n\\n\\n\\n\\nModel risk management\\n\\n\\n\\n\\nModel drift\\n\\n\\n\\n\\n\\n\\nAutoML\\n\\n\\n\\n\\nModel selection\\n\\n\\n\\n\\nFederated learning\\n\\n\\n\\n\\nDistributed machine learning\\n\\n\\n\\n\\nAI stack\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nNatural language processing\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nNatural language understanding\\n\\n\\n\\n\\n\\nCaret right\\n\\nText classification\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nSentiment analysis\\n\\n\\n\\n\\nTutorial: Spam text classifier with PyTorch \\n\\n\\n\\n\\n\\n\\nMachine translation\\n\\n\\n\\n\\n\\nCaret right\\n\\nText mining\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nInformation retrieval\\n\\n\\n\\n\\nInformation extraction\\n\\n\\n\\n\\nTopic modeling\\n\\n\\n\\n\\nLatent semantic analysis\\n\\n\\n\\n\\nLatent Dirichlet Allocation\\n\\n\\n\\n\\nNamed entity recognition\\n\\n\\n\\n\\n\\n\\nWord embeddings\\n\\n\\n\\n\\nBag of words\\n\\n\\n\\n\\nIntelligent search\\n\\n\\n\\n\\nSpeech recognition\\n\\n\\n\\n\\nStemming and lemmatization\\n\\n\\n\\n\\nText summarization\\n\\n\\n\\n\\nConversational AI\\n\\n\\n\\n\\nConversational analytics\\n\\n\\n\\n\\nNatural language generation\\n\\n\\n\\n\\n\\n\\n\\nCaret right\\n\\nComputer vision\\n\\n\\n\\n\\nOverview\\n\\n\\n\\n\\nImage classification\\n\\n\\n\\n\\nObject detection\\n\\n\\n\\n\\n\\nCaret right\\n\\nImage segmentation\\n\\n\\n\\n\\nInstance segmentation\\n\\n\\n\\n\\nSemantic segmentation\\n\\n\\n\\n\\n\\n\\nOptical character recognition\\n\\n\\n\\n\\nImage recognition\\n\\n\\n\\n\\nVisual inspection\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bs4 is used to parse and filter HTML content from web pages\n",
    "import bs4\n",
    "loader = WebBaseLoader(\n",
    "            web_path=\"https://www.ibm.com/think/topics/deep-learning#763338456\",\n",
    "            \n",
    "            # bs_kwargs allows passing arguments directly to BeautifulSoup\n",
    "            bs_kwargs=dict(parse_only = bs4.SoupStrainer(\n",
    "                # SoupStrainer is used to parse only specific HTML elements\n",
    "                # This improves performance and removes unwanted content\n",
    "                class_ = (\"side-nav list\",)\n",
    "                # bs4.SoupStrainer(\"p\")==>paragraphs only\n",
    "            )\n",
    "        ))\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465d49b",
   "metadata": {},
   "source": [
    "### **Wikipedia Loader**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a4a8a",
   "metadata": {},
   "source": [
    "**WIKIPEDIA LOADER (SINGLE QUERY)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b5f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'Virat Kohli', 'summary': \"Virat Kohli (born 5 November 1988) is an Indian international cricketer and the former all-format captain of the Indian national cricket team. He is a right-handed batter and occasional right-arm medium pace bowler. Considered one of the greatest all-format batsmen in the history of cricket, he has been nicknamed the King, the Chase Master, and the Run Machine for his skills, records and ability to lead his team to victory. Kohli has the most centuries in ODIs and the second-most centuries in international cricket with 85 tons across all formats. He is also the leading run-scorer in the Indian Premier League. Kohli is the most successful Test captain of India with most wins and 3 consecutive Test mace retainments. He is the only batter to earn 900+ rating points across all 3 formats.\\nKohli was the captain of the 2008 U19 World Cup winning team and was a crucial member of the teams that won 2011 ODI World Cup, 2013 Champions Trophy, 2024 T20 World Cup, and 2025 Champions Trophy. He plays for Royal Challengers Bengaluru in the Indian Premier League and for Delhi in domestic cricket. In 2013, Kohli was ranked number one in the ODI batting rankings. In 2015, he achieved the same in T20I. In 2018, he was ranked number one in Test, making him the only Indian to hold the number one spot in all three formats. He is the first player to score 20,000 runs in a decade. He was the Cricketer of the Decade for 2011 to 2020.\\nKohli has won ten ICC Awards, making him the most awarded player in international cricket history. He won the ODI Player of the Year award four times in 2012, 2017, 2018, and 2023. He won the Cricketer of the Year award, on two occasions, in 2017 and 2018. In 2018, he became the first player to win all three major awards including Cricketer of the Year, ODI Player of the Year and Test Player of the Year in the same year. He was honored with the Spirit of Cricket Award in 2019 and given the Cricketer of the Decade and ODI Cricketer of the Decade in 2020. Kohli was named the Wisden Leading Cricketer in the World for three consecutive years.\\nKohli has the most Player of the Series and second most Player of the Match awards to his name in all three formats combined. He was honoured with the Arjuna Award in 2013, the Padma Shri in 2017, and India's highest sporting honour, the Khel Ratna Award, in 2018. Time included him on its 100 most influential people in the world list in 2018. Kohli has been deemed one of the most commercially viable athletes, with estimated earnings of ₹634 crore (US$75 million) in the year 2022.\\nAfter winning the 2024 T20 World Cup and winning the Player of the Match award in the final, Kohli announced his retirement from T20Is. On 12 May 2025, aged 36, he announced his retirement from the Test format. He is married to actress Anushka Sharma, and they have two children named Vamika and Akaay Kohli.\", 'source': 'https://en.wikipedia.org/wiki/Virat_Kohli'}, page_content=\"Virat Kohli (born 5 November 1988) is an Indian international cricketer and the former all-format captain of the Indian national cricket team. He is a right-handed batter and occasional right-arm medium pace bowler. Considered one of the greatest all-format batsmen in the history of cricket, he has been nicknamed the King, the Chase Master, and the Run Machine for his skills, records and ability to lead his team to victory. Kohli has the most centuries in ODIs and the second-most centuries in international cricket with 85 tons across all formats. He is also the leading run-scorer in the Indian Premier League. Kohli is the most successful Test captain of India with most wins and 3 consecutive Test mace retainments. He is the only batter to earn 900+ rating points across all 3 formats.\\nKohli was the captain of the 2008 U19 World Cup winning team and was a crucial member of the teams that won 2011 ODI World Cup, 2013 Champions Trophy, 2024 T20 World Cup, and 2025 Champions Trophy. He plays for Royal Challengers Bengaluru in the Indian Premier League and for Delhi in domestic cricket. In 2013, Kohli was ranked number one in the ODI batting rankings. In 2015, he achieved the same in T20I. In 2018, he was ranked number one in Test, making him the only Indian to hold the number one spot in all three formats. He is the first player to score 20,000 runs in a decade. He was the Cricketer of the Decade for 2011 to 2020.\\nKohli has won ten ICC Awards, making him the most awarded player in international cricket history. He won the ODI Player of the Year award four times in 2012, 2017, 2018, and 2023. He won the Cricketer of the Year award, on two occasions, in 2017 and 2018. In 2018, he became the first player to win all three major awards including Cricketer of the Year, ODI Player of the Year and Test Player of the Year in the same year. He was honored with the Spirit of Cricket Award in 2019 and given the Cricketer of the Decade and ODI Cricketer of the Decade in 2020. Kohli was named the Wisden Leading Cricketer in the World for three consecutive years.\\nKohli has the most Player of the Series and second most Player of the Match awards to his name in all three formats combined. He was honoured with the Arjuna Award in 2013, the Padma Shri in 2017, and India's highest sporting honour, the Khel Ratna Award, in 2018. Time included him on its 100 most influential people in the world list in 2018. Kohli has been deemed one of the most commercially viable athletes, with estimated earnings of ₹634 crore (US$75 million) in the year 2022.\\nAfter winning the 2024 T20 World Cup and winning the Player of the Match award in the final, Kohli announced his retirement from T20Is. On 12 May 2025, aged 36, he announced his retirement from the Test format. He is married to actress Anushka Sharma, and they have two children named Vamika and Akaay Kohli.\\n\\n\\n== Early life ==\\nKohli was born on 5 November 1988 in New Delhi into a Punjabi Hindu family. His mother Saroj Kohli is a homemaker while his father Prem Nath Kohli worked as a criminal lawyer. He has an elder brother Vikas and an elder sister Bhawna. His formative years were spent in Uttam Nagar. His early education was at Vishal Bharti Public School. As per his family, Kohli exhibited an early affinity for cricket as a 3-year-old. He would pick up a bat and request his father bowl to him. In 1998, the West Delhi Cricket Academy was created. In May, his father arranged for him to meet Rajkumar Sharma. Upon the suggestion of their neighbours, Kohli's father considered enrolling his son in a professional cricket academy, as they believed his ability merited more than gully cricket.\\nKohli was unable to secure a place in the U-14 Delhi team, due to extraneous factors. His father reportedly received offers to relocate his son to influential clubs, which would ensure his selection, but he declined the proposals. Kohli eventually found his way into the U-15 team. He received training at the academy and participate\"),\n",
       " Document(metadata={'title': 'Career of Virat Kohli', 'summary': \"Virat Kohli's senior career began when he made his debut in List A cricket, playing against Services in the Ranji One-Day Trophy, but he did not have the opportunity to bat during the match. On the international stage, he has been representing India since he was included in the ODl squad for the tour of Sri Lanka. Kohli was part of the team during India won the 2011 Cricket World Cup, the 2013 ICC Champions Trophy, the 2024 ICC T20 World Cup and 2025 ICC Champions Trophy alongside several Asia Cups. He had previously led his side to the 2008 Under-19 Cricket World Cup title. In league cricket, Kohli has played for the Royal Challengers Bengaluru since the inception of the team in 2008 and was part of the team that won the 2025 season.\", 'source': 'https://en.wikipedia.org/wiki/Career_of_Virat_Kohli'}, page_content='Virat Kohli\\'s senior career began when he made his debut in List A cricket, playing against Services in the Ranji One-Day Trophy, but he did not have the opportunity to bat during the match. On the international stage, he has been representing India since he was included in the ODl squad for the tour of Sri Lanka. Kohli was part of the team during India won the 2011 Cricket World Cup, the 2013 ICC Champions Trophy, the 2024 ICC T20 World Cup and 2025 ICC Champions Trophy alongside several Asia Cups. He had previously led his side to the 2008 Under-19 Cricket World Cup title. In league cricket, Kohli has played for the Royal Challengers Bengaluru since the inception of the team in 2008 and was part of the team that won the 2025 season.\\n\\n\\n== International career ==\\n\\n\\n=== 2008–2009: Debut and maiden stint ===\\nIn August 2008, Kohli was included in the ODl squad for the tour of Sri Lanka and the Champions Trophy in Pakistan. Prior to the Sri Lankan tour, Kohli had limited experience, with only eight List A matches under his belt. So, his selection was considered a \"surprise call-up\". During the Sri Lankan tour, as both first-choice openers Sachin Tendulkar and Virender Sehwag, were unable to play due to injury, Kohli was required to fill the role of makeshift opener throughout the series. On August 18, 2008, Kohli made his international debut at the age of 19 in the first ODI of the tour, where he was dismissed for 12 runs, caught dead in front by an incutter from Nuwan Kulasekara. However, in the fourth match of the series, Kohli scored his maiden half century in the ODl format, with a total of fifty-four runs scored.\\nFollowing the postponement of the Champions Trophy to 2009, Kohli was picked as a replacement for the injured Shikhar Dhawan in the India A squad for the unofficial Tests against Australia A in September 2008. Despite limited opportunities, he managed to make an impact in the single innings that he participated in, scoring 49 runs. In October 2008, Kohli participated in a four-day tour match against Australia as part of the Indian Board President\\'s XI team. The match featured a formidable Australian bowling line-up that consisted of Brett Lee, Stuart Clark, Mitchell Johnson, Peter Siddle and Jason Krejza. Despite this, Kohli displayed his batting prowess by scoring 105 runs in the first innings and an unbeaten 16 runs in the second innings, demonstrating his ability to perform against high-level international competition.\\nIn November 2008, Kohli was selected for inclusion in the squad for the home ODI series against England. However, he was not given an opportunity to play in any of the matches. In December 2008, Kohli was awarded a Grade D contract by the Board of Control for Cricket in India (BCCI) as part of the annual contract list for the Indian national team which entitled him to receive ₹1.5 million (equivalent to ₹4.2 million or US$49,000 in 2023). Despite being awarded a contract, in January, Kohli was dropped for the five-match ODl series against Sri Lanka in Sri Lanka.\\nIn July–August 2009, Kohli was selected in the four-team Emerging Players Tournament, held in Australia. He was selected to open the innings for the Indian Emerging Players team in the tournament, and he went on to have a standout performance. Kohli finished as the tournament\\'s leading run-scorer, with a total of 398 runs from seven matches, at an average of 66.33. He was particularly impressive in the final match, where he scored 104 runs off 102 balls against the South Africa Emerging Players team in Brisbane. His strong performance helped lead his team to a 17-run victory and the tournament title. At the conclusion of the tournament, Kris Srikkanth, the chairman of the Indian national selection committee, expressed his admiration for Kohli\\'s performance during the tournament. Kohli later stated that this tournament was a \"turning point\" in his career.\\nIn August 2009, Kohli returned to the national team after recovering from a minor should'),\n",
       " Document(metadata={'title': 'List of international cricket centuries by Virat Kohli', 'summary': 'Virat Kohli is an Indian cricketer and a former captain of the Indian national cricket team. A right-handed top-order batsman, he has made 85 centuries in international cricket—30 in Test cricket, 54 in One Day Internationals (ODIs) and 1 in Twenty20 Internationals (T20Is).\\nKohli made his debut against Sri Lanka in August 2008, and scored his first century the following year when he made 107 against the same team at Eden Gardens, Kolkata. His 86-ball 133 not out against Sri Lanka in February 2012 led India to the second highest run-chase by any team in Australia. Former Australian cricketer Dean Jones described the innings as \"One of the greatest ODI knocks of all time!\". Kohli\\'s highest score of 183 came against Pakistan during the 2012 Asia Cup; India successfully chased a target of 330 set by Pakistan and Kohli was adjudged man of the match. Following that, he made his first century as a captain while playing against the West Indies in the 2013 Triangular Series. In the bilateral series against Australia in October 2013, Kohli made two centuries in successful run-chases. The first of the two, 100 not out, was scored off 52 balls and remains the fastest ODI century by an Indian. The next century, which was scored off 61 balls, remains the third-fastest by an Indian as of September 2019. In November 2023, he went past Sachin Tendulkar\\'s record for most ODI centuries when he made his 50th century in the format; he scored 117 against New Zealand in the 2023 Cricket World Cup semi-final.\\n\\nKohli made his Test debut against the West Indies in 2011 and scored his first century in the format during the Australian tour in January 2012. In the first Test of the 2014–15 Border–Gavaskar Trophy, he became the fourth Indian player to score centuries in both innings of a Test match after making 115 and 141. He was appointed as the captain of the Test team during the series and became the first player to score centuries in each of his first three Test innings as captain. In 2016, Kohli became the fifth player to score three or more double centuries in a calendar year. The following year, he repeated the feat and also became the first batsman to score four double centuries in consecutive Test series. His seven double centuries is the joint fourth-most by a player. In 2017, he became the first captain to score ten centuries in a calendar year. Following year, he scored eleven centuries, second-most in a calendar year to Tendulkar. In 2019, Kohli scored seven centuries which included five ODI-centuries. Moreover, he scored his highest score in Test-cricket against South Africa. In December 2022, Kohli scored a hundred against Bangladesh in the third ODI to surpass Ricky Ponting\\'s total of 71 centuries in international cricket.\\nKohli scored his only T20I hundred against Afghanistan at the 2022 Asia Cup. The following year, he scored 186 against Australia in the first innings of the fourth Test. He would score another century in the third innings of the first Test against Australia in November 2024; this would turn out to be his last Test century due to his retirement from the format in May 2025.', 'source': 'https://en.wikipedia.org/wiki/List_of_international_cricket_centuries_by_Virat_Kohli'}, page_content='Virat Kohli is an Indian cricketer and a former captain of the Indian national cricket team. A right-handed top-order batsman, he has made 85 centuries in international cricket—30 in Test cricket, 54 in One Day Internationals (ODIs) and 1 in Twenty20 Internationals (T20Is).\\nKohli made his debut against Sri Lanka in August 2008, and scored his first century the following year when he made 107 against the same team at Eden Gardens, Kolkata. His 86-ball 133 not out against Sri Lanka in February 2012 led India to the second highest run-chase by any team in Australia. Former Australian cricketer Dean Jones described the innings as \"One of the greatest ODI knocks of all time!\". Kohli\\'s highest score of 183 came against Pakistan during the 2012 Asia Cup; India successfully chased a target of 330 set by Pakistan and Kohli was adjudged man of the match. Following that, he made his first century as a captain while playing against the West Indies in the 2013 Triangular Series. In the bilateral series against Australia in October 2013, Kohli made two centuries in successful run-chases. The first of the two, 100 not out, was scored off 52 balls and remains the fastest ODI century by an Indian. The next century, which was scored off 61 balls, remains the third-fastest by an Indian as of September 2019. In November 2023, he went past Sachin Tendulkar\\'s record for most ODI centuries when he made his 50th century in the format; he scored 117 against New Zealand in the 2023 Cricket World Cup semi-final.\\n\\nKohli made his Test debut against the West Indies in 2011 and scored his first century in the format during the Australian tour in January 2012. In the first Test of the 2014–15 Border–Gavaskar Trophy, he became the fourth Indian player to score centuries in both innings of a Test match after making 115 and 141. He was appointed as the captain of the Test team during the series and became the first player to score centuries in each of his first three Test innings as captain. In 2016, Kohli became the fifth player to score three or more double centuries in a calendar year. The following year, he repeated the feat and also became the first batsman to score four double centuries in consecutive Test series. His seven double centuries is the joint fourth-most by a player. In 2017, he became the first captain to score ten centuries in a calendar year. Following year, he scored eleven centuries, second-most in a calendar year to Tendulkar. In 2019, Kohli scored seven centuries which included five ODI-centuries. Moreover, he scored his highest score in Test-cricket against South Africa. In December 2022, Kohli scored a hundred against Bangladesh in the third ODI to surpass Ricky Ponting\\'s total of 71 centuries in international cricket.\\nKohli scored his only T20I hundred against Afghanistan at the 2022 Asia Cup. The following year, he scored 186 against Australia in the first innings of the fourth Test. He would score another century in the third innings of the first Test against Australia in November 2024; this would turn out to be his last Test century due to his retirement from the format in May 2025.\\n\\n\\n== Key ==\\n\\n\\n== Test cricket centuries ==\\n\\n\\n== One Day International centuries ==\\n\\n\\n== Twenty20 International centuries ==\\n\\n\\n== Footnotes ==\\n\\n\\n== References ==\\n\\n\\n== Bibliography ==\\nMemon, Ayaz; Rao, C. Rajshekar (2013). Virat Kohli: Reliable Rebel. Jaico Publishing House. ISBN 978-81-8495-524-8.'),\n",
       " Document(metadata={'title': 'Anushka Sharma', 'summary': \"Anushka Sharma (pronounced [əˈnʊʃka ˈʃərma]; born 1 May 1988) is an Indian actress who works in Hindi films. She has won many awards including Filmfare Awards and IIFA Awards. Sharma has appeared in Forbes India's Celebrity 100 in the 2010s and was featured by Forbes Asia in their 30 Under 30 list of 2018.\\nBorn in Ayodhya and raised in Bangalore, Sharma had her first modelling assignment for the fashion designer Wendell Rodricks in 2007 and later moved to Mumbai to pursue a full-time career as a model. She made her acting debut opposite Shah Rukh Khan in the top-grossing romantic film Rab Ne Bana Di Jodi (2008) and rose to prominence with starring roles in Yash Raj Films' romances Band Baaja Baaraat (2010) and Jab Tak Hai Jaan (2012), winning the Filmfare Award for Best Supporting Actress for the latter. Sharma went on to earn praise for playing strong-willed women in the crime thriller NH10 (2015), and the dramas Dil Dhadakne Do (2015), Ae Dil Hai Mushkil (2016), and Sui Dhaaga (2018). Her highest-grossing releases came with the sports drama Sultan (2016), and Rajkumar Hirani's films PK (2014) and Sanju (2018). The poorly received Zero (2018) was followed by a hiatus from acting.\\nSharma was the co-founder of the production company Clean Slate Filmz, under which she produced films and series such as NH10, Paatal Lok (2020) and Bulbbul (2020). She is the ambassador for brands and products, has designed her own line of clothing for women, named Nush, and supports charities and causes, including gender equality and animal rights. Sharma is married to cricketer Virat Kohli with whom she has two children.\", 'source': 'https://en.wikipedia.org/wiki/Anushka_Sharma'}, page_content='Anushka Sharma (pronounced [əˈnʊʃka ˈʃərma]; born 1 May 1988) is an Indian actress who works in Hindi films. She has won many awards including Filmfare Awards and IIFA Awards. Sharma has appeared in Forbes India\\'s Celebrity 100 in the 2010s and was featured by Forbes Asia in their 30 Under 30 list of 2018.\\nBorn in Ayodhya and raised in Bangalore, Sharma had her first modelling assignment for the fashion designer Wendell Rodricks in 2007 and later moved to Mumbai to pursue a full-time career as a model. She made her acting debut opposite Shah Rukh Khan in the top-grossing romantic film Rab Ne Bana Di Jodi (2008) and rose to prominence with starring roles in Yash Raj Films\\' romances Band Baaja Baaraat (2010) and Jab Tak Hai Jaan (2012), winning the Filmfare Award for Best Supporting Actress for the latter. Sharma went on to earn praise for playing strong-willed women in the crime thriller NH10 (2015), and the dramas Dil Dhadakne Do (2015), Ae Dil Hai Mushkil (2016), and Sui Dhaaga (2018). Her highest-grossing releases came with the sports drama Sultan (2016), and Rajkumar Hirani\\'s films PK (2014) and Sanju (2018). The poorly received Zero (2018) was followed by a hiatus from acting.\\nSharma was the co-founder of the production company Clean Slate Filmz, under which she produced films and series such as NH10, Paatal Lok (2020) and Bulbbul (2020). She is the ambassador for brands and products, has designed her own line of clothing for women, named Nush, and supports charities and causes, including gender equality and animal rights. Sharma is married to cricketer Virat Kohli with whom she has two children.\\n\\n\\n== Early life and work ==\\nSharma was born on 1 May 1988 in Ayodhya, Uttar Pradesh. Her father, Colonel Ajay Kumar Sharma, is an army officer, and her mother, Ashima Sharma, is a homemaker. Her father is a native of Uttar Pradesh, while her mother is a Garhwali. Her elder brother is film producer Karnesh Sharma, who earlier served in the Merchant Navy. \\nSharma has stated that being a military brat played an important role in shaping her as a person and contributing to her life. In an interview with The Times of India in 2012, she said, \"I take pride in saying that I am an army officer\\'s daughter even more than being an actor.\"\\nSharma was raised in Bangalore. But she did her primary schooling at St. Mary\\'s School, Margherita, Assam. Sakshi Dhoni, the wife of M.S. Dhoni, was her classmate in that school. She completed her schooling at Army School, Bangalore. She then did her graduation in arts from Mount Carmel College, Bangalore.\\nSharma originally intended to pursue a career in modelling or journalism and had no aspirations to be an actress. After graduation, Sharma moved to Mumbai to further her modelling career. She enrolled herself at the Elite Model Management, and was groomed by the style consultant Prasad Bidapa. In 2007, Sharma made her runway debut at the Lakme Fashion Week for designer Wendell Rodricks\\'s Les Vamps Show and was picked to be his finale model at the Spring Summer 2007 Collection. Since then she has done campaigns for the brands Silk & Shine, Whisper, Nathella Jewelry and Fiat Palio. Sharma later said, \"I think I was born to emote and act. I would walk down the ramp and smile and they used to say, \\'give us a blank look.\\' It was really difficult, not to smile\". Whilst modelling, Sharma also joined an acting school and began auditioning for film roles.\\n\\n\\n== Career ==\\n\\n\\n=== Breakthrough (2008–2013) ===\\nSharma made her acting debut in Aditya Chopra\\'s romantic drama Rab Ne Bana Di Jodi (2008), opposite Shah Rukh Khan. She took a day to prepare for her screen test at the Yash Raj Films studio and refused to do an impromptu one. She was signed for a three-film deal with the company and landed the leading role of Tani Sahni, a young bride to a middle-aged man, portrayed by Khan. Khalid Mohamed of Hindustan Times found her to be \"assured and upright\" in the film, but Nikhat Kazmi thought that she \"lacks all chutzpah a'),\n",
       " Document(metadata={'title': 'Royal Challengers Bengaluru', 'summary': \"Royal Challengers Bengaluru, formerly Royal Challengers Bangalore, also known as RCB, are a professional Twenty20 cricket team based in Bengaluru, Karnataka, that competes in the Indian Premier League (IPL). Founded in 2008 by United Spirits, the team's home ground is M. Chinnaswamy Stadium. They won their first title in 2025. The team finished as the runners-up on three occasions: in 2009, 2011, and 2016. They have also qualified for the playoffs in ten of the eighteen seasons.\\nAs of 2025, the team is captained by Rajat Patidar and coached by Andy Flower. The franchise has competed in the Champions League, finishing as runners-up in the 2011 season. As of 2024, RCB was valued at $117 million, making it one of the most valuable franchises.\", 'source': 'https://en.wikipedia.org/wiki/Royal_Challengers_Bengaluru'}, page_content='Royal Challengers Bengaluru, formerly Royal Challengers Bangalore, also known as RCB, are a professional Twenty20 cricket team based in Bengaluru, Karnataka, that competes in the Indian Premier League (IPL). Founded in 2008 by United Spirits, the team\\'s home ground is M. Chinnaswamy Stadium. They won their first title in 2025. The team finished as the runners-up on three occasions: in 2009, 2011, and 2016. They have also qualified for the playoffs in ten of the eighteen seasons.\\nAs of 2025, the team is captained by Rajat Patidar and coached by Andy Flower. The franchise has competed in the Champions League, finishing as runners-up in the 2011 season. As of 2024, RCB was valued at $117 million, making it one of the most valuable franchises.\\n\\n\\n== History ==\\n\\n\\n=== 2008–2010: Initial seasons ===\\n\\nIn September 2007, the Board of Control for Cricket in India announced the establishment of the Indian Premier League (IPL) a Twenty20 competition set to begin in 2008. On 24 January 2008, an auction was held in Mumbai for the league\\'s teams, which represented eight different cities in India, including Bengaluru. The Bangalore franchise was acquired by Vijay Mallya for US$111.6 million, making it the second-highest bid, slightly less than Reliance Industries\\' US$111.9 million bid for the Mumbai Indians.\\n\\nAhead of the 2008 player auction, the IPL designated Rahul Dravid as the icon player for the Bangalore franchise. This designation ensured that Dravid would be paid 15% more than the highest bid player at the auction. The franchise acquired several prominent Indian and international players, including Jacques Kallis, Anil Kumble, Zaheer Khan, Mark Boucher, Dale Steyn, and Cameron White. In the second round of the auction, they also signed Ross Taylor, Misbah-ul-Haq, and India under-19 World Cup-winning captain Virat Kohli.  The franchise named Dravid as the captain of the team and appointed Venkatesh Prasad as the head coach. The team struggled in the inaugural season, winning only four out of their 14 matches and finishing seventh in the eight-team table. Dravid was the sole player to score more than 300 runs in the tournament, and the team even had to bench their most expensive foreign player, Kallis, for several matches due to his poor form. Midway through the season, the string of failures led to the sacking of CEO Charu Sharma, who was replaced by Brijesh Patel. Mallya publicly criticised Dravid and Sharma for their selection of players at the auction, stating that his \"biggest mistake was to abstain from the selection of the team.\" Eventually, the chief cricketing officer of the franchise, Martin Crowe, resigned and Prasad was replaced by Ray Jennings as the head coach.\\nAt the 2009 player auction, the franchise signed Kevin Pietersen for a record US$1.55 million, making him the most expensive player alongside Andrew Flintoff (Chennai Super Kings). They also traded Zaheer Khan for Robin Uthappa with the Mumbai Indians and brought in local batsman Manish Pandey. Due to general elections in India, the tournament was held in South Africa. Pietersen was named captain, but after a string of initial losses, Anil Kumble took over the captaincy when Pietersen left for national duty. RCB\\'s performance improved under Kumble, winning six of their last eight matches to finish third in the league table. They defeated Chennai Super Kings in the semi-final but fell short by six runs in the final against Deccan Chargers.\\n\\nIn 2010, the Royal Challengers, under Kumble\\'s captaincy, secured seven wins from 14 matches, accumulating 14 points. Tied with three other teams for a playoff spot, their superior net run rate qualified them for the semi-finals. In the semi-final, they were defeated by the table-toppers, the Mumbai Indians, by 35 runs. However, the Royal Challengers secured a convincing nine-wicket win over the defending champions, the Deccan Chargers, in the third-place playoff, thus qualifying for the 2010 Champions League Twenty20. Kumble retir'),\n",
       " Document(metadata={'title': 'KL Rahul', 'summary': 'Kannaur Lokesh Rahul (Kannada: [kaɳːuːɾ loːkeːʃ ɾaːhul]; born 18 April 1992) is an Indian international cricketer. He plays for the Indian national team as a right-handed wicket-keeper batter. Rahul represents Karnataka in domestic cricket and Delhi Capitals in the Indian Premier League.\\nRahul made his international debut in 2014 against Australia in the Boxing Day Test in Melbourne. Two years after his Test debut, Rahul made his One-Day International debut in 2016 against Zimbabwe, where he scored his first century by hitting a six on the last ball to reach 100* (115) from 94 (114), which was also the only six of the entire match. Rahul is the first and only Indian cricketer to score an ODI century on his debut. On the same tour, he made his T20I debut.', 'source': 'https://en.wikipedia.org/wiki/KL_Rahul'}, page_content=\"Kannaur Lokesh Rahul (Kannada: [kaɳːuːɾ loːkeːʃ ɾaːhul]; born 18 April 1992) is an Indian international cricketer. He plays for the Indian national team as a right-handed wicket-keeper batter. Rahul represents Karnataka in domestic cricket and Delhi Capitals in the Indian Premier League.\\nRahul made his international debut in 2014 against Australia in the Boxing Day Test in Melbourne. Two years after his Test debut, Rahul made his One-Day International debut in 2016 against Zimbabwe, where he scored his first century by hitting a six on the last ball to reach 100* (115) from 94 (114), which was also the only six of the entire match. Rahul is the first and only Indian cricketer to score an ODI century on his debut. On the same tour, he made his T20I debut.\\n\\n\\n== Early and personal life ==\\nRahul was born on 18 April 1992 to K. N. Lokesh and Rajeshwari in Bangalore, Karnataka in a Kannada-speaking family. His father Lokesh, who hails from Kannanur in Magadi, is a professor and former director at the National Institute of Technology Karnataka (NITK) in Mangalore. His mother, Rajeshwari, is a professor at Mangalore University. His father was a fan of cricketer Sunil Gavaskar and wanted to name his own son after Gavaskar's son but mistook Rohan Gavaskar's name for Rahul. \\n\\nRahul grew up in Surathkal, Mangalore, completing his High School at NITK English Medium School and PUC at St. Aloysius College. He started cricket training at the age of 10, and, two years later, started playing matches for both Bangalore United Cricket Club and his club in Mangalore. At age 18, he moved to Bangalore to study at Jain University and pursue his cricket career.\\nOn 23 January 2023, Rahul married his long-time girlfriend, actress Athiya Shetty daughter of actor Sunil Shetty, after dating for more than three years. Shetty gave birth to a girl, on 24 March 2025.\\n\\n\\n== Domestic career ==\\nRahul made his first-class cricket debut for Karnataka in the 2010–11 season. In the same season, he represented his country at the 2010 ICC Under-19 Cricket World Cup, scoring 143 runs in the competition. He made his debut in the Indian Premier League in 2013, for Royal Challengers Bangalore. During the 2013–14 domestic season he scored 1,033 first-class runs, the second highest scorer that season.\\nPlaying for South Zone in the final of the 2014–15 Duleep Trophy against Central Zone, Rahul scored 185 off 233 balls in the first innings and 130 off 152 in the second. He was named the player of the match and selected to the Indian Test squad for the Australian tour followed.\\nReturning home after the Test series, Rahul became Karnataka's first triple-centurion, scoring 337 against Uttar Pradesh. He went on to score 188 in the 2014–15 Ranji Trophy final against Tamil Nadu and finished the season with an average of 93.11 in the nine matches he played.\\nIn January 2026, Rahul returned to represent Karnataka in the Vijay Hazare Trophy after a six-year gap, having last appeared in the tournament in 2019.\\n\\n\\n== International career ==\\n\\n\\n=== Debut and early career (2014–2021) ===\\nRahul made his Test debut in the 2014 Boxing Day Test at the Melbourne Cricket Ground. He replaced Rohit Sharma and was presented with his Test cap by MS Dhoni. He managed to score only 3 and 1 on his debut. In the next test at Sydney where he opened the innings for the first time, and made his maiden international century, scoring 110 runs.\\n\\nHe was named in the 15-man squad for the Indian tour of Bangladesh in June 2015 but withdrew due to dengue. He returned to the side for the first Test of the Sri Lankan tour after Murali Vijay was ruled out due to injury, scoring his second Test century and winning the Man of the Match award. During the match, he kept wicket after Wriddhiman Saha was injured.\\nIn July 2016, Rahul was named in the squad for India tour of West Indies. In the second series test, Rahul scored 158 runs, his then-highest score in test cricket. In September 2016, he was named in the squad for the\"),\n",
       " Document(metadata={'title': 'WHOOP', 'summary': 'WHOOP, Inc.  (stylized as WHOOP) is an American wearable technology company headquartered in Boston, Massachusetts. Its principal product is a health tracker that measures strain, recovery, and sleep. The device is best known for its use by athletes and is often used to track overall health and detect illness.\\nThe Whoop band is popular among consumers and professional athletes such as Cristiano Ronaldo, Virat Kohli, Rory McIlroy, Aryna Sabalenka, LeBron James and Michael Phelps.', 'source': 'https://en.wikipedia.org/wiki/WHOOP'}, page_content=\"WHOOP, Inc.  (stylized as WHOOP) is an American wearable technology company headquartered in Boston, Massachusetts. Its principal product is a health tracker that measures strain, recovery, and sleep. The device is best known for its use by athletes and is often used to track overall health and detect illness.\\nThe Whoop band is popular among consumers and professional athletes such as Cristiano Ronaldo, Virat Kohli, Rory McIlroy, Aryna Sabalenka, LeBron James and Michael Phelps.\\n\\n\\n== Product ==\\nWHOOP 1.0 was released in 2015, followed by versions in 2016 and 2019. WHOOP 4.0 debuted in 2021 with improved battery technology that increased capacity.\\nThe device collects data on sleep, heart rate variability, resting heart rate, and respiratory rate to create a daily recovery score ranging from 0% to 100%, helping users determine if their body is ready for exertion or needs rest. It also provides suggested exertion goals based on recovery and sleep data.\\nOn March 29, 2023, WHOOP announced its Stress Monitor feature, tracking daily stress levels via HRV and resting heart rate, with breathwork interventions developed with Dr. Andrew Huberman. In September 2023, WHOOP released “WHOOP Coach,” powered by OpenAI, offering conversational health and fitness coaching.\\nIn 2025, WHOOP shared that the FDA comments on its blood pressure feature, arguing the agency was “overstepping its authority.” In May 2025, WHOOP adjusted its upgrade terms for the 5.0 and MG, eventually providing complimentary upgrades for members with 12+ months remaining and refunds for those charged in error.\\nIn September 2025, WHOOP launched “Advanced Labs,” integrating clinical blood test data with wearable health metrics and expanding availability internationally.\\nWHOOP differs from other wearables by having no screen or buttons; all data is accessed through the WHOOP app on Android and iOS. It requires a monthly subscription, and without one, the device stops tracking. According to Time, WHOOP collects significantly more data than competitors, with five sensors gathering 100 MB of data per user per day.\\n\\n\\n== History ==\\nWHOOP was founded in 2012 by Harvard student-athlete Will Ahmed, together with John Capodilupo and Aurelian Nicolae. The company was incubated at the Harvard Innovation Labs. The name “Whoop” originated as a motivational phrase Ahmed used before games.\\nIn August 2021, WHOOP raised $200 million from SoftBank at a valuation of $3.6 billion. Additional investors include IVP, the NFL Players Association, and athletes such as Kevin Durant, Patrick Mahomes, Rory McIlroy, Eli Manning, and Larry Fitzgerald.\\nAs of 2022, Ahmed serves as CEO, Nicolae is Director of Mechanical Engineering, and Capodilupo served as CTO until April 2022.\\n\\n\\n== Sports ==\\nWHOOP is approved by multiple professional sports organizations including CrossFit, the Ladies Professional Golf Association, Major League Baseball, the National Football League Players Association, the Women's Tennis Association and the PGA Tour.\\nThe device is widely used by elite athletes such as Virat Kohli, Michael Phelps,  LeBron James,  and  Rory McIlroy, Nelly Korda, Tiger Woods, Justin Thomas,\\n\\nIn 2017, several NBA players were reported to have worn WHOOP devices during games despite league restrictions.\\nIn 2023, cricketer Virat Kohli prominently wore WHOOP during the ICC Men’s Cricket World Cup, influencing widespread adoption across cricket. In May 2024, Cristiano Ronaldo became both an investor and ambassador for WHOOP.\\n\\n\\n== COVID-19 ==\\nIn 2020, WHOOP played a key role in early COVID-19 detection. PGA Tour golfer Nick Watney noticed a respiratory rate spike on his WHOOP and tested positive for the virus despite no symptoms, prompting a PGA Tour partnership to supply WHOOP devices to players and caddies. Another golfer, Scott Stallings, also identified early signs of infection using WHOOP.\\nWHOOP later partnered with Central Queensland University researchers to validate its virus detection algorithm, which ide\"),\n",
       " Document(metadata={'title': 'Rohit Sharma', 'summary': \"Rohit Gurunath Sharma (born 30 April 1987) is an Indian international cricketer and the former captain of the India national cricket team in all formats of the game. He is a right-handed top-order batter. He represents Mumbai in domestic cricket and Mumbai Indians in the Indian Premier League. Sharma was a member of the teams that won the 2007 T20 World Cup, the 2013 ICC Champions Trophy and was the winning captain of the 2024 T20 World Cup and the 2025 ICC Champions Trophy.\\nSharma holds several batting records which include most runs in T20 Internationals, most sixes in international cricket, most double centuries in ODI cricket (3), most centuries at Cricket World Cups (7) and joint most hundreds in Twenty20 Internationals (5). He also holds the world record for the highest individual score (264) in a One Day International (ODI) and also holds the record for scoring most hundreds (five) in a single Cricket World Cup, for which he won the ICC Men's ODI Cricketer of the Year award in 2019. He is the first and only captain to lead a team in all ICC tournament finals.\\nHe formerly captained Mumbai Indians and the team has won five Indian Premier League titles in 2013, 2015, 2017, 2019 and 2020 under him, making him the most successful captain in IPL history, sharing this record with MS Dhoni. He is also one of two players who have played in every edition of the T20 World Cup, from the inaugural edition in 2007 till 2024. He is the only Indian player to win two T20 World Cups. He became the second Indian captain to win a T20 World Cup.\\nHe has received two national honours, the Arjuna Award in 2015 and the prestigious Khel Ratna Award in 2020 by the Government of India. Under his captaincy, India won the 2018 Asia Cup and the 2023 Asia Cup, the seventh and eighth time the country won the title, both in ODI format as well as the 2018 Nidahas Trophy, their second overall and first in T20I format.\", 'source': 'https://en.wikipedia.org/wiki/Rohit_Sharma'}, page_content='Rohit Gurunath Sharma (born 30 April 1987) is an Indian international cricketer and the former captain of the India national cricket team in all formats of the game. He is a right-handed top-order batter. He represents Mumbai in domestic cricket and Mumbai Indians in the Indian Premier League. Sharma was a member of the teams that won the 2007 T20 World Cup, the 2013 ICC Champions Trophy and was the winning captain of the 2024 T20 World Cup and the 2025 ICC Champions Trophy.\\nSharma holds several batting records which include most runs in T20 Internationals, most sixes in international cricket, most double centuries in ODI cricket (3), most centuries at Cricket World Cups (7) and joint most hundreds in Twenty20 Internationals (5). He also holds the world record for the highest individual score (264) in a One Day International (ODI) and also holds the record for scoring most hundreds (five) in a single Cricket World Cup, for which he won the ICC Men\\'s ODI Cricketer of the Year award in 2019. He is the first and only captain to lead a team in all ICC tournament finals.\\nHe formerly captained Mumbai Indians and the team has won five Indian Premier League titles in 2013, 2015, 2017, 2019 and 2020 under him, making him the most successful captain in IPL history, sharing this record with MS Dhoni. He is also one of two players who have played in every edition of the T20 World Cup, from the inaugural edition in 2007 till 2024. He is the only Indian player to win two T20 World Cups. He became the second Indian captain to win a T20 World Cup.\\nHe has received two national honours, the Arjuna Award in 2015 and the prestigious Khel Ratna Award in 2020 by the Government of India. Under his captaincy, India won the 2018 Asia Cup and the 2023 Asia Cup, the seventh and eighth time the country won the title, both in ODI format as well as the 2018 Nidahas Trophy, their second overall and first in T20I format.\\n\\n\\n== Early life ==\\nSharma was born on 30 April 1987 into a Marathi-Telugu family in Bansod, Nagpur, Maharashtra, India. His mother, Purnima Sharma, is from Visakhapatnam, Andhra Pradesh. His father, Gurunath Sharma, worked as a caretaker of a transport firm storehouse. Sharma was raised by his grandparents and uncles in Borivali because of his father\\'s low income. He would visit his parents, who lived in a single-room house in Dombivli, only during weekends. He has a younger brother, Vishal Sharma.\\nSharma joined a cricket camp in 1999 with his uncle\\'s money. Dinesh Lad, his coach at the camp, asked him to change his school to Swami Vivekanand International School, where Lad was the coach and the cricket facilities were better than those at Sharma\\'s old school. Sharma recollects, \"I told him I couldn\\'t afford it, but he got me a scholarship. So for four years I didn\\'t pay a penny, and did well in my cricket\". Sharma started as an off-spinner who could bat a bit before Lad noticed his batting ability and promoted him from number eight to open the innings. He excelled in the Harris and Giles Shield school cricket tournaments, scoring a century on debut as an opener.\\n\\n\\n== Personal life ==\\n\\nSharma married his longtime girlfriend, Ritika Sajdeh on 13 December 2015 whom he first met in 2008. They welcomed their first child, a daughter born on 30 December 2018. Their second child, a son,  was born on 15 November 2024. Sharma is a practitioner of the meditation technique Sahaj Marg.\\n\\n\\n=== Commercial endorsements ===\\nSharma has been sponsored by several brands including CEAT and the Swiss watchmaker Hublot. In his career, Sharma has endorsed many other brands including Maggi, Glow & Lovely, Lay\\'s, Nissan, energy drink Relentless, Nasivion nasal spray, Aristocrat by VIP Industries, Adidas and Oppo mobiles.\\n\\n\\n== Youth career ==\\nSharma made his List A debut for West Zone against Central Zone in the Deodhar Trophy at Gwalior in March 2005. Batting at number eight, he scored 31 not out as West Zone won by 3 wickets with 24 balls remaining. Cheteshwar Pujar'),\n",
       " Document(metadata={'title': 'India–Pakistan cricket rivalry', 'summary': \"The India–Pakistan cricket rivalry is one of the most intense sports rivalries in the world. Matches between the teams are considered some of the biggest in the world and are among the most-viewed in all of sports.\\nThe two teams have played a total of 211 times, with Pakistan winning 88 matches and India winning 80. In Tests and ODIs, Pakistan has been victorious in more games than India, while India has won more games in T20Is. In ICC World Cups, the two sides have met head to head in 16 matches, with India winning 15 of them. Both India and Pakistan have won the ICC Cricket World Cup, the ICC T20 World Cup, as well as other prestigious tournaments. In fact, India has won seven ICC trophies, while Pakistan has won three ICC trophies.\\nThe tense relations between the two nations, resulting from bitter diplomatic relations and conflict that originated during the Partition of British India into India and Pakistan in 1947, the Indo-Pakistani Wars, and the Kashmir conflict, laid the foundations for the emergence of a fierce sporting rivalry between the two nations who had shared a common cricketing heritage.\\nThe two sides first played in 1952, when Pakistan toured India. Since then numerous Test series and, later, One Day International (ODI) series have been played, although a number of planned tours by both sides have been cancelled or aborted due to political factors. No cricket was played between the two countries from 1962 to 1977 due to two major wars in 1965 and 1971, and the 1999 Kargil War and the 2008 Mumbai terrorist attacks also interrupted cricketing ties between the two nations.\\nIn the 1980s and 1990s, the growth of large expatriate populations from both countries across the world led to neutral venues to host bilateral and multilateral ODI series featuring the two teams. In addition, there has always been high demand for tickets for the matches between the two in global ICC competitions, with over 800,000 ticket applications made for their meeting in the 2019 ICC Cricket World Cup; the television transmission of the match was watched by 273 million viewers.\\nPlayers from both teams routinely face extreme pressure to win and are threatened by extreme reactions in defeat. Extreme fan reactions to defeats in key matches have been recorded, with a limited degree of hooliganism. At the same time, India–Pakistan matches have also offered opportunities for cricket diplomacy as a means to improve relations between the two countries, allowing heads of state and cricket followers from either country to travel to the other to watch the matches.\\nThe last full bilateral tour between the teams was Pakistan's tour of India in 2007, where both Test and ODI series were played. However, following the 2008 terror attacks in Mumbai, orchestrated by Pakistan based terror group Lashkar-e-Taiba, India suspended the planned 2009 series and all future engagements with Pakistan. The attack eventually led to detrimental consequences for both nations, in diplomacy and cricket. Since then, as both teams only meet in ICC or ACC tournaments and with India emerging as the winner on most occasions, the rivalry in cricketing sense has faded to an extent, prompting Indian Captain Suryakumar Yadav to say it isn't a rivalry anymore.\", 'source': 'https://en.wikipedia.org/wiki/India%E2%80%93Pakistan_cricket_rivalry'}, page_content=\"The India–Pakistan cricket rivalry is one of the most intense sports rivalries in the world. Matches between the teams are considered some of the biggest in the world and are among the most-viewed in all of sports.\\nThe two teams have played a total of 211 times, with Pakistan winning 88 matches and India winning 80. In Tests and ODIs, Pakistan has been victorious in more games than India, while India has won more games in T20Is. In ICC World Cups, the two sides have met head to head in 16 matches, with India winning 15 of them. Both India and Pakistan have won the ICC Cricket World Cup, the ICC T20 World Cup, as well as other prestigious tournaments. In fact, India has won seven ICC trophies, while Pakistan has won three ICC trophies.\\nThe tense relations between the two nations, resulting from bitter diplomatic relations and conflict that originated during the Partition of British India into India and Pakistan in 1947, the Indo-Pakistani Wars, and the Kashmir conflict, laid the foundations for the emergence of a fierce sporting rivalry between the two nations who had shared a common cricketing heritage.\\nThe two sides first played in 1952, when Pakistan toured India. Since then numerous Test series and, later, One Day International (ODI) series have been played, although a number of planned tours by both sides have been cancelled or aborted due to political factors. No cricket was played between the two countries from 1962 to 1977 due to two major wars in 1965 and 1971, and the 1999 Kargil War and the 2008 Mumbai terrorist attacks also interrupted cricketing ties between the two nations.\\nIn the 1980s and 1990s, the growth of large expatriate populations from both countries across the world led to neutral venues to host bilateral and multilateral ODI series featuring the two teams. In addition, there has always been high demand for tickets for the matches between the two in global ICC competitions, with over 800,000 ticket applications made for their meeting in the 2019 ICC Cricket World Cup; the television transmission of the match was watched by 273 million viewers.\\nPlayers from both teams routinely face extreme pressure to win and are threatened by extreme reactions in defeat. Extreme fan reactions to defeats in key matches have been recorded, with a limited degree of hooliganism. At the same time, India–Pakistan matches have also offered opportunities for cricket diplomacy as a means to improve relations between the two countries, allowing heads of state and cricket followers from either country to travel to the other to watch the matches.\\nThe last full bilateral tour between the teams was Pakistan's tour of India in 2007, where both Test and ODI series were played. However, following the 2008 terror attacks in Mumbai, orchestrated by Pakistan based terror group Lashkar-e-Taiba, India suspended the planned 2009 series and all future engagements with Pakistan. The attack eventually led to detrimental consequences for both nations, in diplomacy and cricket. Since then, as both teams only meet in ICC or ACC tournaments and with India emerging as the winner on most occasions, the rivalry in cricketing sense has faded to an extent, prompting Indian Captain Suryakumar Yadav to say it isn't a rivalry anymore.\\n\\n\\n== History ==\\n\\nThe Partition of British India in 1947 that led to the creation of independent Indian and Pakistani states was characterised by bloody conflict between ethnic groups that left one million people dead and led to the mass-migration of an estimated ten million people between either nation. The legacy of Partition and subsequent territorial disputes have helped create heated rivalries in field hockey, association football, and especially in cricket, which had been developed during British colonial rule and is the most popular sport in both nations.\\n\\nPakistan became a member of the Imperial Cricket Conference (now the International Cricket Council) in 1948, becoming a Full Member in July 1952. Their tour of India l\"),\n",
       " Document(metadata={'title': 'Indian cricket team in Australia in 2024–25', 'summary': 'The Indian cricket team toured Australia from November 2024 to January 2025 to play five Test matches and three first-class warm-up matches against the Australian cricket team. The Test matches formed part of the 2023–2025 ICC World Test Championship. In March 2024, the Cricket Australia (CA) announced the venues for the Test series. It was the first Test series between India and Australia comprising five matches since 1992. On 26 March 2024, the CA confirmed the full tour itinerary.\\nIndia had retained the Border–Gavaskar Trophy after defeating Australia 2–1 in the previous series in 2023. However, this time Australia won the series by 3–1 to win the trophy for the first time since 2014-15.\\nThis was also the last Test series of Ravichandran Ashwin, Rohit Sharma and Virat Kohli before their Test retirements.', 'source': 'https://en.wikipedia.org/wiki/Indian_cricket_team_in_Australia_in_2024%E2%80%9325'}, page_content='The Indian cricket team toured Australia from November 2024 to January 2025 to play five Test matches and three first-class warm-up matches against the Australian cricket team. The Test matches formed part of the 2023–2025 ICC World Test Championship. In March 2024, the Cricket Australia (CA) announced the venues for the Test series. It was the first Test series between India and Australia comprising five matches since 1992. On 26 March 2024, the CA confirmed the full tour itinerary.\\nIndia had retained the Border–Gavaskar Trophy after defeating Australia 2–1 in the previous series in 2023. However, this time Australia won the series by 3–1 to win the trophy for the first time since 2014-15.\\nThis was also the last Test series of Ravichandran Ashwin, Rohit Sharma and Virat Kohli before their Test retirements.\\n\\n\\n== Venues ==\\nCricket Australia announced their summer cricket schedule in March 2024. The series was played at the main cricket grounds in Australia\\'s five largest cities. It was the first five-match test series to be played between the two nations since India\\'s tour of Australia in 1991/92.\\n\\n\\n== Squads ==\\n\\nIndia named an 18-member squad for the test series along with Mukesh Kumar, Navdeep Saini and Khaleel Ahmed as travelling reserves.\\nOn 17 November, Shubman Gill was ruled out of the first Test with a fractured thumb of his left hand, during the intra-squad training match at the WACA. On 20 November, Devdutt Padikkal, who was a part of the India A squad and was asked to stay back as cover with a few injury scares due to several batsmen getting blows during the practice match with India A, was added to the main squad. Additionally, Yash Dayal was added to the list of travelling reserves as a replacement for the injured Khaleel Ahmed.\\nOn 27 November, Beau Webster was added to the Australian squad as cover for the possible unavailability of Mitchell Marsh due to injury. On 30 November, Sean Abbott and Brendan Doggett were added into the Australian squad for the second Test as injury replacement for Josh Hazlewood who was ruled out due to side strain.\\nOn 17 December, Josh Hazlewood was ruled out of the rest of the series after he suffered a calf strain on the fourth day of the 3rd Test.\\nOn 18 December, following the 3rd Test, Ravichandran Ashwin announced his retirement from international cricket. On 23 December, Tanush Kotian was added into the squad.\\nOn 20 December, Nathan McSweeney was dropped from the squad for the last two Tests with Jhye Richardson and Sam Konstas added to the squad.\\nOn 29 December, Josh Inglis was ruled out from the squad for the last Test due to calf strain.\\n\\n\\n== Tour matches ==\\n\\n\\n=== Squads ===\\n\\nThe tour was kickstarted by India A touring Australia from 31 October to 10 November, ending just 5 days before the official Test series starts. Cricket Australia announced their Australia A squad in early October 2024, naming Nathan McSweeney as their captain. Board of Control for Cricket in India announced India A cricket team\\'s squad in October 2024, naming Ruturaj Gaikwad as the side\\'s captain along with Abhimanyu Easwaran as the vice-captain.\\nIndia \\'A\\' played two games against Australia \\'A\\'. The first of those matches was played at the Great Barrier Reef Arena from 31 October to 3 November while the second was played at the Melbourne Cricket Ground from 7 to 10 November. The first Test was played at the new Perth Stadium from 22 November.\\nWhile announcing the international schedule, Peter Roach, CA\\'s head of Cricket Operations and Scheduling, had said in May: \"The 2024–25 summer is highlighted by the five-Test Border–Gavaskar series, the first five-Test series between the two giants in more than 30 years. To have that running simultaneously with the women\\'s ODIs and preceded by two significant Australia A v India A matches will be terrific for our fans.\"\\nPrior to the start of the series, Mark Steketee and his replacement Liam Hatcher were both ruled out due to injury and were replaced by Brendan Dogget'),\n",
       " Document(metadata={'title': '2025 ICC Champions Trophy', 'summary': \"The 2025 ICC Champions Trophy was the ninth edition of the ICC Champions Trophy. It was hosted by Pakistan Cricket Board from 19 February to 9 March 2025 and featured 15 matches held across three venues in Pakistan and one in the United Arab Emirates.\\nThe tournament was contested by the top eight ranked men's national teams qualified from the 2023 World Cup. Afghanistan made their debut appearance in the tournament.\\nHosts Pakistan were the defending champions and were eliminated in the group stage. India became the champions by defeating New Zealand in the final and also became the first team to win three Champions Trophy titles.\", 'source': 'https://en.wikipedia.org/wiki/2025_ICC_Champions_Trophy'}, page_content=\"The 2025 ICC Champions Trophy was the ninth edition of the ICC Champions Trophy. It was hosted by Pakistan Cricket Board from 19 February to 9 March 2025 and featured 15 matches held across three venues in Pakistan and one in the United Arab Emirates.\\nThe tournament was contested by the top eight ranked men's national teams qualified from the 2023 World Cup. Afghanistan made their debut appearance in the tournament.\\nHosts Pakistan were the defending champions and were eliminated in the group stage. India became the champions by defeating New Zealand in the final and also became the first team to win three Champions Trophy titles.\\n\\n\\n== Background ==\\nThe ICC Champions Trophy is a quadrennial ODI cricket tournament organised by the International Cricket Council (ICC). Initially held as a biennial tournament since its inaugural edition in 1998 as ICC KnockOut Trophy, it was rebranded as ICC Champions Trophy in 2002 and has been held as a quadrennial tournament since 2009. In 2016, the ICC cancelled future editions of the Champions Trophy after the 2017 tournament, aiming to have only one major tournament in each format of international cricket. However in November 2021 as part of the 2024–2031 ICC men's hosts cycle, ICC announced that the tournament would return from 2025 onwards.\\n\\n\\n=== Host selection ===\\nPakistan was announced as the host of the 2025 ICC Champions Trophy on 16 November 2021 as part of the 2024–2031 ICC men's hosts cycle. It is the first global tournament to be hosted by Pakistan after almost 29 years, since the 2009 attack on the Sri Lankan team. The last major tournament to take place in the country was the 1996 Cricket World Cup which it co-hosted with India and Sri Lanka. United Arab Emirates was announced as a neutral venue for Indian Cricket Team matches due to India's refusal to play in Pakistan.\\n\\n\\n=== Format ===\\nThe format of the competition had remained the same as it was since eight teams were introduced in the fray back in 2006. All eight teams were slotted into two groups of four, with each team playing once against every other team in the group. The top two teams from each group advanced to the knockout stage, featuring two semi-finals leading up to the final.\\n\\n\\n=== India's participation ===\\n\\nThe India–Pakistan cricket rivalry has been severely impacted by the tense political relations between the two nations. In November 2023, the Pakistan Cricket Board (PCB) met with the ICC Executive Board to discuss compensation if India refused to play in Pakistan. A year later, the Board of Control for Cricket in India (BCCI) informed the ICC that India wouldn't travel to Pakistan for the tournament, citing security concerns. Pakistan demanded a written explanation and initially rejected the proposed hybrid model.\\n\\n\\n==== Neutral venue arrangements ====\\nOn 19 December 2024, following an agreement between BCCI and PCB, the ICC in an update issued on India and Pakistan hosted matches at ICC events, established that the ICC Champions Trophy 2025 will be played across Pakistan and a neutral venue. The ICC board confirmed that India and Pakistan matches hosted by either country at ICC events between 2024 and 2027 would be played at a neutral venue. The fixtures were announced on 24 December 2024, along with the Dubai International Cricket Stadium in Dubai, UAE as the neutral venue for the tournament.\\n\\n\\n=== Prize money ===\\nThe ICC allocated a pool of US$6.9 million in prize money for the tournament, a 53 percent increase from the previous edition. The winners would receive the grand prize of $2.24 million, with each team receiving an additional $125,000 for participating.\\n\\n\\n=== Marketing ===\\nOn 13 November 2024, the ICC launched a new visual identity for the Champions Trophy with the release of a brand launch video, as the event returned for the first time since 2017. On 14 November 2024, The PCB announced the schedule for trophy tour in the region of Pakistan-administered Kashmir. The PCB's plan to take the trophy to \"),\n",
       " Document(metadata={'title': 'Shubman Gill', 'summary': \"Shubman Gill (born 8 September 1999) is an Indian international cricketer who plays for the India national team. Gill captains the Test and the ODI side. He has also captained the team in T20I. A right-handed batsman, Gill represents Punjab in domestic cricket and captains the Gujarat Titans in the Indian Premier League.\\nIn ODI cricket, he is the fastest player to reach 2000 runs in 38 innings and 2500 runs in 50 innings. He also holds the record for the youngest cricketer to score a double century in ODIs at the age of 23. With his country, he won the 2025 ICC Champions Trophy as vice captain. He made his List-A debut against Vidarbha in 2017 and first-class debut for Punjab against Bengal in the 2017–18 Ranji Trophy, scoring a half-century in the game, and 129 runs in the last match against Services.\\nAs vice-captain of the Indian under-19 team, Gill scored 372 runs at an average of 124.00 in the 2018 Under-19 Cricket World Cup, where he played a crucial role in India's fourth title win, earning the edition's Player of the Tournament award. His unbeaten 102 in the semi-final against Pakistan U-19 drew praise from batting greats such as Rahul Dravid, Sachin Tendulkar, VVS Laxman, and Sourav Ganguly.\\nShubman Gill was named ICC Men’s Player of the Month four times — in January 2023, September 2023, February 2025, and July 2025. He is also the first male player to win the award four times. He was also named in the ICC Men’s ODI Team of the Year in 2023.\", 'source': 'https://en.wikipedia.org/wiki/Shubman_Gill'}, page_content=\"Shubman Gill (born 8 September 1999) is an Indian international cricketer who plays for the India national team. Gill captains the Test and the ODI side. He has also captained the team in T20I. A right-handed batsman, Gill represents Punjab in domestic cricket and captains the Gujarat Titans in the Indian Premier League.\\nIn ODI cricket, he is the fastest player to reach 2000 runs in 38 innings and 2500 runs in 50 innings. He also holds the record for the youngest cricketer to score a double century in ODIs at the age of 23. With his country, he won the 2025 ICC Champions Trophy as vice captain. He made his List-A debut against Vidarbha in 2017 and first-class debut for Punjab against Bengal in the 2017–18 Ranji Trophy, scoring a half-century in the game, and 129 runs in the last match against Services.\\nAs vice-captain of the Indian under-19 team, Gill scored 372 runs at an average of 124.00 in the 2018 Under-19 Cricket World Cup, where he played a crucial role in India's fourth title win, earning the edition's Player of the Tournament award. His unbeaten 102 in the semi-final against Pakistan U-19 drew praise from batting greats such as Rahul Dravid, Sachin Tendulkar, VVS Laxman, and Sourav Ganguly.\\nShubman Gill was named ICC Men’s Player of the Month four times — in January 2023, September 2023, February 2025, and July 2025. He is also the first male player to win the award four times. He was also named in the ICC Men’s ODI Team of the Year in 2023.\\n\\n\\n== Early life ==\\nGill was born on 8 September 1999 into a Punjabi Sikh family in village Chak Jaimal Singh Wala of Fazilka district, Punjab, India. His father, Lakhwinder Singh, is a farmer who aspired to become a cricketer. He has an twin sister named Shahneel Gill. He showed early promise in cricket, picking up a bat at the age of three. Recognising his interest in the game, Lakhwinder decided to train him, bowling 500 to 700 balls to him daily. In 2007, he moved the family to Mohali, near the Punjab Cricket Association Stadium, to facilitate better training opportunities for Gill.\\nAt the age of twelve, Gill's performance caught the attention of former Indian bowler Karsan Ghavri, who recommended that Gill attend the Under-19 all-India pace bowlers' camp. Gill faced U-19 bowlers in the nets, leading Ghavri to request PCA to put him into Punjab's U-14 team. He is a friend of Abhishek Sharma since childhood and they used to open the innings for Punjab in the under-14s. In an Inter-District Under-16 match against Amritsar, Gill, representing Mohali, scored 351 runs and shared a record opening stand of 587 runs with Nirmal Singh. At the age of 14, he scored a double-century on his Under-16 debut for Punjab in the Vijay Merchant Trophy.\\n\\n\\n== Domestic career ==\\nGill made his List A debut for Punjab in the 2016–17 Vijay Hazare Trophy on 25 February 2017 against Vidharbha, during which he scored 11 runs before being run out. In his second match against Assam, he scored his maiden List A century, scoring 121 runs off 129 balls. His first-class debut came against Bengal in the 2017–18 Ranji Trophy on 17 November 2017. Later in the same month, in his second first-class match, he scored his maiden century while batting for Punjab against Services. He scored 129 runs off 142 balls.\\nIn October 2018, Gill was named in India C's squad for  the 2018–19 Deodhar Trophy. In the final round-robin match against India A, he scored an unbeaten century, helping send India C through to the final. The following month, he was named as one of the eight players to watch ahead of the 2018–19 Ranji Trophy by ESPNcricinfo. In December 2018, during the match against Tamil Nadu in the Ranji Trophy, Gill scored his maiden double century in first-class cricket, scoring 268 runs. On 25 December 2018, on the fourth day of the match against Hyderabad in the Ranji Trophy, with Punjab needing 338 runs from 57 overs, Gill scored 148 off 154 balls, almost single-handedly taking his side to victory. The match finished as\"),\n",
       " Document(metadata={'title': '2025 Indian Premier League final', 'summary': 'The 2025 Indian Premier League final was a Twenty20 (T20) cricket match played at the Narendra Modi Stadium, Ahmedabad, on 3 June 2025 to determine the winner of the 2025 Indian Premier League. It was originally scheduled to be played at Eden Gardens, Kolkata, on 25 May 2025 before being rescheduled.\\nAfter winning the toss, Punjab Kings elected to field. Royal Challengers Bengaluru (RCB) came in to bat, and scored 190/9 in 20 overs. Punjab Kings were restricted to 184/7 in their 20 overs; thus, RCB won the match by 6 runs and won their maiden Indian Premier League (IPL) trophy after 18 years.', 'source': 'https://en.wikipedia.org/wiki/2025_Indian_Premier_League_final'}, page_content=\"The 2025 Indian Premier League final was a Twenty20 (T20) cricket match played at the Narendra Modi Stadium, Ahmedabad, on 3 June 2025 to determine the winner of the 2025 Indian Premier League. It was originally scheduled to be played at Eden Gardens, Kolkata, on 25 May 2025 before being rescheduled.\\nAfter winning the toss, Punjab Kings elected to field. Royal Challengers Bengaluru (RCB) came in to bat, and scored 190/9 in 20 overs. Punjab Kings were restricted to 184/7 in their 20 overs; thus, RCB won the match by 6 runs and won their maiden Indian Premier League (IPL) trophy after 18 years.\\n\\n\\n== Background ==\\n\\nThe 2025 Indian Premier League is the 18th edition of the Indian Premier League, a franchise Twenty20 cricket league held in India, organized by the Board of Control for Cricket in India (BCCI). It is held annually since the first edition in 2008. On 16 February, the fixtures for the season were confirmed with the 2025 season set to commence from 22 March with 10 teams competing in 74 matches across 13 venues, concluding with the final at the Eden Gardens on 25 May with the venue to host its third IPL final after 2013 and 2015.\\nOn 9 May 2025, the remaining matches were suspended due to the 2025 India–Pakistan crisis. The revised schedule was announced on 12 May, and the remaining matches resumed on 17 May and were held across six venues. On 20 May the playoff fixtures were confirmed with final rescheduled for 3 June at the Narendra Modi Stadium with the venue hosting its third final after 2022 and 2023.\\nRoyal Challengers Bengaluru qualified for their fourth IPL final after being runners-up in 2009, 2011 and 2016 while Punjab Kings qualified for their second IPL final after being runners-up in 2014. Both teams were competing for their maiden titles.\\n\\n\\n== Road to the final ==\\n\\nRoyal Challengers Bengaluru ranked second in the league stage with 9 wins, 4 losses and an abandoned match garnering a total of 19 points. They defeated Punjab Kings in the Qualifier 1 to gain their place in the final.\\nPunjab Kings ranked first in the league stage with 9 wins, 4 losses and an abandoned match garnering a total of 19 points. They lost the Qualifier 1 to Royal Challengers Bengaluru and had to defeat Mumbai Indians in Qualifier 2 for a place in the final.\\n\\nSource: ESPNcricinfo\\n\\n\\n== Closing ceremony ==\\nDuring the closing ceremony, Shankar Mahadevan along with his sons and other artists performed a musical tribute to the Indian armed forces. Dancers performed on the song Teri Mitti (sung by B Praak). Aircraft were also seen releasing tri-colour smoke trails in the sky as a tribute to the Indian Armed Forces following the success of Operation Sindoor.\\n\\n\\n== Match ==\\n\\n\\n=== Match officials ===\\nSource:\\n\\nOn-field umpires: Jayaraman Madanagopal (Ind) and Nitin Menon (Ind)\\nThird umpire: Chris Gaffaney (NZ)\\nReserve umpire: K. N. Ananthapadmanabhan (Ind)\\nMatch referee: Javagal Srinath (Ind)\\n\\n\\n=== Team and toss ===\\nPunjab Kings captain Shreyas Iyer won the toss and elected to field first. Both teams were unchanged from their previous matches.\\n\\n\\n=== Royal Challengers Bengaluru innings ===\\nRoyal Challengers Bengaluru had a poor start to the innings as they lost their opener Phil Salt to Kyle Jamieson in the second over. As, Mayank Agarwal joined Virat Kohli in the middle he made 24 runs before being dismissed by Chahal. Later, Rajat Patidar and Kohli tried to stabilize the innings but Patidar was dismissed by Jamieson on 26. As Jitesh Sharma joined Kohli both took the score to 131 but Kohli's innings was cut short when he got dismissed by Omarzai on 43 leaving them on 131 off 4. Liam Livingstone and Jitesh Sharma quickly spearheaded the innings and made 25 and 24 respectively but were dismissed early by Vyshak and Jamieson respectively. As Bengaluru were 171 off 6 in 17.4, Romario Shepherd came and made a quick short score of 17 off 9 balls before being dismissed and thus, taking the total score tally to 190 off 9. Arshdeep Singh and Jamieson got 3 w\"),\n",
       " Document(metadata={'title': \"2024 Men's T20 World Cup final\", 'summary': \"The 2024 ICC Men's T20 World Cup final was a Twenty20 International (T20I) cricket match played at Kensington Oval in Bridgetown, Barbados on 29 June 2024 to determine the winner of the 2024 ICC Men's T20 World Cup. It was played between South Africa and India.\\nIndia won the toss and electing to bat first, they registered a score of 176/7. In the second innings, South Africa managed to post a score of 169/8 thus India claimed the victory by 7 runs to win their second T20 World Cup title. Virat Kohli was named Player of the Match for scoring 76 runs off 59 balls. Following the victory, Kohli, Indian captain Rohit Sharma and Ravindra Jadeja announced their retirement from T20I cricket.\", 'source': 'https://en.wikipedia.org/wiki/2024_Men%27s_T20_World_Cup_final'}, page_content=\"The 2024 ICC Men's T20 World Cup final was a Twenty20 International (T20I) cricket match played at Kensington Oval in Bridgetown, Barbados on 29 June 2024 to determine the winner of the 2024 ICC Men's T20 World Cup. It was played between South Africa and India.\\nIndia won the toss and electing to bat first, they registered a score of 176/7. In the second innings, South Africa managed to post a score of 169/8 thus India claimed the victory by 7 runs to win their second T20 World Cup title. Virat Kohli was named Player of the Match for scoring 76 runs off 59 balls. Following the victory, Kohli, Indian captain Rohit Sharma and Ravindra Jadeja announced their retirement from T20I cricket.\\n\\n\\n== Background ==\\n\\nThe 2024 ICC Men's T20 World Cup was the ninth edition of the ICC Men's T20 World Cup, a biennial world cup for cricket in Twenty20 International (T20I) format, organized by the International Cricket Council (ICC). In November 2021 as part of the 2024-2031 ICC men's hosts cycle, the ICC announced that the 2024 ICC Men's T20 World Cup would be played in the United States and the West Indies.\\nOn 22 September 2023, the ICC released the venues that would host matches across the tournament, with the Kensington Oval in Barbados named as the venue for the final. On 5 January 2024, the ICC announced the tournament's schedule, with the final scheduled on 29 June. This was the second T20 World Cup final played at the stadium, after the 2010 final.\\nThis was South Africa's maiden T20 World Cup final, while it was India's third final, having been champions in 2007 and runners-up in 2014. Both teams qualified for the final unbeaten, with neither of them losing a group stage, Super 8 or semi-final. Before this match, India and South Africa had played each other six times in the ICC Men's T20 World Cup, with India recording four wins (2007, 2010, 2012 and 2014) and South Africa winning two (2009 and 2022).\\n\\n\\n== Road to the final ==\\n\\n\\n=== Overview ===\\nSource: ESPNcricinfo\\n\\n\\n=== South Africa ===\\nSouth Africa began their T20 World Cup campaign with a victory over Sri Lanka at Nassau County International Cricket Stadium in New York, and went on to defeat Netherlands and Bangladesh at the same venue. After defeating Nepal at Arnos Vale, they finished the group stage as Group D winners. In the Super 8 stage, they defeated co-hosts United States at Sir Vivian Richards Stadium in North Sound, defending champions England at Daren Sammy Cricket Ground in Gros Islet, and former champions and co-hosts West Indies at North Sound, finishing as winners of Group 2.\\nSouth Africa then defeated Afghanistan in the semi-final at the Brian Lara Cricket Academy in San Fernando, Trinidad and Tobago to earn their place at their maiden T20 World Cup final.\\n\\n\\n=== India ===\\nIndia began their T20 World Cup campaign with a victory over Ireland at Nassau County International Cricket Stadium, and went on to defeat Pakistan and co-hosts United States at the same venue. Their match with Canada was abandoned for heavy rainfall at the Central Broward Park in Florida, and India finished the group stage as winners of Group A. In the Super 8 stage, they defeated Afghanistan at Kensington Oval in Barbados, Bangladesh in North Sound, and Australia in Gros Islet, finishing as winners of Group 1.\\nIndia then defeated defending champions England in the semi-final at the Providence Stadium in Guyana to earn their place at the T20 World Cup final for the third time.\\n\\n\\n== Match ==\\n\\n\\n=== Match officials ===\\nOn 28 June 2024, the International Cricket Council (ICC) named New Zealand's Chris Gaffaney and England's Richard Illingworth as the on-field umpires, along with England's Richard Kettleborough as the third umpire, Australia's Rod Tucker as the reserve umpire, and West Indies' Richie Richardson as match referee.\\n\\nOn-field umpires: Chris Gaffaney (NZ) and Richard Illingworth (Eng)\\nTV umpire: Richard Kettleborough (Eng)\\nReserve umpire: Rod Tucker (Aus)\\nMatch referee: Richie Richardson (WI)\\n\"),\n",
       " Document(metadata={'title': 'Babar Azam', 'summary': 'Mohammad Babar Azam (Urdu, Punjabi: محمد بابر اعظم; pronounced [muhamməd babəɾ azəm]; born 15 October 1994) is a Pakistani international cricketer and a former captain of the Pakistan national team in all three formats of the game. A right-handed top-order batter, he captains Peshawar Zalmi in the Pakistan Super League. Azam was a member of the Pakistan team that won the 2017 ICC Champions Trophy.', 'source': 'https://en.wikipedia.org/wiki/Babar_Azam'}, page_content=\"Mohammad Babar Azam (Urdu, Punjabi: محمد بابر اعظم; pronounced [muhamməd babəɾ azəm]; born 15 October 1994) is a Pakistani international cricketer and a former captain of the Pakistan national team in all three formats of the game. A right-handed top-order batter, he captains Peshawar Zalmi in the Pakistan Super League. Azam was a member of the Pakistan team that won the 2017 ICC Champions Trophy.\\n\\n\\n== Early life ==\\nBabar Azam was born on 15 October 1994 into a Punjabi Kamboh family in the Walled City of Lahore. His father Mohammad Azam Siddiqui owned a small watch repair shop while his mother is a housewife. He is the eldest of three siblings Safeer Azam, Faisal Azam and Fariya Azam. His older first cousins (through his elder paternal uncle) Kamran and Umar Akmal were the reason he was attracted to cricket, and their stories inspired him to take up cricket as his profession. He had been a ball boy at Gaddafi Stadium before joining a cricket academy and starting his domestic cricket career there.\\nHe sought guidance from Rana Sadiq, his first coach, who taught him the fundamentals of batting. Later, he went on to be a part of the Pakistan under-19 setup.\\n\\n\\n== International career ==\\n\\n\\n=== Early career ===\\nOn 31 May 2015, Azam was included in the Pakistan ODI squad for the home series against Zimbabwe. He made his ODI debut in the third ODI on 31 May and scored an impressive fifty scoring 54 runs off 60 balls. His impressive debut earned him a place in both Test and ODI squads selected for an away series against Sri Lanka. He was not selected to play in the Test series. During the ODI series, he only scored 37 runs in the two matches that he played. Azam was included in the squad for the away ODI series against Zimbabwe in September 2015.\\nHe was retained in the One Day squad for the home series against England. In the first ODI of the four match series he scored 62 not out with a strike rate of 100. He had scores of 4, 22 and 51 in next three matches respectively. He finished the series with 139 runs at an average of 46.33.\\nIn January 2016, Pakistan visited New Zealand. In the first ODI match, Azam scored 62 runs off 76 balls. Pakistan lost the match by 70 runs. He was the leading run scorer in the ODI series with 145 runs in 2 innings at an average of 72.50.\\nIn the five-match ODI series against England in July, he batted in five games and only scored 122 runs. He made his Twenty20 International debut for Pakistan against England on 7 September. He scored an unbeaten 15 runs off 11 balls. Pakistan won the match and series.\\nBesides the England series, Pakistan played two match ODI series against Ireland. In the first ODI of the series, Pakistan beat Ireland by 255 runs and created record of their biggest win in terms of runs in an ODI.  Azam contributed in his side's victory by scoring 29 runs. With the second and final ODI abandoned due to rain, Pakistan won the series 1–0.\\n\\n\\n=== Rise in shorter formats and breaking records ===\\n\\nAzam was selected in the home series against the West Indies in 2016. In the first match of the ODI series he scored his maiden international century, scoring 120 off 131 balls and earning his first man of the Match award. In the second ODI, he scored another century, this time scoring 123 off 126 balls, and contributing to Pakistan's total of over 330 runs. In the third and final ODI of the series Azam scored a third consecutive century (117 from 106). He also set the record for most runs (360) in a three match ODI series. He became the only batsman to score 350+ runs in a three match ODI series.\\nHe made his Test debut for Pakistan against the West Indies in Dubai on 13 October 2016 and scored 69 runs in his first innings. He was the first player to score a fifty on his Test debut through a day/night Test.\\nOn 19 January 2017, in the third ODI against Australia, Azam became then joint-fastest player to score 1,000 runs in ODIs and then fastest for Pakistan in his 21st innings before his record was later \"),\n",
       " Document(metadata={'title': 'New Zealand cricket team in India in 2025–26', 'summary': \"The New Zealand cricket team is touring India in January 2026 to play the India cricket team. The tour consists of three One Day International (ODI) and five Twenty20 Internationals (T20I) matches. The T20I series will form part of both teams' preparation ahead of the 2026 Men's T20 World Cup tournament. In June 2025, the Board of Control for Cricket in India (BCCI) confirmed the fixtures for the tour, as a part of the 2025–26 home international season.\\nAs a result of the 3rd ODI, New Zealand won their first ODI series in Indian soil.\", 'source': 'https://en.wikipedia.org/wiki/New_Zealand_cricket_team_in_India_in_2025%E2%80%9326'}, page_content=\"The New Zealand cricket team is touring India in January 2026 to play the India cricket team. The tour consists of three One Day International (ODI) and five Twenty20 Internationals (T20I) matches. The T20I series will form part of both teams' preparation ahead of the 2026 Men's T20 World Cup tournament. In June 2025, the Board of Control for Cricket in India (BCCI) confirmed the fixtures for the tour, as a part of the 2025–26 home international season.\\nAs a result of the 3rd ODI, New Zealand won their first ODI series in Indian soil.\\n\\n\\n== Squads ==\\n\\nOn 11 January, Rishabh Pant was ruled out of the ODI series due to injury, and Dhruv Jurel was named as his replacement. On 12 January, Washington Sundar was ruled out of the remainder of ODI series due to left lower rib injury, and Ayush Badoni was named as his replacement. On 16 January, Washington Sundar was ruled out of the T20I series due to injuries, and Ravi Bishnoi and Shreyas Iyer were added into the squad as replacements.\\n\\n\\n== ODI series ==\\n\\n\\n=== 1st ODI ===\\n\\n\\n=== 2nd ODI ===\\n\\n\\n=== 3rd ODI ===\\n\\n\\n== T20I series ==\\n\\n\\n=== 1st T20I ===\\n\\n\\n=== 2nd T20I ===\\n\\n\\n=== 3rd T20I ===\\n\\n\\n=== 4th T20I ===\\n\\n\\n=== 5th T20I ===\\n\\n\\n== Notes ==\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nSeries home at ESPNcricinfo\"),\n",
       " Document(metadata={'title': 'Kolkata Knight Riders', 'summary': \"The Kolkata Knight Riders, also known as KKR, are  a professional Twenty20 cricket team based in Kolkata, West Bengal, that competes in the Indian Premier League (IPL). The franchise is owned by actor Shah Rukh Khan, actress Juhi Chawla, and her spouse Jay Mehta. Their home ground is Eden Gardens.\\nThe franchise, which has gained immense popularity due to its association with celebrity owners, qualified for the IPL playoffs for the first time in 2011. They became the IPL champions in 2012, by defeating Chennai Super Kings in the final. They repeated the feat in 2014, defeating Kings XI Punjab. In 2024, they won the title for the third time by beating Sunrisers Hyderabad. The Knight Riders hold the record for the longest winning streak by any IPL team (14).\\nThe side's all-time leading run-scorer is Gautam Gambhir, while their leading wicket-taker is Sunil Narine. The official motto of the team is Korbo, Lorbo, Jeetbo (Perform, Fight, Win) and the official colours are purple and gold.\", 'source': 'https://en.wikipedia.org/wiki/Kolkata_Knight_Riders'}, page_content='The Kolkata Knight Riders, also known as KKR, are  a professional Twenty20 cricket team based in Kolkata, West Bengal, that competes in the Indian Premier League (IPL). The franchise is owned by actor Shah Rukh Khan, actress Juhi Chawla, and her spouse Jay Mehta. Their home ground is Eden Gardens.\\nThe franchise, which has gained immense popularity due to its association with celebrity owners, qualified for the IPL playoffs for the first time in 2011. They became the IPL champions in 2012, by defeating Chennai Super Kings in the final. They repeated the feat in 2014, defeating Kings XI Punjab. In 2024, they won the title for the third time by beating Sunrisers Hyderabad. The Knight Riders hold the record for the longest winning streak by any IPL team (14).\\nThe side\\'s all-time leading run-scorer is Gautam Gambhir, while their leading wicket-taker is Sunil Narine. The official motto of the team is Korbo, Lorbo, Jeetbo (Perform, Fight, Win) and the official colours are purple and gold.\\n\\n\\n== Franchise history ==\\n\\nIn 2007, the Board of Control for Cricket in India (BCCI) created the cricket tournament Indian Premier League, based on the Twenty20 format of the game. Eight teams participated in the inaugural tournament held in April – June 2008. The teams representing the eight different cities of India were put up on auction in Mumbai on 20 February 2008. The team representing Kolkata was eventually bought by Bollywood superstar Shah Rukh Khan\\'s company Red Chillies Entertainment in partnership with actress Juhi Chawla and her husband Jay Mehta for a price of $75.09 million, equal to approximately ₹2.98 billion at that time. Sourav Ganguly, a native of West Bengal and former captain of the Indian national team, was named the Icon player for the team. The name of the team is a reference to the popular 1980s American television series Knight Rider.\\n\\n\\n== Valuation ==\\nAccording to Forbes in 2022, Kolkata Knight Riders were the third most valuable team in the IPL behind MI and CSK with a valuation of $1.1 billion.\\n\\n\\n== Livery ==\\nInitially, when the Kolkata Knight Riders were first introduced in 2008, the logo of the team consisted of a blazing golden Viking helmet against a black background with the name of the team written in gold next to it. However, the black background was changed to purple in the third season. It was in 2012 that the current logo, which has a blazing purple Corinthian helmet trimmed with gold, with Kolkata Knight Riders written within a shield, was introduced.\\nThe tagline of the team was \"All the King\\'s Men\" during the first four seasons. However, in the fifth it was replaced by \"New Dawn, New Knights\". The team\\'s official colours were black and gold during the first two seasons. At the time, Khan said that \"golden symbolizes spirit of life and black presents the Goddess Kali.\" It was later changed to purple and gold during the third season and was kept so. The jersey was created by Bollywood fashion designer Manish Malhotra.\\nThe main theme of the team, Korbo, Lorbo, Jeetbo Re (we will act, fight, and win!), was scored by Vishal–Shekhar duo. A Knight Riders album featuring several singers and music composers, including Usha Uthup and Bappi Lahiri, was also created.\\n\\n\\n== Rivalries ==\\n\\nThe Knight Riders have historically been a successful franchise in the IPL. This success has led them to have many rivalries with other teams.\\n\\n\\n=== Mumbai Indians ===\\nBoth teams play in major markets, with Mumbai Indians based in Mumbai and Kolkata Knight Riders based in Kolkata. Mumbai Indians is the most successful IPL franchise with five championships. However, until Mumbai\\'s third championship, both teams were tied with two championships each. In the first two seasons of the IPL, Mumbai swept Kolkata in all four games. It wasn\\'t until the 2010 IPL season that Kolkata won against Mumbai. Both sides have been captained by Indian cricket legends at one point (Mumbai was captained by Sachin Tendulkar and Kolkata was captained by Sourav '),\n",
       " Document(metadata={'title': 'India national cricket team', 'summary': \"The India men's national cricket team represents India in international cricket. It is governed by the Board of Control for Cricket in India (BCCI) and is a full member nation of the International Cricket Council with Test, One Day International and Twenty20 International status. India are the current holders of the T20 World Cup, the ICC Champions Trophy and the Asia Cup.\\nThe team has played 598 Test matches, winning 185, losing 188, with 224 draws and 1 tie. As of August 2025, India is ranked fourth in the ICC Men's Test Team Rankings with 107 rating points. India have played in two of the three World Test Championship finals, finishing runners-up in 2021 and 2023.\\nThe Indian team has played 1,075 ODI matches, winning 571, losing 450, tying 10 and with 44 ending in a no-result. As of September 2025, India is ranked first in the ICC Men's ODI Team Rankings with 124 rating points. India have appeared in the World Cup final four times and have won the title twice. They have also won the Champions Trophy a record three times.\\nThe national team has played 263 Twenty20 International matches, winning 175, losing 73, tying 7 and with 8 ending in a no-result. As of August 2025, India is ranked first in the ICC Men's T20I Team Rankings with 271 rating points and also won the T20 World Cup twice.\", 'source': 'https://en.wikipedia.org/wiki/India_national_cricket_team'}, page_content=\"The India men's national cricket team represents India in international cricket. It is governed by the Board of Control for Cricket in India (BCCI) and is a full member nation of the International Cricket Council with Test, One Day International and Twenty20 International status. India are the current holders of the T20 World Cup, the ICC Champions Trophy and the Asia Cup.\\nThe team has played 598 Test matches, winning 185, losing 188, with 224 draws and 1 tie. As of August 2025, India is ranked fourth in the ICC Men's Test Team Rankings with 107 rating points. India have played in two of the three World Test Championship finals, finishing runners-up in 2021 and 2023.\\nThe Indian team has played 1,075 ODI matches, winning 571, losing 450, tying 10 and with 44 ending in a no-result. As of September 2025, India is ranked first in the ICC Men's ODI Team Rankings with 124 rating points. India have appeared in the World Cup final four times and have won the title twice. They have also won the Champions Trophy a record three times.\\nThe national team has played 263 Twenty20 International matches, winning 175, losing 73, tying 7 and with 8 ending in a no-result. As of August 2025, India is ranked first in the ICC Men's T20I Team Rankings with 271 rating points and also won the T20 World Cup twice.\\n\\n\\n== History ==\\n\\n\\n=== Early history (1700s–1918) ===\\n\\nThe British first brought cricket to India in the early 1700s, with the first cricket match played in 1721. It was played and adopted by Kolis of Gujarat who were sea pirates and outlaws who often looted the British ships. The East India Company tried to manage the Kolis through cricket and were successful. In 1848, the Parsi community in Mumbai formed the Oriental Cricket Club, the first cricket club to be established by Indians. After slow beginnings, the Europeans eventually invited the Parsis to play a match in 1877. By 1912, the Parsis, Hindus, Sikhs and Muslims of Bombay played a quadrangular tournament with the Europeans every year. In the early 1900s, some Indians went on to play for the England cricket team. Some of these, such as Ranjitsinhji and Duleepsinhji were greatly appreciated by the British and their names went on to be used for the Ranji Trophy and Duleep Trophy – two major first-class tournaments in India. In 1911, an Indian men's cricket team, captained by Bhupinder Singh of Patiala, went on their first official tour of the British Isles, but only played English county teams and not the England cricket team.\\n\\n\\n=== Test match status (1918–1970) ===\\n\\nIndia was invited to the International Cricket Council in 1926, and made their debut as a Test-playing nation in England in 1932, led by C. K. Nayudu, who was considered the best Indian batsman at the time. The one-off Test match between the two sides was played at Lord's in London. The team was not strong in their batting at this point and went on to lose by 158 runs. India hosted its first men's Test cricket series in 1933 when England toured India. The visitors won the three-Test series 2–0 with the matches held at Bombay (now Mumbai), Calcutta (now Kolkata) and Madras (now Chennai). The Indian team continued to improve throughout the 1930s and 1940s but did not achieve an international victory during this period. In the early 1940s, India did not play any men's Test cricket due to World War II. The team's first series as an independent country was in late 1947 against Don Bradman's Australia. It was also the first Test series India played which was not against England. Australia men's cricket team won the five-match series 4–0, with Bradman tormenting the Indian bowling in his final Australian summer. India subsequently played their first Test series at home not against England, but against the West Indies in 1948. West Indies won the five-Test series 1–0. India recorded their first Test victory, in their 24th match, against England at Madras in 1952. Later in the same year, they won their first Test series, which was aga\"),\n",
       " Document(metadata={'title': 'Board of Control for Cricket in India', 'summary': \"The Board of Control for Cricket in India (BCCI) is the principal national governing body of the sport of cricket in India. Its headquarters are situated at the Cricket Centre in Wankhede Stadium, Mumbai. BCCI is the wealthiest governing body of cricket in the world. It has a revenue of more than ₹9,700 crore (US$1.1 billion).\\nIt is involved in talent development through grassroots programs and cricket academies. Its initiatives include coaching, infrastructure development, and player welfare programs designed to maintain and enhance India's competitive performance internationally.\\nBCCI was established on 1 December 1928 in Madras under Act XXI of 1860 of Madras and was subsequently reregistered under the Tamil Nadu Societies Registration Act, 1975. It is a consortium of state cricket associations that select their representatives who elect the BCCI president. It joined the Imperial Cricket Conference in 1926 which later became the International Cricket Council. The BCCI is an autonomous, private organization that does not fall under the purview of the National Sports Federation of India of Government of India and does not receive any grants from the Ministry of Youth Affairs and Sports. The BCCI is influential in international cricket. The International Cricket Council shares the largest part of its revenue with the BCCI. Organised by the BCCI, the Indian Premier League (IPL) is one of the wealthiest sports leagues in the world.\\nIn financial year 2023–2024, BCCI earned ₹18,700 crore (US$2.2 billion). BCCI paid ₹4,298 crore (US$510 million) in taxes for the financial year 2022–23.\\nR. E. Grant Govan was the first BCCI president and Anthony De Mello was its first secretary.\\nBCCI has hosted multiple Cricket World Cups, and will host the 2025 Women's Cricket World Cup, the 2026 Men's T20 World Cup, the 2029 Champions Trophy, and the 2031 Cricket World Cup.\\nThe BCCI manages four squads that represent India in international cricket; the men's national cricket team, the women's national cricket team, the men's national under-19 cricket team and the women's national under-19 cricket team. It also governs the developmental squads;  the India A team, the India B team and the India A women's team. Its national selection committee, which is led by chief national selector, selects players for these teams. As part of its duties, the BCCI organises and schedules matches to be played by each of these teams, and schedules, sanctions and organises domestic cricket in India.\", 'source': 'https://en.wikipedia.org/wiki/Board_of_Control_for_Cricket_in_India'}, page_content=\"The Board of Control for Cricket in India (BCCI) is the principal national governing body of the sport of cricket in India. Its headquarters are situated at the Cricket Centre in Wankhede Stadium, Mumbai. BCCI is the wealthiest governing body of cricket in the world. It has a revenue of more than ₹9,700 crore (US$1.1 billion).\\nIt is involved in talent development through grassroots programs and cricket academies. Its initiatives include coaching, infrastructure development, and player welfare programs designed to maintain and enhance India's competitive performance internationally.\\nBCCI was established on 1 December 1928 in Madras under Act XXI of 1860 of Madras and was subsequently reregistered under the Tamil Nadu Societies Registration Act, 1975. It is a consortium of state cricket associations that select their representatives who elect the BCCI president. It joined the Imperial Cricket Conference in 1926 which later became the International Cricket Council. The BCCI is an autonomous, private organization that does not fall under the purview of the National Sports Federation of India of Government of India and does not receive any grants from the Ministry of Youth Affairs and Sports. The BCCI is influential in international cricket. The International Cricket Council shares the largest part of its revenue with the BCCI. Organised by the BCCI, the Indian Premier League (IPL) is one of the wealthiest sports leagues in the world.\\nIn financial year 2023–2024, BCCI earned ₹18,700 crore (US$2.2 billion). BCCI paid ₹4,298 crore (US$510 million) in taxes for the financial year 2022–23.\\nR. E. Grant Govan was the first BCCI president and Anthony De Mello was its first secretary.\\nBCCI has hosted multiple Cricket World Cups, and will host the 2025 Women's Cricket World Cup, the 2026 Men's T20 World Cup, the 2029 Champions Trophy, and the 2031 Cricket World Cup.\\nThe BCCI manages four squads that represent India in international cricket; the men's national cricket team, the women's national cricket team, the men's national under-19 cricket team and the women's national under-19 cricket team. It also governs the developmental squads;  the India A team, the India B team and the India A women's team. Its national selection committee, which is led by chief national selector, selects players for these teams. As part of its duties, the BCCI organises and schedules matches to be played by each of these teams, and schedules, sanctions and organises domestic cricket in India.\\n\\n\\n== History ==\\n\\nThe first game of cricket was played in India by European sailors, who played the sport as a recreational activity in the first half of the 18th century. These sailors played cricket near their coastal settlements. The first recorded match in India was played between the British army and British settlers in 1751. The world's second-oldest cricket club, Calcutta Cricket Club, was founded in 1792 in present-day Kolkata. The Parsis were the first civilian community to accept cricket as a sport and play it in India. In 1848, they set up the Oriental Cricket Club in present-day Mumbai. In 1850, they founded the Young Zoroastrian Cricket Club. In 1886, Hindus founded the Hindu Gymkhana sports club.\\nIn 1912, an all-India cricket team visited England for the first time, and were sponsored and captained by the Maharaja of Patiala. In 1926, two representatives of Calcutta Cricket Club travelled to London to attend meetings of the Imperial Cricket Conference, the predecessor of the current International Cricket Council. Although technically not an official representative of Indian cricket, they were allowed to attend by Lord Harris, chairman of the conference. The outcome of the meeting was the MCC's decision to send a team that was led by Arthur Gilligan, who had captained England in The Ashes, to India.\\n\\n\\n=== Founding and early years ===\\n\\nIn a meeting with the Maharaja of Patiala, Bhupinder Singh, and others, Gilligan promised to press for its inclusion in the ICC if\"),\n",
       " Document(metadata={'title': 'Shreyas Iyer', 'summary': \"Shreyas Santosh Iyer (born 6 December 1994) is an Indian international cricketer who represents the India national team. A right-handed batter, he primarily plays as a top-order or middle-order batter across formats. Iyer also represents Mumbai in domestic cricket and captains the Punjab Kings in the Indian Premier League (IPL). He serves as the vice-captain of India's One Day International (ODI) team.\\nIyer made his international debut in 2017 and has been a regular member of India’s limited-overs sides. He achieved a notable milestone on his Test debut against New Zealand in November 2021, scoring a century in the first innings and a half-century in the second, becoming the first Indian player to record both on Test debut. Earlier in his career, he represented the India Under-19s at the 2014 Under-19 Cricket World Cup.\\nIn major international tournaments, Iyer was part of the Indian squad that finished runners-up at the 2023 Cricket World Cup, during which he scored a century against New Zealand in the semi-final. He was also a member of the teams that won the 2023 Asia Cup and the 2025 ICC Champions Trophy. For his performances, he was named ICC Men's Player of the Month in February 2022 and March 2025.\\nIn the IPL, Iyer began his career with the then Delhi Daredevils (now Delhi Capitals) in 2015, winning the Emerging Player of the Year award in his debut season, and played for them till 2021. He later captained the Kolkata Knight Riders from 2022 to 2024, leading them to the IPL title in 2024. In 2025, he was signed by the Punjab Kings for ₹26.75 crore (US$3.2 million), briefly becoming the most expensive player in IPL auction history before the record was surpassed in the same auction.\", 'source': 'https://en.wikipedia.org/wiki/Shreyas_Iyer'}, page_content=\"Shreyas Santosh Iyer (born 6 December 1994) is an Indian international cricketer who represents the India national team. A right-handed batter, he primarily plays as a top-order or middle-order batter across formats. Iyer also represents Mumbai in domestic cricket and captains the Punjab Kings in the Indian Premier League (IPL). He serves as the vice-captain of India's One Day International (ODI) team.\\nIyer made his international debut in 2017 and has been a regular member of India’s limited-overs sides. He achieved a notable milestone on his Test debut against New Zealand in November 2021, scoring a century in the first innings and a half-century in the second, becoming the first Indian player to record both on Test debut. Earlier in his career, he represented the India Under-19s at the 2014 Under-19 Cricket World Cup.\\nIn major international tournaments, Iyer was part of the Indian squad that finished runners-up at the 2023 Cricket World Cup, during which he scored a century against New Zealand in the semi-final. He was also a member of the teams that won the 2023 Asia Cup and the 2025 ICC Champions Trophy. For his performances, he was named ICC Men's Player of the Month in February 2022 and March 2025.\\nIn the IPL, Iyer began his career with the then Delhi Daredevils (now Delhi Capitals) in 2015, winning the Emerging Player of the Year award in his debut season, and played for them till 2021. He later captained the Kolkata Knight Riders from 2022 to 2024, leading them to the IPL title in 2024. In 2025, he was signed by the Punjab Kings for ₹26.75 crore (US$3.2 million), briefly becoming the most expensive player in IPL auction history before the record was surpassed in the same auction.\\n\\n\\n== Early life ==\\nIyer was born on 6 December 1994 in Chembur, Bombay. His father, Santosh Iyer, is a Tamilian, and his mother, Rohini Iyer, is a Tuluva. His ancestors are from Thrissur, Kerala. He was educated at Don Bosco High School, Matunga and at Ramniranjan Anandilal Podar College of Commerce and Economics, Mumbai.\\nAt the age of 18, Iyer was spotted by coach Pravin Amre at the Shivaji Park Gymkhana, who trained him in his early cricketing days. Iyer's teammates at the age group levels used to compare him to Virender Sehwag. During his graduation from Podar College, Iyer helped his college team win six trophies.\\n\\n\\n== Domestic career ==\\nIn 2014, Iyer represented the Trent Bridge Cricket Team. During a trip to the UK, he played three matches, scoring 297 runs and averaging 99 runs per game. He set a new team record with a highest score of 171.\\nIyer made his List A debut for Mumbai in November 2014, playing in the 2014–15 Vijay Hazare Trophy. He scored 273 runs in that tournament at an average of 54.60. Iyer made his first-class cricket debut in December 2014 during the 2014–15 Ranji Trophy. He scored a total of 809 runs at an average of 50.56 in his debut Ranji season, including two centuries and six fifties. He was 7th highest scorer of the 2014–15 Ranji Trophy.\\nIn the 2015–16 Ranji Trophy, Iyer scored 1,321 runs at an average of 73.39, including four centuries and seven fifties, becoming the top scorer of the Ranji season and the second player to score 1,300 runs in a single Ranji Trophy competition. In the 2016–17 Ranji Trophy, Iyer scored 725 runs at an average of 42.64, including two centuries and two fifties. He scored 202 not out off 210 balls against the visiting Australia team in a 3-Day Practice match in Mumbai, his highest first-class score.\\nIn September 2018, Iyer was named the vice-captain of Mumbai for the 2018–19 Vijay Hazare Trophy tournament. He was the leading run-scorer for Mumbai in the tournament, with 373 runs in seven matches. In October 2018, Iyer was named the captain of India B's squad for the 2018–19 Deodhar Trophy. He was also the leading run-scorer in that tournament, with 199 runs in three matches.\\nIn February 2019, in the opening round of the 2018–19 Syed Mushtaq Ali Trophy tournament, Iyer made the highest s\"),\n",
       " Document(metadata={'title': 'ICC Awards', 'summary': \"The ICC Awards is an International cricket award presented annually by the sport's governing body, ICC.\\nThe first awarding ceremony was held on 7 September 2004 in London, England. Between 2009 and 2014 the awards were known as the LG ICC Awards for sponsorship reasons.\\nVirat Kohli holds the record for most awards by an individual with 10 awards, and most appearances in teams with 14 times along with AB de Villiers. In Women's section, Ellyse Perry holds the record for most awards by an individual with 6 awards and Smriti Mandhana holds the record for most appearances in teams with 9 times.\", 'source': 'https://en.wikipedia.org/wiki/ICC_Awards'}, page_content='The ICC Awards is an International cricket award presented annually by the sport\\'s governing body, ICC.\\nThe first awarding ceremony was held on 7 September 2004 in London, England. Between 2009 and 2014 the awards were known as the LG ICC Awards for sponsorship reasons.\\nVirat Kohli holds the record for most awards by an individual with 10 awards, and most appearances in teams with 14 times along with AB de Villiers. In Women\\'s section, Ellyse Perry holds the record for most awards by an individual with 6 awards and Smriti Mandhana holds the record for most appearances in teams with 9 times.\\n\\n\\n== Men\\'s awards ==\\n\\n\\n=== Cricketer Of The Decade (Sir Garfield Sobers Award) ===\\n\\n\\n=== Cricketer Of The Year ===\\n\\n\\n=== Test Cricketer Of The Decade ===\\n\\n\\n=== Test Cricketer Of The Year ===\\n\\n\\n=== ODI Cricketer Of The Decade ===\\n\\n\\n=== ODI Cricketer Of The Year ===\\n\\n\\n=== T20I Cricketer Of The Decade ===\\n\\n\\n=== T20I Cricketer Of The Year ===\\n\\n\\n=== Emerging Cricketer Of The Year ===\\n\\n\\n=== Associate Cricketer Of The Decade ===\\n\\n\\n=== Associate Cricketer Of The Year ===\\n\\n\\n=== Test Team Of The Decade ===\\n\\n\\n=== Test Team Of The Year ===\\n\\n\\n=== ODI Team Of The Decade ===\\n\\n\\n=== ODI Team Of The Year ===\\n\\n\\n=== T20I Team Of The Decade ===\\n\\n\\n=== T20I Team Of The Year ===\\n\\n\\n== Women\\'s awards ==\\n\\n\\n=== Cricketer Of The Decade ===\\n\\n\\n=== Cricketer of the Year ===\\n\\n\\n=== ODI Cricketer Of The Decade ===\\n\\n\\n=== ODI Cricketer of the Year ===\\n\\n\\n=== T20I Cricketer Of The Decade ===\\n\\n\\n=== T20I Cricketer of the Year ===\\n\\n\\n=== Emerging Cricketer of the Year ===\\n\\n\\n=== Associate Cricketer of the Year ===\\n\\n\\n=== ODI Team of the Year ===\\n\\n\\n=== T20I Team of the Year ===\\n\\n\\n== Mixed awards ==\\n\\n\\n=== ICC Umpire of the Year ===\\n\\n\\n=== ICC Spirit of Cricket ===\\nDescribed by the ICC as being awarded to the teams and players most notable for \"upholding the \\'Spirit of the Game\\'\", involving respect for:\\nTheir opponents\\nTheir own captain and team\\nThe role of the umpires\\nThe game\\'s traditional values\\nTeams\\n\\nPlayers\\n\\n\\n== Defunct awards ==\\n\\n\\n=== ICC Twenty20 International Performance of the Year ===\\nIn 2021, The award was succeeded by ICC T20I Player of the Year, which is given to a player based on his performance in the whole year. This was from 2008 to 2019, when T20Is weren\\'t usually played frequently enough to have a \"Player of the Year\" award for this format.\\n\\n\\n=== Captain of the Year ===\\n\\n\\n=== Team of the Year ===\\n\\n\\n=== Women\\'s Team of the Year ===\\n\\n\\n=== LG People\\'s Choice Award ===\\n\\n\\n=== Fan\\'s Moment of the Year ===\\n\\n\\n== Monthly awards ==\\nIn January 2021, the ICC introduced \"Player of the Month\" awards to recognise cricketers, male and female, that performed best across all forms of international cricket each month. Nominees and winners are determined by an ICC panel of ex-players and journalists, with a public vote having a 10% contribution to the final results.\\n\\n\\n=== Men\\'s Player of the Month ===\\n\\n\\n=== Women\\'s Player of the Month ===\\n\\n\\n== Awards by country ==\\n\\n\\n== Development Awards ==\\nThe ICC Development Awards was launched in 2002, to recognise the ICC associate member nations for its innovative development programmes and inspiring efforts on the field of play. \\nICC introduced a new set of awards in 2019. The six categories were: Gray-Nicholls Participation Programme of the Year (now. ICC Development Initiative of the Year), 100% Cricket Women’s Cricket Initiative of the Year, ICC Associate Member Men’s Performance of the Year, ICC Associate Member Women’s Performance of the Year, ICC Digital Fan Engagement of the Year and Cricket 4 Good Social Impact Initiative of the Year. The Global winner in each category is chosen from the Regional winners coming from all five ICC regions.\\nICC announces the award winners every year separately to annual ICC Awards.\\n\\n\\n=== ICC Development Initiative of the Year ===\\n\\n\\n=== 100% Cricket Female Cricket Initiative of the Year ===\\n\\n\\n=== ICC Associate Member Men’s Performance of the Year ===\\n\\n\\n=== ICC Associate Member Women’s Performance of the Year ==='),\n",
       " Document(metadata={'title': 'AB de Villiers', 'summary': 'Abraham Benjamin de Villiers  (born 17 February 1984) is a South African former international cricketer. He is regarded as one of the greatest batters of his generation. de Villiers was named as the ICC ODI Player of the Year three times during his 15-year international career. He was one of the five Wisden cricketers of the decade at the end of 2019. He began his international career as a wicket-keeper-batter, but he has most often played only as a batter.\\nRegarded as one of the most innovative and destructive batsmen in the modern era, de Villiers is known for a range of unorthodox shots, particularly behind the wicket-keeper. He made his international debut in a Test match against England in 2004 and first played a One Day International (ODI) in early 2005. His debut in Twenty20 International cricket came in 2006. He scored over 8,000 runs in both Test and ODI cricket and is one of the very few batsmen to have a batting average of over fifty in both forms of the game. In limited overs cricket, he is an attacking player. He holds the record for the fastest ODI fifty (16 balls) equalled by Matthew Forde of the West Indies who made 58 off 19 balls against Ireland, fastest ODI century (31 balls), and fastest ODI 150 (62 balls)\\nDe Villiers captained South Africa in all three formats, although after a series of injuries, he stepped down from the Test captaincy. In 2017, he stepped down from captaining the national limited-overs games and in May 2018, at the age of 34, he announced his retirement from all forms of international cricket. In January 2020, however, de Villiers expressed an interest in making an international comeback and play in the 2020 T20 World Cup, although later in the year it was confirmed that he would not do so. On 19 November 2021, de Villiers announced his retirement from all forms of cricket. In October 2024, de Villiers became the 8th South African cricketer to be inducted into the ICC Hall of Fame.', 'source': 'https://en.wikipedia.org/wiki/AB_de_Villiers'}, page_content='Abraham Benjamin de Villiers  (born 17 February 1984) is a South African former international cricketer. He is regarded as one of the greatest batters of his generation. de Villiers was named as the ICC ODI Player of the Year three times during his 15-year international career. He was one of the five Wisden cricketers of the decade at the end of 2019. He began his international career as a wicket-keeper-batter, but he has most often played only as a batter.\\nRegarded as one of the most innovative and destructive batsmen in the modern era, de Villiers is known for a range of unorthodox shots, particularly behind the wicket-keeper. He made his international debut in a Test match against England in 2004 and first played a One Day International (ODI) in early 2005. His debut in Twenty20 International cricket came in 2006. He scored over 8,000 runs in both Test and ODI cricket and is one of the very few batsmen to have a batting average of over fifty in both forms of the game. In limited overs cricket, he is an attacking player. He holds the record for the fastest ODI fifty (16 balls) equalled by Matthew Forde of the West Indies who made 58 off 19 balls against Ireland, fastest ODI century (31 balls), and fastest ODI 150 (62 balls)\\nDe Villiers captained South Africa in all three formats, although after a series of injuries, he stepped down from the Test captaincy. In 2017, he stepped down from captaining the national limited-overs games and in May 2018, at the age of 34, he announced his retirement from all forms of international cricket. In January 2020, however, de Villiers expressed an interest in making an international comeback and play in the 2020 T20 World Cup, although later in the year it was confirmed that he would not do so. On 19 November 2021, de Villiers announced his retirement from all forms of cricket. In October 2024, de Villiers became the 8th South African cricketer to be inducted into the ICC Hall of Fame.\\n\\n\\n== Early life ==\\nAbraham Benjamin de Villiers was born on 17 February 1984 in Warmbad (modern day Bela-Bela), South Africa to Abraham B de Villiers and Millie de Villiers. He has two elder brothers Jan de Villiers and Wessels de Villiers. He described his childhood days as \"really relaxed lifestyle up there, where everyone knows everyone\". He was educated at Afrikaanse Hoër Seunskool in Pretoria along with teammate Faf du Plessis, who was and still remains his good friend. He is a high school graduate. His father was a doctor who had played rugby union in his youth, and he encouraged his son to play sports as a child.\\n\\n\\n== Career ==\\nDe Villiers is a right-handed batter who accumulated 8765 runs in Tests including 22 centuries and 46 fifties. He holds the record for most Test innings without registering a duck (78), before being dismissed for naught against Bangladesh in November 2008. He also holds the second-highest individual score by a South African batsman, with an unbeaten 278. Until 2012 he was an occasional wicket-keeper for South Africa, although after the retirement of regular Test keeper Mark Boucher and under his own captaincy he has started to regularly keep wicket for the national team in Tests, ODIs and T20Is. He gave up wicket-keeping in 2015 and handed the gloves to debutant Quinton de Kock.\\nHe holds the records for the fastest 50 (16 balls), 100 (31 balls) and 150 (64 balls) of all time in One Day Internationals by any batsmen, and also holds the fastest hundred by a South African in Tests and the fastest 50 by South African in T20Is. He is a three-time ICC ODI player of the year, winning the award in 2010, 2014 and 2015.\\nAfter the 2011 Cricket World Cup he succeeded Graeme Smith as captain of the national ODI team, and became Test captain after the second Test of the home series against England in 2015/16. He stepped down from Test captaincy in December 2016 due to an elbow injury which kept him out of the team for a long period.\\nAB de Villiers is claimed by many to be a multifaceted, versa'),\n",
       " Document(metadata={'title': 'Indian cricket team in Australia in 2020–21', 'summary': \"The India cricket team toured Australia from November 2020 to January 2021 to play four Tests, three One Day Internationals (ODIs) and three Twenty20 International (T20I) matches. The Test series formed part of the inaugural ICC World Test Championship, and the ODI series formed part of the inaugural ICC Cricket World Cup Super League.\\nIn February 2020, the Board of Control for Cricket in India (BCCI) announced that they wanted to play one of the Test matches as a day/night fixture. On 22 October 2020, the tour was approved by the NSW Government, with Sydney and Canberra confirmed as the hosts of the limited overs matches. Four days later, Cricket Australia confirmed the fixtures for the tour. On 9 November 2020, the BCCI announced that India's captain Virat Kohli had been granted paternity leave, and left the tour after the first Test match. Ajinkya Rahane led the Indian team in Kohli's absence.\\nAustralia won the first and second ODI matches to take a lead in the series. India won the third ODI match by 13 runs, with Australia winning the series 2–1. India also won the first and second T20I matches, winning the T20I series with a game to spare. This series victory made Virat Kohli the first captain to win a T20I series in both Australia and England. Australia won the third and final match by 12 runs, with India winning the series 2–1.\\nIn the first Test, India were bowled out for 36 runs in the second innings, their lowest team total in a Test match. Australia went on to win the match by eight wickets. India then won the second Test by the same margin to level the series. The third Test ended in a draw, with the series remaining at 1–1. India won the fourth and final Test match by three wickets, to win the series 2–1.\\nIt was the 10th time Australia lost a test series on home soil outside The Ashes, West Indies in 1979–80, West Indies in 1984–85, New Zealand in 1985–86, West Indies in 1988–89, West Indies in 1992–93, South Africa in 2008–09, South Africa in 2012–13, South Africa in 2016–17 and India in 2018–19.\", 'source': 'https://en.wikipedia.org/wiki/Indian_cricket_team_in_Australia_in_2020%E2%80%9321'}, page_content='The India cricket team toured Australia from November 2020 to January 2021 to play four Tests, three One Day Internationals (ODIs) and three Twenty20 International (T20I) matches. The Test series formed part of the inaugural ICC World Test Championship, and the ODI series formed part of the inaugural ICC Cricket World Cup Super League.\\nIn February 2020, the Board of Control for Cricket in India (BCCI) announced that they wanted to play one of the Test matches as a day/night fixture. On 22 October 2020, the tour was approved by the NSW Government, with Sydney and Canberra confirmed as the hosts of the limited overs matches. Four days later, Cricket Australia confirmed the fixtures for the tour. On 9 November 2020, the BCCI announced that India\\'s captain Virat Kohli had been granted paternity leave, and left the tour after the first Test match. Ajinkya Rahane led the Indian team in Kohli\\'s absence.\\nAustralia won the first and second ODI matches to take a lead in the series. India won the third ODI match by 13 runs, with Australia winning the series 2–1. India also won the first and second T20I matches, winning the T20I series with a game to spare. This series victory made Virat Kohli the first captain to win a T20I series in both Australia and England. Australia won the third and final match by 12 runs, with India winning the series 2–1.\\nIn the first Test, India were bowled out for 36 runs in the second innings, their lowest team total in a Test match. Australia went on to win the match by eight wickets. India then won the second Test by the same margin to level the series. The third Test ended in a draw, with the series remaining at 1–1. India won the fourth and final Test match by three wickets, to win the series 2–1.\\nIt was the 10th time Australia lost a test series on home soil outside The Ashes, West Indies in 1979–80, West Indies in 1984–85, New Zealand in 1985–86, West Indies in 1988–89, West Indies in 1992–93, South Africa in 2008–09, South Africa in 2012–13, South Africa in 2016–17 and India in 2018–19.\\n\\n\\n== Background ==\\nIn April 2020, Kevin Roberts, CEO of Cricket Australia looked at \"creative\" solutions for the tour due to the COVID-19 pandemic. These included the possibility of playing five Test matches instead of four, and to play all the Test matches behind closed doors at the Adelaide Oval. The Australian government was also looking at applying international travel exemptions to allow the tour to happen. The following month, the BCCI confirmed that they were willing to put players in a two-week quarantine period to ensure that the tour goes ahead. Kevin Roberts later added that there is a \"nine out of 10\" chance of the tour taking place. The Test series was scheduled to start in December 2020, with the first Test in Brisbane. The ODI series was scheduled to start in January 2021. On 28 May 2020, Cricket Australia confirmed all of the fixtures for the series. The following day, Kevin Roberts stated that the number of Test venues could be reduced to one or two grounds, depending on any travel restrictions imposed due to the virus.\\nOriginally, the tour was also going to start with three Twenty20 International (T20I) matches, commencing on 11 October 2020, ahead of the then scheduled 2020 ICC Men\\'s T20 World Cup. However, in July 2020, the International Cricket Council (ICC) confirmed that the tournament had been postponed until 2021, due to the COVID-19 pandemic. As a result, the T20I matches were postponed, after they clashed with the revised fixtures for the 2020 Indian Premier League. Despite a lockdown in Melbourne in August 2020, Cricket Australia said they would do everything they can to ensure the Boxing Day Test goes ahead as planned. Cricket Australia were also looking at a revised schedule for the tour, including playing all the limited-overs matches before the Test series. On 20 August 2020, Sourav Ganguly, president of the BCCI, said that India\\'s senior men\\'s team would travel to Australia to fulfil thei'),\n",
       " Document(metadata={'title': 'ICC Awards of the Decade', 'summary': \"The ICC Awards of the Decade was a one-off edition of the ICC Awards annual awards programme, celebrating the stand-out performers and moments from a ten year period of international cricket. The announcement of the ICC World XI teams, along with the winners of the individual ICC awards, was made on 27 December 2020. Virat Kohli won Men's Cricketer of the Decade while Ellyse Perry was named as Women's Cricketer of the Decade.\", 'source': 'https://en.wikipedia.org/wiki/ICC_Awards_of_the_Decade'}, page_content=\"The ICC Awards of the Decade was a one-off edition of the ICC Awards annual awards programme, celebrating the stand-out performers and moments from a ten year period of international cricket. The announcement of the ICC World XI teams, along with the winners of the individual ICC awards, was made on 27 December 2020. Virat Kohli won Men's Cricketer of the Decade while Ellyse Perry was named as Women's Cricketer of the Decade.\\n\\n\\n== Award categories and winners ==\\n\\n\\n=== Individual awards ===\\n\\n\\n=== ICC Teams of the Decade ===\\n\\n\\n==== Men's teams ====\\n\\n\\n==== Women's teams ====\\n\\n\\n== Criteria ==\\n\\nThe criteria for nomination for the ICC Player of the Decade award are designed to recognize sustained excellence and significant impact in international cricket over a ten-year period. To be eligible for nomination, a cricketer must have achieved one of the following milestones: winning at least one ICC trophy, including the Cricket World Cup, ICC Test Championship Mace, ICC Men's T20 World Cup, or ICC Champions Trophy. Alternatively, the nominee can qualify by being named the ICC Player of the Tournament in any of these competitions at least once. These criteria highlight both team success and individual brilliance, ensuring that the nominees have not only contributed to their teams' achievements on the world stage but have also exhibited outstanding personal performances in major international tournaments.\\n\\n\\n== Nominations ==\\nThe following were the nominations and winners for the ICC Awards of the Decade:\\n\\n\\n=== ICC Men’s Cricketer of the Decade ===\\n Virat Kohli – Winner\\n Ravichandran Ashwin\\n Joe Root\\n Kumar Sangakkara\\n Steve Smith\\n AB de Villiers\\n Kane Williamson\\n(Out of these only Kumar Sangakarra was retired at the time of nomination)\\n\\n\\n=== ICC Women’s Cricketer of the Decade ===\\n Suzie Bates\\n Meg Lanning\\n Ellyse Perry - Winner\\n Mithali Raj\\n Sarah Taylor\\n Stafanie Taylor\\n\\n\\n=== ICC Men's Test Cricketer of the Decade ===\\n James Anderson\\n Virat Kohli\\n Rangana Herath\\n Steve Smith - Winner\\n Yasir Shah\\n Joe Root\\n Kane Williamson\\n\\n\\n=== ICC Men’s ODI Cricketer of the Decade ===\\n Virat Kohli - Winner\\n Lasith Malinga\\n Kumar Sangakkara\\n Rohit Sharma\\n Mitchell Starc\\n AB de Villiers\\n\\n\\n=== ICC Women’s ODI Cricketer of the Decade ===\\n Suzie Bates\\n Meg Lanning\\n Ellyse Perry - Winner\\n Mithali Raj\\n Stafanie Taylor\\n\\n\\n=== ICC Men's T20I Cricketer of the Decade ===\\n Aaron Finch\\n Virat Kohli\\n Chris Gayle\\n Rashid Khan - Winner\\n Lasith Malinga\\n Rohit Sharma\\n Imran Tahir\\n\\n\\n=== ICC Women’s T20I Cricketer of the Decade ===\\n Sophie Devine\\n Deandra Dottin\\n Ellyse Perry - Winner\\n Meg Lanning\\n Anya Shrubsole\\n Alyssa Healy\\n\\n\\n=== ICC Men's Associate Cricketer of the Decade ===\\n Richie Berrington\\n Peter Borren\\n Kyle Coetzer - Winner\\n Paras Khadka\\n Calum MacLeod\\n Assad Vala\\n\\n\\n=== ICC Women's Associate Cricketer of the Decade ===\\n Kathryn Bryce - Winner\\n Sarah Bryce\\n Natthakan Chantam\\n Sterre Kalis\\n Chanida Sutthiruang\\n Sornnorin Tippoch\\n\\n\\n=== ICC Spirit of Cricket Award of the Decade ===\\n\\n MS Dhoni (2011 Winner) - Winner\\n Daniel Vettori (2012 Winner)\\n Mahela Jayawardene (2013 Winner)\\n Katherine Brunt (2014 Winner)\\n Brendon McCullum (2015 Winner)\\n Misbah-ul-Haq (2016 Winner)\\n Anya Shrubsole (2017 Winner)\\n Kane Williamson (2018 Winner)\\n Virat Kohli (2019 Winner)\\n\\n\\n== See also ==\\n\\nInternational Cricket Council\\nICC Awards\\nSir Garfield Sobers Trophy (Cricketer of the Year)\\nICC Test Player of the Year\\nICC ODI Player of the Year\\nDavid Shepherd Trophy (Umpire of the Year)\\nICC Women's Cricketer of the Year\\nICC Test Team of the Year\\nICC ODI Team of the Year\\n\\n\\n== References ==\"),\n",
       " Document(metadata={'title': \"2022 Men's T20 World Cup\", 'summary': \"The 2022 ICC Men's T20 World Cup was the eighth edition of the Men's T20 World Cup, formerly known as the ICC World Twenty20. It was played in Australia from 16 October to 13 November 2022. In the final, England beat Pakistan by five wickets to win their second ICC Men's T20 World Cup title and draw level with the West Indies, who also won 2 ICC Men's T20 World Cup titles in both the 2012 and the 2016 editions. In winning the tournament, England also became the first team to simultaneously be the existing winners of the Cricket World Cup and the T20 World Cup. Sam Curran was named the player of the match and also the player of the tournament. It was the last edition to feature 16 team format, before it was expanded to 20 teams in the next edition.\\nAlthough originally scheduled to be held in 2020, the International Cricket Council (ICC) postponed the tournament because of the COVID-19 pandemic, with the re-arranged tournament held in Australia in 2022. The host nation were also the defending champions.\\nThe host cities for matches were Adelaide, Brisbane, Geelong, Hobart, Melbourne, Perth, and Sydney. The semi-finals took place at the Sydney Cricket Ground and at the Adelaide Oval.\\nA series of global qualifying matches took place for the right to play in the group stage of the tournament, with the two best-placed teams from the groups entering the Super 12 stage to compete alongside the eight pre-qualified nations.\", 'source': 'https://en.wikipedia.org/wiki/2022_Men%27s_T20_World_Cup'}, page_content=\"The 2022 ICC Men's T20 World Cup was the eighth edition of the Men's T20 World Cup, formerly known as the ICC World Twenty20. It was played in Australia from 16 October to 13 November 2022. In the final, England beat Pakistan by five wickets to win their second ICC Men's T20 World Cup title and draw level with the West Indies, who also won 2 ICC Men's T20 World Cup titles in both the 2012 and the 2016 editions. In winning the tournament, England also became the first team to simultaneously be the existing winners of the Cricket World Cup and the T20 World Cup. Sam Curran was named the player of the match and also the player of the tournament. It was the last edition to feature 16 team format, before it was expanded to 20 teams in the next edition.\\nAlthough originally scheduled to be held in 2020, the International Cricket Council (ICC) postponed the tournament because of the COVID-19 pandemic, with the re-arranged tournament held in Australia in 2022. The host nation were also the defending champions.\\nThe host cities for matches were Adelaide, Brisbane, Geelong, Hobart, Melbourne, Perth, and Sydney. The semi-finals took place at the Sydney Cricket Ground and at the Adelaide Oval.\\nA series of global qualifying matches took place for the right to play in the group stage of the tournament, with the two best-placed teams from the groups entering the Super 12 stage to compete alongside the eight pre-qualified nations.\\n\\n\\n== Background ==\\nIn April 2018, the ICC announced that the tournament would replace the scheduled 2021 ICC Champions Trophy. This was after the ICC granted full international status to Twenty20 matches played between member sides from 1 January 2019 onwards.\\nIn October 2019, it was reported that the ICC could scrap the T20 World Cup Qualifier, which would have been used as a pathway for qualification to the T20 World Cup. Therefore, 12 teams from the 2021 Men's T20 World Cup and four teams from qualification events would advance to the T20 World Cup. On 23 January 2020, the ICC confirmed the full details of qualification for the tournament. In May 2020, the ICC told the Board of Control for Cricket in India (BCCI) that they reserved the right to take away hosting rights from India, after the BCCI did not secure a tax exemption from the Indian government for the tournament.\\nIn July 2020, when the previous edition of the tournament was being reviewed due to the COVID-19 pandemic, Earl Eddings, the chairman of Cricket Australia suggested that Australia could host that tournament in October 2021, and India stage this tournament a year later in 2022. The ICC also confirmed that either Australia or India, the hosts for the tournaments originally scheduled to take place in 2020 and 2021 respectively, would host this tournament.\\nSeveral warm-up matches were played between 10 and 19 October 2022 between all participants. The first set of matches featured the teams from the groups in the first round of the main tournament, before the teams in the Super 12 phase played their warm-up matches. These matches did not have either T20I or T20 status as teams were allowed to field all 15 members of their squad.\\n\\n\\n== Teams and qualifications ==\\n\\nThe twelve teams that reached the Super 12 phase of the 2021 ICC Men's T20 World Cup automatically qualified for the 2022 tournament. Afghanistan, Australia, Bangladesh, England, India, Pakistan, New Zealand and South Africa all qualified directly for the Super 12 phase of this tournament, based on their performances in the 2021 tournament and their rankings as of 15 November 2021. Namibia, Scotland, Sri Lanka and the West Indies were all placed in the group stage of the competition.\\nThe remaining four places came from the top two teams from each of the two Global Qualifiers. The Global Qualifiers had a total of sixteen teams; the bottom four teams from the 2021 ICC Men's T20 World Cup (Ireland, Netherlands, Oman and Papua New Guinea), the next four highest ranked T20I sides (Zimbabwe, Nepal, \")]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "loader = WikipediaLoader(query=\"Virat Kohli\", )\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa2f4a",
   "metadata": {},
   "source": [
    "**WIKIPEDIA LOADER (LIMITED DOCUMENTS)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da5876b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'title': 'MS Dhoni', 'summary': \"Mahendra Singh  Dhoni ([məˈɦeːnd̪ɾə ˈsɪŋɡʱ ˈd̪ʱoːniː] ; born 7 July 1981) is an Indian professional cricketer who plays as a right-handed batter and a wicket-keeper. Widely regarded as one of the most prolific wicket-keeper batsmen and captains, he represented the Indian cricket team and was the captain of the side in limited overs formats from 2007 to 2017 and in Test cricket from 2008 to 2014. Dhoni has captained the most international matches and is the most successful Indian captain. He has led India to victory in the 2007 ICC World Twenty20, the 2011 Cricket World Cup, and the 2013 ICC Champions Trophy, being the only captain to win three different limited overs ICC tournaments. He also led the teams that won the Asia Cup in 2010 and 2016, and he was a member of the title winning squad in 2018.\\nBorn in Ranchi, Dhoni made his first class debut for Bihar in 1999. He made his debut for the Indian cricket team on 23 December 2004 in an ODI against Bangladesh and played his first test a year later against Sri Lanka. In 2007, he became the captain of the ODI side before taking over in all formats by 2008. Dhoni retired from Test cricket in 2014 but continued playing in limited overs cricket till 2019. He has scored 17,266 runs in international cricket including 10,000 plus runs at an average of more than 50 in ODIs.\\nIn the Indian Premier League (IPL), Dhoni plays for Chennai Super Kings (CSK), leading them to the final on ten occasions and winning it five times (2010, 2011, 2018, 2021 and 2023) jointly sharing this title with Rohit Sharma . He has also led CSK to two Champions League T20 titles in 2010 and 2014. Dhoni is among the few batsmen to have scored more than five thousand runs in the IPL, as well as being the first wicket-keeper to do so.\\nIn 2008, Dhoni was awarded India's highest sport honour Major Dhyan Chand Khel Ratna Award by Government of India. He received the fourth highest civilian award Padma Shri in 2009 and third highest civilian award Padma Bhushan in 2018. Dhoni holds an honorary rank of Lieutenant colonel in the Parachute Regiment of the Indian Territorial Army which was presented to him by the Indian Army in 2011. In June 2025, he was inducted into ICC Cricket Hall of Fame.\", 'source': 'https://en.wikipedia.org/wiki/MS_Dhoni'}, page_content='Mahendra Singh  Dhoni ([məˈɦeːnd̪ɾə ˈsɪŋɡʱ ˈd̪ʱoːniː] ; born 7 July 1981) is an Indian professional cricketer who plays as a right-handed batter and a wicket-keeper. Widely regarded as one of the most prolific wicket-keeper batsmen and captains, he represented the Indian cricket team and was the captain of the side in limited overs formats from 2007 to 2017 and in Test cricket from 2008 to 2014. Dhoni has captained the most international matches and is the most successful Indian captain. He has led India to victory in the 2007 ICC World Twenty20, the 2011 Cricket World Cup, and the 2013 ICC Champions Trophy, being the only captain to win three different limited overs ICC tournaments. He also led the teams that won the Asia Cup in 2010 and 2016, and he was a member of the title winning squad in 2018.\\nBorn in Ranchi, Dhoni made his first class debut for Bihar in 1999. He made his debut for the Indian cricket team on 23 December 2004 in an ODI against Bangladesh and played his first test a year later against Sri Lanka. In 2007, he became the captain of the ODI side before taking over in all formats by 2008. Dhoni retired from Test cricket in 2014 but continued playing in limited overs cricket till 2019. He has scored 17,266 runs in international cricket including 10,000 plus runs at an average of more than 50 in ODIs.\\nIn the Indian Premier League (IPL), Dhoni plays for Chennai Super Kings (CSK), leading them to the final on ten occasions and winning it five times (2010, 2011, 2018, 2021 and 2023) jointly sharing this title with Rohit Sharma . He has also led CSK to two Champions League T20 titles in 2010 and 2014. Dhoni is among the few batsmen to have scored more than five thousand runs in the IPL, as well as being the first wicket-keeper to do so.\\nIn 2008, Dhoni was awarded India\\'s highest sport honour Major Dhyan Chand Khel Ratna Award by Government of India. He received the fourth highest civilian award Padma Shri in 2009 and third highest civilian award Padma Bhushan in 2018. Dhoni holds an honorary rank of Lieutenant colonel in the Parachute Regiment of the Indian Territorial Army which was presented to him by the Indian Army in 2011. In June 2025, he was inducted into ICC Cricket Hall of Fame.\\n\\n\\n== Early life ==\\nDhoni was born on 7 July 1981 in Ranchi, Bihar (now in Jharkhand) in a Hindu Rajput family to Pan Singh and Devaki Devi. His parents hailed from Lwali village in the Almora district of Uttar Pradesh (now Uttarakhand). He was the youngest of three children. His family spells the surname as \"Dhauni\". The spelling \"Dhoni\" emerged due to a spelling mistake in his school certificates and, despite repeated attempts by his family, has never been rectified.\\nDhoni did his schooling from DAV Jawahar Vidya Mandir, where he started playing football as a goalkeeper, but later moved to play cricket on the suggestion of his coach Keshav Banerjee. From 2001 to 2003, Dhoni worked as a Travelling Ticket Examiner (TTE) at Kharagpur under South Eastern Railway zone of Indian Railways.\\n\\n\\n== Youth career ==\\nHe played as a wicket-keeper for Commando cricket club from 1995 to 1998 and Central Coal Fields Limited (CCL) team in 1998. At CCL, he batted higher up the order and helped the team qualify to the higher division. Based on his performance at club cricket, he was picked for the 1997/98 season of Vinoo Mankad Trophy under-16 championship. In the 1998–99, Dhoni played for Bihar U-19 team in the Cooch Behar Trophy and scored 176 runs in 5 matches. In the 1999–2000 Cooch Behar Trophy, the Bihar U-19 cricket team made it to the finals, where Dhoni made 84 in a losing cause. Dhoni\\'s contribution in the tournament included 488 runs in nine matches with five fifties, 17 catches and seven stumpings. Dhoni made it to the East Zone U-19 squad for the C. K. Nayudu Trophy in the 1999–2000 season and scored only 97 runs in four matches, as East Zone lost all the matches and finished last in the tournament.\\nDhoni made his Ranji Trophy debut for Bih'),\n",
       " Document(metadata={'title': 'Dhoni (film)', 'summary': 'Dhoni is a 2012 Indian drama film co-written, directed and produced by Prakash Raj. Simultaneously made in Tamil and Telugu languages, it stars Raj alongside Akash and Radhika Apte. The plot illustrates the conflicting interests of a father and his son; the father wants his son to study MBA, but his son is more interested in sports and wants to become a famous cricketer like Mahendra Singh Dhoni. Dhoni released on 10 February 2012 to positive reviews. The film is a remake of 2010 Marathi film Shikshanachya Aaicha Gho.', 'source': 'https://en.wikipedia.org/wiki/Dhoni_(film)'}, page_content='Dhoni is a 2012 Indian drama film co-written, directed and produced by Prakash Raj. Simultaneously made in Tamil and Telugu languages, it stars Raj alongside Akash and Radhika Apte. The plot illustrates the conflicting interests of a father and his son; the father wants his son to study MBA, but his son is more interested in sports and wants to become a famous cricketer like Mahendra Singh Dhoni. Dhoni released on 10 February 2012 to positive reviews. The film is a remake of 2010 Marathi film Shikshanachya Aaicha Gho.\\n\\n\\n== Plot ==\\nSubramaniam is a lower-middle-class widower with his two kids. He works from dawn to dusk to bring up his son Karthick and his daughter Kaveri. He wishes to give them a good education. He wants to see his son become an MBA graduate. But his son not interested in studies. Fourteen-year-old Karthick wants to become a good cricketer. His inspiration is Mahendra Singh Dhoni and he like him, he wants to be an attacking wicketkeeper-batsman.\\nWhile Subramaniam enrolls him in a good school, Karthick fails in most of the subjects. However, his cricket coach is in all praise, as Karthick played a major role in winning a Cricket Tournament. Kaveri often spends time with Nalini. Subramaniam learns that Nalini earns her living through prostitution and he strictly orders his daughter to stay away from her. As Karthick is poor in studies, The Principal tells Subramaniam to take his son out.\\nImmediately Subramaniam takes Karthick away from cricket coaching and makes him to go a series of tuition classes. Karthick fails to cope with his studies even after leaving cricket, which makes Subramaniam lose his patience. Subramaniam beats Karthick and injures his head by mistake for which Subramaniam is arrested. As Karthick goes into a coma, Subramaniam is very upset. He thanks Nalini for helping him pay the hospital bill.\\nWhen Subramaniam goes to Karthick\\'s school to collect things from Karthick\\'s locker, he finds many trophies and certificates which makes him argue with the teacher that if his son is not good at studies it does not mean that he is good for nothing. Soon Subramaniam goes for TV shows to debate. As he is working in a government office they ban him from going to the office and cancel the loan for his son\\'s operation. Subramaniam cannot bear it anymore and he goes to a function where the Chief Minister comes, Subramaniam talks with the Chief Minister about all this. The Chief Minister promises Subramaniam that there will be changes and he will get the money for his son\\'s operation. Karthick\\'s operation is successfully done. Karthick plays the final cricket tournament in his school he hits the last ball which goes for a six and Karthick wins the Cricket Match. The movie ends as Karthick\\'s cricket coach and Subramaniam carry him.\\n\\n\\n== Cast ==\\n\\n\\n== Production ==\\nPrakash Raj announced that he would direct a bilingual named Dhoni. He said: \"The film deals with the pressure that children undergo these days in schools\".\\nHindi film actress Mugdha Godse was reported to have been signed on to essay the opposite lead role, while Ilaiyaraaja was roped in to do the musical honors. Radhika Apte confirmed that she was playing a pivotal role in the film. Telugu film director Puri Jagannadh\\'s son Aakash was selected to portray Prakash Raj\\'s son.\\nThe first look of the film was unveiled in August 2011.\\nIn November 2011, choreographer-actor Prabhu Deva shot for five days for a cameo role.\\n\\n\\n== Reception ==\\n\\n\\n=== Critical response ===\\nDhoni received a positive response from critics. The Times of India rated it 3.5 out of 5, saying, \"...thanks to a combination of inspired acting, stimulating writing, a stirring background score and fine camera work, the film rises above the ordinary to make for a compelling cinema experience.\" Sify wrote \"On the whole, don?t miss Dhoni. The beauty of the narration is that the message applies to everyone and it might change your life\".\\nSunita Chowdary of Cinegoer.com, said that Dhoni is \"a perfect'),\n",
       " Document(metadata={'title': 'Sushant Singh Rajput', 'summary': \"Sushant Singh Rajput (21 January 1986 – 14 June 2020) was an Indian actor best known for his work in Hindi cinema. He earned acclaim for his performances in several notable films, including Kai Po Che! (2013), Detective Byomkesh Bakshy! (2015), M.S. Dhoni: The Untold Story (2016), Kedarnath (2018), Sonchiriya (2019), and Chhichhore (2019). Rajput received a Screen Award and was nominated for the Filmfare Awards on three occasions. He was featured twice on Forbes India's Celebrity 100 list, and was regarded as one of the most talented and versatile actors of his generation.\\nRajput began his acting career after dropping out of his engineering course at the Delhi College of Engineering and entering the theatre industry in Mumbai. He moved on to feature in Hindi television serials, his debut show was the romantic drama Kis Desh Mein Hai Meraa Dil (2008), followed by the lead role in the soap opera Pavitra Rishta (2009–2011). He made his film debut with the film adaptation Kai Po Che! (2013) which became a critical and commercial success. He followed up with his starring roles as a tourist guide in the romantic comedy Shuddh Desi Romance (2013) and the titular detective in the mystery film Detective Byomkesh Bakshy! (2015). Rajput's highest-grossing releases came with a supporting role in the satire PK (2014), and from the title role in the sports biopic of Mahendra Singh Dhoni. For his performance in the latter, he received his first nomination for the Filmfare Award for Best Actor.\\nRajput died by suicide at his home in Bandra, Mumbai, in June 2020, aged 34. Various controversies surrounded his death. The Narcotics Control Bureau claimed Rajput had been using various people to obtain drugs since 2018 and filed abetment charges against them. Abetment to suicide charges were filed and the case was handed to the Central Bureau of Investigation, who filed a closure report on 22 March 2025 ruling out any foul play. His last film, Dil Bechara (2020), was released posthumously on the streaming platform Hotstar.\", 'source': 'https://en.wikipedia.org/wiki/Sushant_Singh_Rajput'}, page_content=\"Sushant Singh Rajput (21 January 1986 – 14 June 2020) was an Indian actor best known for his work in Hindi cinema. He earned acclaim for his performances in several notable films, including Kai Po Che! (2013), Detective Byomkesh Bakshy! (2015), M.S. Dhoni: The Untold Story (2016), Kedarnath (2018), Sonchiriya (2019), and Chhichhore (2019). Rajput received a Screen Award and was nominated for the Filmfare Awards on three occasions. He was featured twice on Forbes India's Celebrity 100 list, and was regarded as one of the most talented and versatile actors of his generation.\\nRajput began his acting career after dropping out of his engineering course at the Delhi College of Engineering and entering the theatre industry in Mumbai. He moved on to feature in Hindi television serials, his debut show was the romantic drama Kis Desh Mein Hai Meraa Dil (2008), followed by the lead role in the soap opera Pavitra Rishta (2009–2011). He made his film debut with the film adaptation Kai Po Che! (2013) which became a critical and commercial success. He followed up with his starring roles as a tourist guide in the romantic comedy Shuddh Desi Romance (2013) and the titular detective in the mystery film Detective Byomkesh Bakshy! (2015). Rajput's highest-grossing releases came with a supporting role in the satire PK (2014), and from the title role in the sports biopic of Mahendra Singh Dhoni. For his performance in the latter, he received his first nomination for the Filmfare Award for Best Actor.\\nRajput died by suicide at his home in Bandra, Mumbai, in June 2020, aged 34. Various controversies surrounded his death. The Narcotics Control Bureau claimed Rajput had been using various people to obtain drugs since 2018 and filed abetment charges against them. Abetment to suicide charges were filed and the case was handed to the Central Bureau of Investigation, who filed a closure report on 22 March 2025 ruling out any foul play. His last film, Dil Bechara (2020), was released posthumously on the streaming platform Hotstar.\\n\\n\\n== Early life and education ==\\nSushant Singh Rajput was born in Patna in the state of Bihar to Krishna Kumar Singh and Usha Singh. His father is a retired technical officer and worked at Bihar State Handloom Corporation in Patna, and his mother was a homemaker. Rajput was the only son and the youngest of five siblings and had the nickname Gulshan. One of his four sisters, Mitu Singh, was a state-level cricket player. He studied at St. Karen's High School in Patna. His family moved to Delhi following his mother's death in 2002 where he completed his schooling for intermediate studies in the Kulachi Hansraj Model School.\\nRajput was reportedly an avid reader who was deeply interested in astrophysics and won the National Olympiad in Physics. He secured admission in the Delhi College of Engineering (later renamed Delhi Technological University) to pursue a Bachelor of Engineering degree in mechanical engineering. According to Rajput, he did not have any interest in engineering but his family gave him no option which left him dissatisfied. He instead wanted to become an astronaut and later an air force pilot but was also interested in Bollywood, being a fan of Shah Rukh Khan.\\n\\n\\n== Career ==\\n\\n\\n=== 2006–2011: Early career and television ===\\nDuring his course at the Delhi College of Engineering, Rajput enrolled himself in Shiamak Davar's dance classes. Soon afterward, he also began attending acting classes under the theatre director Barry John. Rajput later stated that he found the experience to be liberating and wanted to continue doing it forever. He featured as a background dancer in the Dhoom Again song of Dhoom 2 and in Aishwarya Rai's performance at the closing ceremony of the 2006 Commonwealth Games. In 2006, he dropped out of his engineering course during his fourth year to begin a career in arts and performance. He moved to Mumbai, took up odd jobs and small roles alongside working in the theatre industry. Rajput eventually join\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = WikipediaLoader(query=\"Mahendra Singh Dhoni\", load_max_docs=3)\n",
    "pages = loader.load()\n",
    "pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6caf1e37",
   "metadata": {},
   "source": [
    "**WIKIPEDIA LOADER (MULTIPLE QUERIES)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d2f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of search queries\n",
    "queries = [\n",
    "    \"Virat Kohli\",\n",
    "    \"Mahendra Singh Dhoni\",\n",
    "    \"Sachin Tendulkar\"\n",
    "]\n",
    "\n",
    "# Empty list to store all Wikipedia documents\n",
    "all_pages = []\n",
    "\n",
    "# Loop through each query and load Wikipedia content\n",
    "for query in queries:\n",
    "    loader = WikipediaLoader(query=query, load_max_docs=2)   # Limit number of documents per query\n",
    "    pages = loader.load()\n",
    "    all_pages.extend(pages)\n",
    "\n",
    "# Print all loaded Wikipedia documents\n",
    "all_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70371ef",
   "metadata": {},
   "source": [
    "#### **Arxiv Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58fc752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'Published': '2023-08-02', 'Title': 'Attention Is All You Need', 'Authors': 'Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin', 'Summary': 'The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.'}, page_content='Provided proper attribution is provided, Google hereby grants permission to\\nreproduce the tables and figures in this paper solely for use in journalistic or\\nscholarly works.\\nAttention Is All You Need\\nAshish Vaswani∗\\nGoogle Brain\\navaswani@google.com\\nNoam Shazeer∗\\nGoogle Brain\\nnoam@google.com\\nNiki Parmar∗\\nGoogle Research\\nnikip@google.com\\nJakob Uszkoreit∗\\nGoogle Research\\nusz@google.com\\nLlion Jones∗\\nGoogle Research\\nllion@google.com\\nAidan N. Gomez∗†\\nUniversity of Toronto\\naidan@cs.toronto.edu\\nŁukasz Kaiser∗\\nGoogle Brain\\nlukaszkaiser@google.com\\nIllia Polosukhin∗‡\\nillia.polosukhin@gmail.com\\nAbstract\\nThe dominant sequence transduction models are based on complex recurrent or\\nconvolutional neural networks that include an encoder and a decoder. The best\\nperforming models also connect the encoder and decoder through an attention\\nmechanism. We propose a new simple network architecture, the Transformer,\\nbased solely on attention mechanisms, dispensing with recurrence and convolutions\\nentirely. Experiments on two machine translation tasks show these models to\\nbe superior in quality while being more parallelizable and requiring significantly\\nless time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-\\nto-German translation task, improving over the existing best results, including\\nensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task,\\nour model establishes a new single-model state-of-the-art BLEU score of 41.8 after\\ntraining for 3.5 days on eight GPUs, a small fraction of the training costs of the\\nbest models from the literature. We show that the Transformer generalizes well to\\nother tasks by applying it successfully to English constituency parsing both with\\nlarge and limited training data.\\n∗Equal contribution. Listing order is random. Jakob proposed replacing RNNs with self-attention and started\\nthe effort to evaluate this idea. Ashish, with Illia, designed and implemented the first Transformer models and\\nhas been crucially involved in every aspect of this work. Noam proposed scaled dot-product attention, multi-head\\nattention and the parameter-free position representation and became the other person involved in nearly every\\ndetail. Niki designed, implemented, tuned and evaluated countless model variants in our original codebase and\\ntensor2tensor. Llion also experimented with novel model variants, was responsible for our initial codebase, and\\nefficient inference and visualizations. Lukasz and Aidan spent countless long days designing various parts of and\\nimplementing tensor2tensor, replacing our earlier codebase, greatly improving results and massively accelerating\\nour research.\\n†Work performed while at Google Brain.\\n‡Work performed while at Google Research.\\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\\narXiv:1706.03762v7  [cs.CL]  2 Aug 2023\\n1\\nIntroduction\\nRecurrent neural networks, long short-term memory [13] and gated recurrent [7] neural networks\\nin particular, have been firmly established as state of the art approaches in sequence modeling and\\ntransduction problems such as language modeling and machine translation [35, 2, 5]. Numerous\\nefforts have since continued to push the boundaries of recurrent language models and encoder-decoder\\narchitectures [38, 24, 15].\\nRecurrent models typically factor computation along the symbol positions of the input and output\\nsequences. Aligning the positions to steps in computation time, they generate a sequence of hidden\\nstates ht, as a function of the previous hidden state ht−1 and the input for position t. This inherently\\nsequential nature precludes parallelization within training examples, which becomes critical at longer\\nsequence lengths, as memory constraints limit batching across examples. Recent work has achieved\\nsignificant improvements in computational efficiency through factorization tricks [21] and conditional\\ncomputation [32], while also improving model performance in case of the latter. The fundamental\\nconstraint of sequential computation, however, remains.\\nAttention mechanisms have become an integral part of compelling sequence modeling and transduc-\\ntion models in various tasks, allowing modeling of dependencies without regard to their distance in\\nthe input or output sequences [2, 19]. In all but a few cases [27], however, such attention mechanisms\\nare used in conjunction with a recurrent network.\\nIn this work we propose the Transformer, a model architecture eschewing recurrence and instead\\nrelying entirely on an attention mechanism to draw global dependencies between input and output.\\nThe Transformer allows for significantly more parallelization and can reach a new state of the art in\\ntranslation quality after being trained for as little as twelve hours on eight P100 GPUs.\\n2\\nBackground\\nThe goal of reducing sequential computation also forms the foundation of the Extended Neural GPU\\n[16], ByteNet [18] and ConvS2S [9], all of which use convolutional neural networks as basic building\\nblock, computing hidden representations in parallel for all input and output positions. In these models,\\nthe number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difficult to learn dependencies between distant positions [12]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as\\ndescribed in section 3.2.\\nSelf-attention, sometimes called intra-attention is an attention mechanism relating different positions\\nof a single sequence in order to compute a representation of the sequence. Self-attention has been\\nused successfully in a variety of tasks including reading comprehension, abstractive summarization,\\ntextual entailment and learning task-independent sentence representations [4, 27, 28, 22].\\nEnd-to-end memory networks are based on a recurrent attention mechanism instead of sequence-\\naligned recurrence and have been shown to perform well on simple-language question answering and\\nlanguage modeling tasks [34].\\nTo the best of our knowledge, however, the Transformer is the first transduction model relying\\nentirely on self-attention to compute representations of its input and output without using sequence-\\naligned RNNs or convolution. In the following sections, we will describe the Transformer, motivate\\nself-attention and discuss its advantages over models such as [17, 18] and [9].\\n3\\nModel Architecture\\nMost competitive neural sequence transduction models have an encoder-decoder structure [5, 2, 35].\\nHere, the encoder maps an input sequence of symbol representations (x1, ..., xn) to a sequence\\nof continuous representations z = (z1, ..., zn). Given z, the decoder then generates an output\\nsequence (y1, ..., ym) of symbols one element at a time. At each step the model is auto-regressive\\n[10], consuming the previously generated symbols as additional input when generating the next.\\n2\\nFigure 1: The Transformer - model architecture.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1\\nEncoder and Decoder Stacks\\nEncoder:\\nThe encoder is composed of a stack of N = 6 identical layers. Each layer has two\\nsub-layers. The first is a multi-head self-attention mechanism, and the second is a simple, position-\\nwise fully connected feed-forward network. We employ a residual connection [11] around each of\\nthe two sub-layers, followed by layer normalization [1]. That is, the output of each sub-layer is\\nLayerNorm(x + Sublayer(x)), where Sublayer(x) is the function implemented by the sub-layer\\nitself. To facilitate these residual connections, all sub-layers in the model, as well as the embedding\\nlayers, produce outputs of dimension dmodel = 512.\\nDecoder:\\nThe decoder is also composed of a stack of N = 6 identical layers. In addition to the two\\nsub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head\\nattention over the output of the encoder stack. Similar to the encoder, we employ residual connections\\naround each of the sub-layers, followed by layer normalization. We also modify the self-attention\\nsub-layer in the decoder stack to prevent positions from attending to subsequent positions. This\\nmasking, combined with fact that the output embeddings are offset by one position, ensures that the\\npredictions for position i can depend only on the known outputs at positions less than i.\\n3.2\\nAttention\\nAn attention function can be described as mapping a query and a set of key-value pairs to an output,\\nwhere the query, keys, values, and output are all vectors. The output is computed as a weighted sum\\n3\\nScaled Dot-Product Attention\\nMulti-Head Attention\\nFigure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\\nattention layers running in parallel.\\nof the values, where the weight assigned to each value is computed by a compatibility function of the\\nquery with the corresponding key.\\n3.2.1\\nScaled Dot-Product Attention\\nWe call our particular attention \"Scaled Dot-Product Attention\" (Figure 2). The input consists of\\nqueries and keys of dimension dk, and values of dimension dv. We compute the dot products of the\\nquery with all keys, divide each by √dk, and apply a softmax function to obtain the weights on the\\nvalues.\\nIn practice, we compute the attention function on a set of queries simultaneously, packed together\\ninto a matrix Q. The keys and values are also packed together into matrices K and V . We compute\\nthe matrix of outputs as:\\nAttention(Q, K, V ) = softmax(QKT\\n√dk\\n)V\\n(1)\\nThe two most commonly used attention functions are additive attention [2], and dot-product (multi-\\nplicative) attention. Dot-product attention is identical to our algorithm, except for the scaling factor\\nof\\n1\\n√dk . Additive attention computes the compatibility function using a feed-forward network with\\na single hidden layer. While the two are similar in theoretical complexity, dot-product attention is\\nmuch faster and more space-efficient in practice, since it can be implemented using highly optimized\\nmatrix multiplication code.\\nWhile for small values of dk the two mechanisms perform similarly, additive attention outperforms\\ndot product attention without scaling for larger values of dk [3]. We suspect that for large values of\\ndk, the dot products grow large in magnitude, pushing the softmax function into regions where it has\\nextremely small gradients 4. To counteract this effect, we scale the dot products by\\n1\\n√dk .\\n3.2.2\\nMulti-Head Attention\\nInstead of performing a single attention function with dmodel-dimensional keys, values and queries,\\nwe found it beneficial to linearly project the queries, keys and values h times with different, learned\\nlinear projections to dk, dk and dv dimensions, respectively. On each of these projected versions of\\nqueries, keys and values we then perform the attention function in parallel, yielding dv-dimensional\\n4To illustrate why the dot products get large, assume that the components of q and k are independent random\\nvariables with mean 0 and variance 1. Then their dot product, q · k = Pdk\\ni=1 qiki, has mean 0 and variance dk.\\n4\\noutput values. These are concatenated and once again projected, resulting in the final values, as\\ndepicted in Figure 2.\\nMulti-head attention allows the model to jointly attend to information from different representation\\nsubspaces at different positions. With a single attention head, averaging inhibits this.\\nMultiHead(Q, K, V ) = Concat(head1, ..., headh)W O\\nwhere headi = Attention(QW Q\\ni , KW K\\ni , V W V\\ni )\\nWhere the projections are parameter matrices W Q\\ni\\n∈Rdmodel×dk, W K\\ni\\n∈Rdmodel×dk, W V\\ni\\n∈Rdmodel×dv\\nand W O ∈Rhdv×dmodel.\\nIn this work we employ h = 8 parallel attention layers, or heads. For each of these we use\\ndk = dv = dmodel/h = 64. Due to the reduced dimension of each head, the total computational cost\\nis similar to that of single-head attention with full dimensionality.\\n3.2.3\\nApplications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[38, 2, 9].\\n• The encoder contains self-attention layers. In a self-attention layer all of the keys, values\\nand queries come from the same place, in this case, the output of the previous layer in the\\nencoder. Each position in the encoder can attend to all positions in the previous layer of the\\nencoder.\\n• Similarly, self-attention layers in the decoder allow each position in the decoder to attend to\\nall positions in the decoder up to and including that position. We need to prevent leftward\\ninformation flow in the decoder to preserve the auto-regressive property. We implement this\\ninside of scaled dot-product attention by masking out (setting to −∞) all values in the input\\nof the softmax which correspond to illegal connections. See Figure 2.\\n3.3\\nPosition-wise Feed-Forward Networks\\nIn addition to attention sub-layers, each of the layers in our encoder and decoder contains a fully\\nconnected feed-forward network, which is applied to each position separately and identically. This\\nconsists of two linear transformations with a ReLU activation in between.\\nFFN(x) = max(0, xW1 + b1)W2 + b2\\n(2)\\nWhile the linear transformations are the same across different positions, they use different parameters\\nfrom layer to layer. Another way of describing this is as two convolutions with kernel size 1.\\nThe dimensionality of input and output is dmodel = 512, and the inner-layer has dimensionality\\ndff = 2048.\\n3.4\\nEmbeddings and Softmax\\nSimilarly to other sequence transduction models, we use learned embeddings to convert the input\\ntokens and output tokens to vectors of dimension dmodel. We also use the usual learned linear transfor-\\nmation and softmax function to convert the decoder output to predicted next-token probabilities. In\\nour model, we share the same weight matrix between the two embedding layers and the pre-softmax\\nlinear transformation, similar to [30]. In the embedding layers, we multiply those weights by √dmodel.\\n5\\nTable 1: Maximum path lengths, per-layer complexity and minimum number of sequential operations\\nfor different layer types. n is the sequence length, d is the representation dimension, k is the kernel\\nsize of convolutions and r the size of the neighborhood in restricted self-attention.\\nLayer Type\\nComplexity per Layer\\nSequential\\nMaximum Path Length\\nOperations\\nSelf-Attention\\nO(n2 · d)\\nO(1)\\nO(1)\\nRecurrent\\nO(n · d2)\\nO(n)\\nO(n)\\nConvolutional\\nO(k · n · d2)\\nO(1)\\nO(logk(n))\\nSelf-Attention (restricted)\\nO(r · n · d)\\nO(1)\\nO(n/r)\\n3.5\\nPositional Encoding\\nSince our model contains no recurrence and no convolution, in order for the model to make use of the\\norder of the sequence, we must inject some information about the relative or absolute position of the\\ntokens in the sequence. To this end, we add \"positional encodings\" to the input embeddings at the\\nbottoms of the encoder and decoder stacks. The positional encodings have the same dimension dmodel\\nas the embeddings, so that the two can be summed. There are many choices of positional encodings,\\nlearned and fixed [9].\\nIn this work, we use sine and cosine functions of different frequencies:\\nPE(pos,2i) = sin(pos/100002i/dmodel)\\nPE(pos,2i+1) = cos(pos/100002i/dmodel)\\nwhere pos is the position and i is the dimension. That is, each dimension of the positional encoding\\ncorresponds to a sinusoid. The wavelengths form a geometric progression from 2π to 10000 · 2π. We\\nchose this function because we hypothesized it would allow the model to easily learn to attend by\\nrelative positions, since for any fixed offset k, PEpos+k can be represented as a linear function of\\nPEpos.\\nWe also experimented with using learned positional embeddings [9] instead, and found that the two\\nversions produced nearly identical results (see Table 3 row (E)). We chose the sinusoidal version\\nbecause it may allow the model to extrapolate to sequence lengths longer than the ones encountered\\nduring training.\\n4\\nWhy Self-Attention\\nIn this section we compare various aspects of self-attention layers to the recurrent and convolu-\\ntional layers commonly used for mapping one variable-length sequence of symbol representations\\n(x1, ..., xn) to another sequence of equal length (z1, ..., zn), with xi, zi ∈Rd, such as a hidden\\nlayer in a typical sequence transduction encoder or decoder. Motivating our use of self-attention we\\nconsider three desiderata.\\nOne is the total computational complexity per layer. Another is the amount of computation that can\\nbe parallelized, as measured by the minimum number of sequential operations required.\\nThe third is the path length between long-range dependencies in the network. Learning long-range\\ndependencies is a key challenge in many sequence transduction tasks. One key factor affecting the\\nability to learn such dependencies is the length of the paths forward and backward signals have to\\ntraverse in the network. The shorter these paths between any combination of positions in the input\\nand output sequences, the easier it is to learn long-range dependencies [12]. Hence we also compare\\nthe maximum path length between any two input and output positions in networks composed of the\\ndifferent layer types.\\nAs noted in Table 1, a self-attention layer connects all positions with a constant number of sequentially\\nexecuted operations, whereas a recurrent layer requires O(n) sequential operations. In terms of\\ncomputational complexity, self-attention layers are faster than recurrent layers when the sequence\\n6\\nlength n is smaller than the representation dimensionality d, which is most often the case with\\nsentence representations used by state-of-the-art models in machine translations, such as word-piece\\n[38] and byte-pair [31] representations. To improve computational performance for tasks involving\\nvery long sequences, self-attention could be restricted to considering only a neighborhood of size r in\\nthe input sequence centered around the respective output position. This would increase the maximum\\npath length to O(n/r). We plan to investigate this approach further in future work.\\nA single convolutional layer with kernel width k < n does not connect all pairs of input and output\\npositions. Doing so requires a stack of O(n/k) convolutional layers in the case of contiguous kernels,\\nor O(logk(n)) in the case of dilated convolutions [18], increasing the length of the longest paths\\nbetween any two positions in the network. Convolutional layers are generally more expensive than\\nrecurrent layers, by a factor of k. Separable convolutions [6], however, decrease the complexity\\nconsiderably, to O(k · n · d + n · d2). Even with k = n, however, the complexity of a separable\\nconvolution is equal to the combination of a self-attention layer and a point-wise feed-forward layer,\\nthe approach we take in our model.\\nAs side benefit, self-attention could yield more interpretable models. We inspect attention distributions\\nfrom our models and present and discuss examples in the appendix. Not only do individual attention\\nheads clearly learn to perform different tasks, many appear to exhibit behavior related to the syntactic\\nand semantic structure of the sentences.\\n5\\nTraining\\nThis section describes the training regime for our models.\\n5.1\\nTraining Data and Batching\\nWe trained on the standard WMT 2014 English-German dataset consisting of about 4.5 million\\nsentence pairs. Sentences were encoded using byte-pair encoding [3], which has a shared source-\\ntarget vocabulary of about 37000 tokens. For English-French, we used the significantly larger WMT\\n2014 English-French dataset consisting of 36M sentences and split tokens into a 32000 word-piece\\nvocabulary [38]. Sentence pairs were batched together by approximate sequence length. Each training\\nbatch contained a set of sentence pairs containing approximately 25000 source tokens and 25000\\ntarget tokens.\\n5.2\\nHardware and Schedule\\nWe trained our models on one machine with 8 NVIDIA P100 GPUs. For our base models using\\nthe hyperparameters described throughout the paper, each training step took about 0.4 seconds. We\\ntrained the base models for a total of 100,000 steps or 12 hours. For our big models,(described on the\\nbottom line of table 3), step time was 1.0 seconds. The big models were trained for 300,000 steps\\n(3.5 days).\\n5.3\\nOptimizer\\nWe used the Adam optimizer [20] with β1 = 0.9, β2 = 0.98 and ϵ = 10−9. We varied the learning\\nrate over the course of training, according to the formula:\\nlrate = d−0.5\\nmodel · min(step_num−0.5, step_num · warmup_steps−1.5)\\n(3)\\nThis corresponds to increasing the learning rate linearly for the first warmup_steps training steps,\\nand decreasing it thereafter proportionally to the inverse square root of the step number. We used\\nwarmup_steps = 4000.\\n5.4\\nRegularization\\nWe employ three types of regularization during training:\\n7\\nTable 2: The Transformer achieves better BLEU scores than previous state-of-the-art models on the\\nEnglish-to-German and English-to-French newstest2014 tests at a fraction of the training cost.\\nModel\\nBLEU\\nTraining Cost (FLOPs)\\nEN-DE\\nEN-FR\\nEN-DE\\nEN-FR\\nByteNet [18]\\n23.75\\nDeep-Att + PosUnk [39]\\n39.2\\n1.0 · 1020\\nGNMT + RL [38]\\n24.6\\n39.92\\n2.3 · 1019\\n1.4 · 1020\\nConvS2S [9]\\n25.16\\n40.46\\n9.6 · 1018\\n1.5 · 1020\\nMoE [32]\\n26.03\\n40.56\\n2.0 · 1019\\n1.2 · 1020\\nDeep-Att + PosUnk Ensemble [39]\\n40.4\\n8.0 · 1020\\nGNMT + RL Ensemble [38]\\n26.30\\n41.16\\n1.8 · 1020\\n1.1 · 1021\\nConvS2S Ensemble [9]\\n26.36\\n41.29\\n7.7 · 1019\\n1.2 · 1021\\nTransformer (base model)\\n27.3\\n38.1\\n3.3 · 1018\\nTransformer (big)\\n28.4\\n41.8\\n2.3 · 1019\\nResidual Dropout\\nWe apply dropout [33] to the output of each sub-layer, before it is added to the\\nsub-layer input and normalized. In addition, we apply dropout to the sums of the embeddings and the\\npositional encodings in both the encoder and decoder stacks. For the base model, we use a rate of\\nPdrop = 0.1.\\nLabel Smoothing\\nDuring training, we employed label smoothing of value ϵls = 0.1 [36]. This\\nhurts perplexity, as the model learns to be more unsure, but improves accuracy and BLEU score.\\n6\\nResults\\n6.1\\nMachine Translation\\nOn the WMT 2014 English-to-German translation task, the big transformer model (Transformer (big)\\nin Table 2) outperforms the best previously reported models (including ensembles) by more than 2.0\\nBLEU, establishing a new state-of-the-art BLEU score of 28.4. The configuration of this model is\\nlisted in the bottom line of Table 3. Training took 3.5 days on 8 P100 GPUs. Even our base model\\nsurpasses all previously published models and ensembles, at a fraction of the training cost of any of\\nthe competitive models.\\nOn the WMT 2014 English-to-French translation task, our big model achieves a BLEU score of 41.0,\\noutperforming all of the previously published single models, at less than 1/4 the training cost of the\\nprevious state-of-the-art model. The Transformer (big) model trained for English-to-French used\\ndropout rate Pdrop = 0.1, instead of 0.3.\\nFor the base models, we used a single model obtained by averaging the last 5 checkpoints, which\\nwere written at 10-minute intervals. For the big models, we averaged the last 20 checkpoints. We\\nused beam search with a beam size of 4 and length penalty α = 0.6 [38]. These hyperparameters\\nwere chosen after experimentation on the development set. We set the maximum output length during\\ninference to input length + 50, but terminate early when possible [38].\\nTable 2 summarizes our results and compares our translation quality and training costs to other model\\narchitectures from the literature. We estimate the number of floating point operations used to train a\\nmodel by multiplying the training time, the number of GPUs used, and an estimate of the sustained\\nsingle-precision floating-point capacity of each GPU 5.\\n6.2\\nModel Variations\\nTo evaluate the importance of different components of the Transformer, we varied our base model\\nin different ways, measuring the change in performance on English-to-German translation on the\\n5We used values of 2.8, 3.7, 6.0 and 9.5 TFLOPS for K80, K40, M40 and P100, respectively.\\n8\\nTable 3: Variations on the Transformer architecture. Unlisted values are identical to those of the base\\nmodel. All metrics are on the English-to-German translation development set, newstest2013. Listed\\nperplexities are per-wordpiece, according to our byte-pair encoding, and should not be compared to\\nper-word perplexities.\\nN\\ndmodel\\ndff\\nh\\ndk\\ndv\\nPdrop\\nϵls\\ntrain\\nPPL\\nBLEU\\nparams\\nsteps\\n(dev)\\n(dev)\\n×106\\nbase\\n6\\n512\\n2048\\n8\\n64\\n64\\n0.1\\n0.1\\n100K\\n4.92\\n25.8\\n65\\n(A)\\n1\\n512\\n512\\n5.29\\n24.9\\n4\\n128\\n128\\n5.00\\n25.5\\n16\\n32\\n32\\n4.91\\n25.8\\n32\\n16\\n16\\n5.01\\n25.4\\n(B)\\n16\\n5.16\\n25.1\\n58\\n32\\n5.01\\n25.4\\n60\\n(C)\\n2\\n6.11\\n23.7\\n36\\n4\\n5.19\\n25.3\\n50\\n8\\n4.88\\n25.5\\n80\\n256\\n32\\n32\\n5.75\\n24.5\\n28\\n1024\\n128\\n128\\n4.66\\n26.0\\n168\\n1024\\n5.12\\n25.4\\n53\\n4096\\n4.75\\n26.2\\n90\\n(D)\\n0.0\\n5.77\\n24.6\\n0.2\\n4.95\\n25.5\\n0.0\\n4.67\\n25.3\\n0.2\\n5.47\\n25.7\\n(E)\\npositional embedding instead of sinusoids\\n4.92\\n25.7\\nbig\\n6\\n1024\\n4096\\n16\\n0.3\\n300K\\n4.33\\n26.4\\n213\\ndevelopment set, newstest2013. We used beam search as described in the previous section, but no\\ncheckpoint averaging. We present these results in Table 3.\\nIn Table 3 rows (A), we vary the number of attention heads and the attention key and value dimensions,\\nkeeping the amount of computation constant, as described in Section 3.2.2. While single-head\\nattention is 0.9 BLEU worse than the best setting, quality also drops off with too many heads.\\nIn Table 3 rows (B), we observe that reducing the attention key size dk hurts model quality. This\\nsuggests that determining compatibility is not easy and that a more sophisticated compatibility\\nfunction than dot product may be beneficial. We further observe in rows (C) and (D) that, as expected,\\nbigger models are better, and dropout is very helpful in avoiding over-fitting. In row (E) we replace our\\nsinusoidal positional encoding with learned positional embeddings [9], and observe nearly identical\\nresults to the base model.\\n6.3\\nEnglish Constituency Parsing\\nTo evaluate if the Transformer can generalize to other tasks we performed experiments on English\\nconstituency parsing. This task presents specific challenges: the output is subject to strong structural\\nconstraints and is significantly longer than the input. Furthermore, RNN sequence-to-sequence\\nmodels have not been able to attain state-of-the-art results in small-data regimes [37].\\nWe trained a 4-layer transformer with dmodel = 1024 on the Wall Street Journal (WSJ) portion of the\\nPenn Treebank [25], about 40K training sentences. We also trained it in a semi-supervised setting,\\nusing the larger high-confidence and BerkleyParser corpora from with approximately 17M sentences\\n[37]. We used a vocabulary of 16K tokens for the WSJ only setting and a vocabulary of 32K tokens\\nfor the semi-supervised setting.\\nWe performed only a small number of experiments to select the dropout, both attention and residual\\n(section 5.4), learning rates and beam size on the Section 22 development set, all other parameters\\nremained unchanged from the English-to-German base translation model. During inference, we\\n9\\nTable 4: The Transformer generalizes well to English constituency parsing (Results are on Section 23\\nof WSJ)\\nParser\\nTraining\\nWSJ 23 F1\\nVinyals & Kaiser el al. (2014) [37]\\nWSJ only, discriminative\\n88.3\\nPetrov et al. (2006) [29]\\nWSJ only, discriminative\\n90.4\\nZhu et al. (2013) [40]\\nWSJ only, discriminative\\n90.4\\nDyer et al. (2016) [8]\\nWSJ only, discriminative\\n91.7\\nTransformer (4 layers)\\nWSJ only, discriminative\\n91.3\\nZhu et al. (2013) [40]\\nsemi-supervised\\n91.3\\nHuang & Harper (2009) [14]\\nsemi-supervised\\n91.3\\nMcClosky et al. (2006) [26]\\nsemi-supervised\\n92.1\\nVinyals & Kaiser el al. (2014) [37]\\nsemi-supervised\\n92.1\\nTransformer (4 layers)\\nsemi-supervised\\n92.7\\nLuong et al. (2015) [23]\\nmulti-task\\n93.0\\nDyer et al. (2016) [8]\\ngenerative\\n93.3\\nincreased the maximum output length to input length + 300. We used a beam size of 21 and α = 0.3\\nfor both WSJ only and the semi-supervised setting.\\nOur results in Table 4 show that despite the lack of task-specific tuning our model performs sur-\\nprisingly well, yielding better results than all previously reported models with the exception of the\\nRecurrent Neural Network Grammar [8].\\nIn contrast to RNN sequence-to-sequence models [37], the Transformer outperforms the Berkeley-\\nParser [29] even when training only on the WSJ training set of 40K sentences.\\n7\\nConclusion\\nIn this work, we presented the Transformer, the first sequence transduction model based entirely on\\nattention, replacing the recurrent layers most commonly used in encoder-decoder architectures with\\nmulti-headed self-attention.\\nFor translation tasks, the Transformer can be trained significantly faster than architectures based\\non recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014\\nEnglish-to-French translation tasks, we achieve a new state of the art. In the former task our best\\nmodel outperforms even all previously reported ensembles.\\nWe are excited about the future of attention-based models and plan to apply them to other tasks. We\\nplan to extend the Transformer to problems involving input and output modalities other than text and\\nto investigate local, restricted attention mechanisms to efficiently handle large inputs and outputs\\nsuch as images, audio and video. Making generation less sequential is another research goals of ours.\\nThe code we used to train and evaluate our models is available at https://github.com/\\ntensorflow/tensor2tensor.\\nAcknowledgements\\nWe are grateful to Nal Kalchbrenner and Stephan Gouws for their fruitful\\ncomments, corrections and inspiration.\\nReferences\\n[1] Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. arXiv preprint\\narXiv:1607.06450, 2016.\\n[2] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly\\nlearning to align and translate. CoRR, abs/1409.0473, 2014.\\n[3] Denny Britz, Anna Goldie, Minh-Thang Luong, and Quoc V. Le. Massive exploration of neural\\nmachine translation architectures. CoRR, abs/1703.03906, 2017.\\n[4] Jianpeng Cheng, Li Dong, and Mirella Lapata. Long short-term memory-networks for machine\\nreading. arXiv preprint arXiv:1601.06733, 2016.\\n10\\n[5] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Fethi Bougares, Holger Schwenk,\\nand Yoshua Bengio. Learning phrase representations using rnn encoder-decoder for statistical\\nmachine translation. CoRR, abs/1406.1078, 2014.\\n[6] Francois Chollet. Xception: Deep learning with depthwise separable convolutions. arXiv\\npreprint arXiv:1610.02357, 2016.\\n[7] Junyoung Chung, Çaglar Gülçehre, Kyunghyun Cho, and Yoshua Bengio. Empirical evaluation\\nof gated recurrent neural networks on sequence modeling. CoRR, abs/1412.3555, 2014.\\n[8] Chris Dyer, Adhiguna Kuncoro, Miguel Ballesteros, and Noah A. Smith. Recurrent neural\\nnetwork grammars. In Proc. of NAACL, 2016.\\n[9] Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu-\\ntional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.\\n[10] Alex Graves.\\nGenerating sequences with recurrent neural networks.\\narXiv preprint\\narXiv:1308.0850, 2013.\\n[11] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for im-\\nage recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition, pages 770–778, 2016.\\n[12] Sepp Hochreiter, Yoshua Bengio, Paolo Frasconi, and Jürgen Schmidhuber. Gradient flow in\\nrecurrent nets: the difficulty of learning long-term dependencies, 2001.\\n[13] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural computation,\\n9(8):1735–1780, 1997.\\n[14] Zhongqiang Huang and Mary Harper. Self-training PCFG grammars with latent annotations\\nacross languages. In Proceedings of the 2009 Conference on Empirical Methods in Natural\\nLanguage Processing, pages 832–841. ACL, August 2009.\\n[15] Rafal Jozefowicz, Oriol Vinyals, Mike Schuster, Noam Shazeer, and Yonghui Wu. Exploring\\nthe limits of language modeling. arXiv preprint arXiv:1602.02410, 2016.\\n[16] Łukasz Kaiser and Samy Bengio. Can active memory replace attention? In Advances in Neural\\nInformation Processing Systems, (NIPS), 2016.\\n[17] Łukasz Kaiser and Ilya Sutskever. Neural GPUs learn algorithms. In International Conference\\non Learning Representations (ICLR), 2016.\\n[18] Nal Kalchbrenner, Lasse Espeholt, Karen Simonyan, Aaron van den Oord, Alex Graves, and Ko-\\nray Kavukcuoglu. Neural machine translation in linear time. arXiv preprint arXiv:1610.10099v2,\\n2017.\\n[19] Yoon Kim, Carl Denton, Luong Hoang, and Alexander M. Rush. Structured attention networks.\\nIn International Conference on Learning Representations, 2017.\\n[20] Diederik Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015.\\n[21] Oleksii Kuchaiev and Boris Ginsburg. Factorization tricks for LSTM networks. arXiv preprint\\narXiv:1703.10722, 2017.\\n[22] Zhouhan Lin, Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen\\nZhou, and Yoshua Bengio. A structured self-attentive sentence embedding. arXiv preprint\\narXiv:1703.03130, 2017.\\n[23] Minh-Thang Luong, Quoc V. Le, Ilya Sutskever, Oriol Vinyals, and Lukasz Kaiser. Multi-task\\nsequence to sequence learning. arXiv preprint arXiv:1511.06114, 2015.\\n[24] Minh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-\\nbased neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\\n11\\n[25] Mitchell P Marcus, Mary Ann Marcinkiewicz, and Beatrice Santorini. Building a large annotated\\ncorpus of english: The penn treebank. Computational linguistics, 19(2):313–330, 1993.\\n[26] David McClosky, Eugene Charniak, and Mark Johnson. Effective self-training for parsing. In\\nProceedings of the Human Language Technology Conference of the NAACL, Main Conference,\\npages 152–159. ACL, June 2006.\\n[27] Ankur Parikh, Oscar Täckström, Dipanjan Das, and Jakob Uszkoreit. A decomposable attention\\nmodel. In Empirical Methods in Natural Language Processing, 2016.\\n[28] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\\nsummarization. arXiv preprint arXiv:1705.04304, 2017.\\n[29] Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. Learning accurate, compact,\\nand interpretable tree annotation. In Proceedings of the 21st International Conference on\\nComputational Linguistics and 44th Annual Meeting of the ACL, pages 433–440. ACL, July\\n2006.\\n[30] Ofir Press and Lior Wolf. Using the output embedding to improve language models. arXiv\\npreprint arXiv:1608.05859, 2016.\\n[31] Rico Sennrich, Barry Haddow, and Alexandra Birch. Neural machine translation of rare words\\nwith subword units. arXiv preprint arXiv:1508.07909, 2015.\\n[32] Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc Le, Geoffrey Hinton,\\nand Jeff Dean. Outrageously large neural networks: The sparsely-gated mixture-of-experts\\nlayer. arXiv preprint arXiv:1701.06538, 2017.\\n[33] Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdi-\\nnov. Dropout: a simple way to prevent neural networks from overfitting. Journal of Machine\\nLearning Research, 15(1):1929–1958, 2014.\\n[34] Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. End-to-end memory\\nnetworks. In C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 28, pages 2440–2448. Curran Associates,\\nInc., 2015.\\n[35] Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning with neural\\nnetworks. In Advances in Neural Information Processing Systems, pages 3104–3112, 2014.\\n[36] Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens, and Zbigniew Wojna.\\nRethinking the inception architecture for computer vision. CoRR, abs/1512.00567, 2015.\\n[37] Vinyals & Kaiser, Koo, Petrov, Sutskever, and Hinton. Grammar as a foreign language. In\\nAdvances in Neural Information Processing Systems, 2015.\\n[38] Yonghui Wu, Mike Schuster, Zhifeng Chen, Quoc V Le, Mohammad Norouzi, Wolfgang\\nMacherey, Maxim Krikun, Yuan Cao, Qin Gao, Klaus Macherey, et al. Google’s neural machine\\ntranslation system: Bridging the gap between human and machine translation. arXiv preprint\\narXiv:1609.08144, 2016.\\n[39] Jie Zhou, Ying Cao, Xuguang Wang, Peng Li, and Wei Xu. Deep recurrent models with\\nfast-forward connections for neural machine translation. CoRR, abs/1606.04199, 2016.\\n[40] Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. Fast and accurate\\nshift-reduce constituent parsing. In Proceedings of the 51st Annual Meeting of the ACL (Volume\\n1: Long Papers), pages 434–443. ACL, August 2013.\\n12\\nAttention Visualizations\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nIt\\nis\\nin\\nthis\\nspirit\\nthat\\na\\nmajority\\nof\\nAmerican\\ngovernments\\nhave\\npassed\\nnew\\nlaws\\nsince\\n2009\\nmaking\\nthe\\nregistration\\nor\\nvoting\\nprocess\\nmore\\ndifficult\\n.\\n<EOS>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\n<pad>\\nFigure 3: An example of the attention mechanism following long-distance dependencies in the\\nencoder self-attention in layer 5 of 6. Many of the attention heads attend to a distant dependency of\\nthe verb ‘making’, completing the phrase ‘making...more difficult’. Attentions here shown only for\\nthe word ‘making’. Different colors represent different heads. Best viewed in color.\\n13\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 4: Two attention heads, also in layer 5 of 6, apparently involved in anaphora resolution. Top:\\nFull attentions for head 5. Bottom: Isolated attentions from just the word ‘its’ for attention heads 5\\nand 6. Note that the attentions are very sharp for this word.\\n14\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nThe\\nLaw\\nwill\\nnever\\nbe\\nperfect\\n,\\nbut\\nits\\napplication\\nshould\\nbe\\njust\\n-\\nthis\\nis\\nwhat\\nwe\\nare\\nmissing\\n,\\nin\\nmy\\nopinion\\n.\\n<EOS>\\n<pad>\\nFigure 5: Many of the attention heads exhibit behaviour that seems related to the structure of the\\nsentence. We give two such examples above, from two different heads from the encoder self-attention\\nat layer 5 of 6. The heads clearly learned to perform different tasks.\\n15\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import ArxivLoader\n",
    "loader = ArxivLoader(query = \"1706.03762\", load_max_docs = 3)\n",
    "papers = loader.load()\n",
    "papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f324c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(papers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
